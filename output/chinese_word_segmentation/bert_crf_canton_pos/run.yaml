task: "chinese_word_segmentation"
device: 0
data:
  output_dir: "../output/chinese_word_segmentation/bert_crf_canton_pos"
  data_dir: "../data/datasets/internal/cws/canton_pos"
  train: train.json 
  dev: dev.json 
  test: test.json
text_prepro:
  steps:
    - full_to_half
eval:
  batch_size: 64
  model_file: "model.pt"
train:
  model_class: "BERT_CRF"
  kd: 
    use_kd: False
  seed: 42
  log_steps: 100
  batch_size: 32
  final_model: "best" # "best" or "last"
  optimization_metric: "micro_f1" # "micro_f1" or "macro_f1"
  early_stop: 5
model_params:
  # ================= TDBERT =================
  num_train_epochs: 15
  embedding_trainable: True
  tokenizer_name: "bert-base-chinese"
  pretrained_lm: "bert-base-chinese"