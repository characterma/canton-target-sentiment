***** Args *****
   task: chinese_word_segmentation
   device: 0
   data: {'output_dir': '../output/cws_canton_20210621_bert', 'data_dir': '../data/datasets/canton_ws', 'train': 'train.json', 'dev': 'dev.json', 'test': 'test.json'}
   text_prepro: {'steps': ['full_to_half']}
   eval: {'batch_size': 64, 'model_file': 'model.pt'}
   train: {'model_class': 'BERT_CRF', 'seed': 42, 'batch_size': 16, 'final_model': 'best', 'optimization_metric': 'micro_f1', 'early_stop': 5}
   model_params: {'num_train_epochs': 20, 'embedding_trainable': True, 'tokenizer_name': 'bert-base-chinese', 'pretrained_lm': 'bert-base-chinese'}
***** Loading tokenizer *****
  Tokenizer source = 'transformers'
  Tokenizer name = 'bert-base-chinese'
***** Initializing model *****
  Task = chinese_word_segmentation
  Model class = BERT_CRF
***** Loading pretrained language model *****
  Pretrained BERT = 'bert-base-chinese'
***** Loading data *****
  Data path = ../data/datasets/canton_ws/train.json
  Number of raw samples = 1956
  Number of loaded samples = 1956
***** Loading data *****
  Data path = ../data/datasets/canton_ws/dev.json
  Number of raw samples = 244
  Number of loaded samples = 244
***** Running training *****
  Num examples = 1956
  Num Epochs = 20
  Sampler = random
  Batch size = 16
  Gradient Accumulation steps = 1
***** Epoch end: 0 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.5334566143161469
  micro_f1 = 0.7322215911381763
  support = 6364
  ADJ-precision = 0.5137254901960784
  ADJ-recall = 0.4729241877256318
  ADJ-f1-score = 0.49248120300751874
  ADJ-support = 277
  ADP-precision = 0.5801526717557252
  ADP-recall = 0.6031746031746031
  ADP-f1-score = 0.5914396887159533
  ADP-support = 252
  ADV-precision = 0.5541838134430727
  ADV-recall = 0.7739463601532567
  ADV-f1-score = 0.6458832933653077
  ADV-support = 522
  AUX-precision = 0.5987654320987654
  AUX-recall = 0.5511363636363636
  AUX-f1-score = 0.57396449704142
  AUX-support = 176
  CCONJ-precision = 0.5333333333333333
  CCONJ-recall = 0.5245901639344263
  CCONJ-f1-score = 0.5289256198347108
  CCONJ-support = 122
  DET-precision = 0.5284552845528455
  DET-recall = 0.41139240506329117
  DET-f1-score = 0.4626334519572953
  DET-support = 158
  EMO-precision = 0.0
  EMO-recall = 0.0
  EMO-f1-score = 0.0
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.762796504369538
  NOUN-recall = 0.7506142506142506
  NOUN-f1-score = 0.7566563467492259
  NOUN-support = 1628
  NUM-precision = 0.7770491803278688
  NUM-recall = 0.8810408921933085
  NUM-f1-score = 0.8257839721254355
  NUM-support = 269
  PART-precision = 0.8972602739726028
  PART-recall = 0.7401129943502824
  PART-f1-score = 0.8111455108359132
  PART-support = 354
  PRON-precision = 0.6949152542372882
  PRON-recall = 0.6165413533834586
  PRON-f1-score = 0.6533864541832669
  PRON-support = 133
  PROPN-precision = 0.6164658634538153
  PROPN-recall = 0.7451456310679612
  PROPN-f1-score = 0.6747252747252748
  PROPN-support = 412
  PUNCT-precision = 0.9446680080482898
  PUNCT-recall = 0.9853095487932844
  PUNCT-f1-score = 0.9645608628659476
  PUNCT-support = 953
  SCONJ-precision = 0.4117647058823529
  SCONJ-recall = 0.31343283582089554
  SCONJ-f1-score = 0.35593220338983045
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7123034227567068
  VERB-recall = 0.751219512195122
  VERB-f1-score = 0.731244064577398
  VERB-support = 1025
  loss = 29.50706434249878
  dataset = dev
***** Epoch end: 1 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.6220570943509266
  micro_f1 = 0.7916623698124388
  support = 6364
  ADJ-precision = 0.6109215017064846
  ADJ-recall = 0.6462093862815884
  ADJ-f1-score = 0.6280701754385966
  ADJ-support = 277
  ADP-precision = 0.658273381294964
  ADP-recall = 0.7261904761904762
  ADP-f1-score = 0.690566037735849
  ADP-support = 252
  ADV-precision = 0.7023809523809523
  ADV-recall = 0.7911877394636015
  ADV-f1-score = 0.7441441441441441
  ADV-support = 522
  AUX-precision = 0.7664670658682635
  AUX-recall = 0.7272727272727273
  AUX-f1-score = 0.7463556851311953
  AUX-support = 176
  CCONJ-precision = 0.7313432835820896
  CCONJ-recall = 0.8032786885245902
  CCONJ-f1-score = 0.765625
  CCONJ-support = 122
  DET-precision = 0.5886524822695035
  DET-recall = 0.5253164556962026
  DET-f1-score = 0.5551839464882943
  DET-support = 158
  EMO-precision = 0.0
  EMO-recall = 0.0
  EMO-f1-score = 0.0
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7630359212050984
  NOUN-recall = 0.808968058968059
  NOUN-f1-score = 0.7853309481216458
  NOUN-support = 1628
  NUM-precision = 0.8621908127208481
  NUM-recall = 0.9070631970260223
  NUM-f1-score = 0.8840579710144928
  NUM-support = 269
  PART-precision = 0.9228295819935691
  PART-recall = 0.8107344632768362
  PART-f1-score = 0.8631578947368421
  PART-support = 354
  PRON-precision = 0.875
  PRON-recall = 0.6842105263157895
  PRON-f1-score = 0.7679324894514769
  PRON-support = 133
  PROPN-precision = 0.75
  PROPN-recall = 0.7135922330097088
  PROPN-f1-score = 0.7313432835820897
  PROPN-support = 412
  PUNCT-precision = 0.977319587628866
  PUNCT-recall = 0.9947534102833159
  PUNCT-f1-score = 0.9859594383775351
  PUNCT-support = 953
  SCONJ-precision = 0.6024096385542169
  SCONJ-recall = 0.746268656716418
  SCONJ-f1-score = 0.6666666666666667
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7497630331753554
  VERB-recall = 0.7717073170731708
  VERB-f1-score = 0.7605769230769232
  VERB-support = 1025
  loss = 23.351131916046143
  dataset = dev
***** Epoch end: 2 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.6517096169060514
  micro_f1 = 0.8105624267112623
  support = 6364
  ADJ-precision = 0.6217105263157895
  ADJ-recall = 0.6823104693140795
  ADJ-f1-score = 0.6506024096385542
  ADJ-support = 277
  ADP-precision = 0.7091633466135459
  ADP-recall = 0.7063492063492064
  ADP-f1-score = 0.7077534791252486
  ADP-support = 252
  ADV-precision = 0.7680890538033395
  ADV-recall = 0.7931034482758621
  ADV-f1-score = 0.7803958529688972
  ADV-support = 522
  AUX-precision = 0.8224852071005917
  AUX-recall = 0.7897727272727273
  AUX-f1-score = 0.8057971014492753
  AUX-support = 176
  CCONJ-precision = 0.896551724137931
  CCONJ-recall = 0.8524590163934426
  CCONJ-f1-score = 0.8739495798319327
  CCONJ-support = 122
  DET-precision = 0.6296296296296297
  DET-recall = 0.5379746835443038
  DET-f1-score = 0.5802047781569966
  DET-support = 158
  EMO-precision = 0.0
  EMO-recall = 0.0
  EMO-f1-score = 0.0
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7702546296296297
  NOUN-recall = 0.8175675675675675
  NOUN-f1-score = 0.7932061978545888
  NOUN-support = 1628
  NUM-precision = 0.8715277777777778
  NUM-recall = 0.9330855018587361
  NUM-f1-score = 0.9012567324955117
  NUM-support = 269
  PART-precision = 0.8826979472140762
  PART-recall = 0.8502824858757062
  PART-f1-score = 0.8661870503597123
  PART-support = 354
  PRON-precision = 0.8807339449541285
  PRON-recall = 0.7218045112781954
  PRON-f1-score = 0.7933884297520661
  PRON-support = 133
  PROPN-precision = 0.7529411764705882
  PROPN-recall = 0.7766990291262136
  PROPN-f1-score = 0.7646356033452807
  PROPN-support = 412
  PUNCT-precision = 0.9683673469387755
  PUNCT-recall = 0.9958027282266527
  PUNCT-f1-score = 0.9818934299017071
  PUNCT-support = 953
  SCONJ-precision = 0.7746478873239436
  SCONJ-recall = 0.8208955223880597
  SCONJ-f1-score = 0.7971014492753623
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7634508348794063
  VERB-recall = 0.8029268292682927
  VERB-f1-score = 0.7826913932477413
  VERB-support = 1025
  loss = 21.660911083221436
  dataset = dev
***** Epoch end: 3 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.6905417362607138
  micro_f1 = 0.8110562183512556
  support = 6364
  ADJ-precision = 0.5853658536585366
  ADJ-recall = 0.6931407942238267
  ADJ-f1-score = 0.6347107438016528
  ADJ-support = 277
  ADP-precision = 0.6928838951310862
  ADP-recall = 0.7341269841269841
  ADP-f1-score = 0.7129094412331406
  ADP-support = 252
  ADV-precision = 0.7579505300353356
  ADV-recall = 0.8218390804597702
  ADV-f1-score = 0.7886029411764705
  ADV-support = 522
  AUX-precision = 0.7700534759358288
  AUX-recall = 0.8181818181818182
  AUX-f1-score = 0.793388429752066
  AUX-support = 176
  CCONJ-precision = 0.8195488721804511
  CCONJ-recall = 0.8934426229508197
  CCONJ-f1-score = 0.8549019607843137
  CCONJ-support = 122
  DET-precision = 0.5933333333333334
  DET-recall = 0.5632911392405063
  DET-f1-score = 0.577922077922078
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7993827160493827
  NOUN-recall = 0.7954545454545454
  NOUN-f1-score = 0.7974137931034483
  NOUN-support = 1628
  NUM-precision = 0.8853046594982079
  NUM-recall = 0.9182156133828996
  NUM-f1-score = 0.9014598540145985
  NUM-support = 269
  PART-precision = 0.856353591160221
  PART-recall = 0.8757062146892656
  PART-f1-score = 0.8659217877094972
  PART-support = 354
  PRON-precision = 0.8253968253968254
  PRON-recall = 0.7819548872180451
  PRON-f1-score = 0.803088803088803
  PRON-support = 133
  PROPN-precision = 0.7416481069042317
  PROPN-recall = 0.808252427184466
  PROPN-f1-score = 0.7735191637630662
  PROPN-support = 412
  PUNCT-precision = 0.9683350357507661
  PUNCT-recall = 0.9947534102833159
  PUNCT-f1-score = 0.981366459627329
  PUNCT-support = 953
  SCONJ-precision = 0.7631578947368421
  SCONJ-recall = 0.8656716417910447
  SCONJ-f1-score = 0.8111888111888113
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7776689520078355
  VERB-recall = 0.7746341463414634
  VERB-f1-score = 0.7761485826001955
  VERB-support = 1025
  loss = 21.316763401031494
  dataset = dev
***** Epoch end: 4 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.6984594396477297
  micro_f1 = 0.8177954740729905
  support = 6364
  ADJ-precision = 0.6402640264026402
  ADJ-recall = 0.7003610108303249
  ADJ-f1-score = 0.6689655172413793
  ADJ-support = 277
  ADP-precision = 0.6937269372693727
  ADP-recall = 0.746031746031746
  ADP-f1-score = 0.7189292543021033
  ADP-support = 252
  ADV-precision = 0.7633451957295374
  ADV-recall = 0.8218390804597702
  ADV-f1-score = 0.7915129151291513
  ADV-support = 522
  AUX-precision = 0.7684210526315789
  AUX-recall = 0.8295454545454546
  AUX-f1-score = 0.7978142076502732
  AUX-support = 176
  CCONJ-precision = 0.8384615384615385
  CCONJ-recall = 0.8934426229508197
  CCONJ-f1-score = 0.865079365079365
  CCONJ-support = 122
  DET-precision = 0.6274509803921569
  DET-recall = 0.6075949367088608
  DET-f1-score = 0.6173633440514469
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.80545229244114
  NOUN-recall = 0.7985257985257985
  NOUN-f1-score = 0.8019740900678594
  NOUN-support = 1628
  NUM-precision = 0.8953068592057761
  NUM-recall = 0.9219330855018587
  NUM-f1-score = 0.9084249084249084
  NUM-support = 269
  PART-precision = 0.8788732394366198
  PART-recall = 0.8813559322033898
  PART-f1-score = 0.8801128349788434
  PART-support = 354
  PRON-precision = 0.8547008547008547
  PRON-recall = 0.7518796992481203
  PRON-f1-score = 0.8
  PRON-support = 133
  PROPN-precision = 0.7427937915742794
  PROPN-recall = 0.8131067961165048
  PROPN-f1-score = 0.7763615295480879
  PROPN-support = 412
  PUNCT-precision = 0.9671120246659815
  PUNCT-recall = 0.9874081846799581
  PUNCT-f1-score = 0.9771547248182761
  PUNCT-support = 953
  SCONJ-precision = 0.7733333333333333
  SCONJ-recall = 0.8656716417910447
  SCONJ-f1-score = 0.8169014084507041
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7857838364167478
  VERB-recall = 0.7873170731707317
  VERB-f1-score = 0.7865497076023391
  VERB-support = 1025
  loss = 22.066081523895264
  dataset = dev
***** Epoch end: 5 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.6983396092979879
  micro_f1 = 0.81662663529737
  support = 6364
  ADJ-precision = 0.6241830065359477
  ADJ-recall = 0.6895306859205776
  ADJ-f1-score = 0.6552315608919382
  ADJ-support = 277
  ADP-precision = 0.7159090909090909
  ADP-recall = 0.75
  ADP-f1-score = 0.7325581395348838
  ADP-support = 252
  ADV-precision = 0.7734806629834254
  ADV-recall = 0.8045977011494253
  ADV-f1-score = 0.7887323943661972
  ADV-support = 522
  AUX-precision = 0.7474226804123711
  AUX-recall = 0.8238636363636364
  AUX-f1-score = 0.7837837837837838
  AUX-support = 176
  CCONJ-precision = 0.8043478260869565
  CCONJ-recall = 0.9098360655737705
  CCONJ-f1-score = 0.8538461538461539
  CCONJ-support = 122
  DET-precision = 0.6206896551724138
  DET-recall = 0.569620253164557
  DET-f1-score = 0.594059405940594
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7843601895734598
  NOUN-recall = 0.8132678132678133
  NOUN-f1-score = 0.7985524728588661
  NOUN-support = 1628
  NUM-precision = 0.8981818181818182
  NUM-recall = 0.9182156133828996
  NUM-f1-score = 0.9080882352941176
  NUM-support = 269
  PART-precision = 0.9037900874635568
  PART-recall = 0.8757062146892656
  PART-f1-score = 0.8895265423242468
  PART-support = 354
  PRON-precision = 0.8524590163934426
  PRON-recall = 0.7819548872180451
  PRON-f1-score = 0.8156862745098038
  PRON-support = 133
  PROPN-precision = 0.7683215130023641
  PROPN-recall = 0.7888349514563107
  PROPN-f1-score = 0.7784431137724551
  PROPN-support = 412
  PUNCT-precision = 0.9723360655737705
  PUNCT-recall = 0.9958027282266527
  PUNCT-f1-score = 0.9839294971487818
  PUNCT-support = 953
  SCONJ-precision = 0.8082191780821918
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8428571428571429
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7911646586345381
  VERB-recall = 0.7687804878048781
  VERB-f1-score = 0.7798119742701634
  VERB-support = 1025
  loss = 22.404154300689697
  dataset = dev
***** Epoch end: 6 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.7032593458974037
  micro_f1 = 0.8221816652631503
  support = 6364
  ADJ-precision = 0.6595744680851063
  ADJ-recall = 0.6714801444043321
  ADJ-f1-score = 0.6654740608228981
  ADJ-support = 277
  ADP-precision = 0.746938775510204
  ADP-recall = 0.7261904761904762
  ADP-f1-score = 0.7364185110663983
  ADP-support = 252
  ADV-precision = 0.7906542056074767
  ADV-recall = 0.8103448275862069
  ADV-f1-score = 0.8003784295175023
  ADV-support = 522
  AUX-precision = 0.7944444444444444
  AUX-recall = 0.8125
  AUX-f1-score = 0.803370786516854
  AUX-support = 176
  CCONJ-precision = 0.8248175182481752
  CCONJ-recall = 0.9262295081967213
  CCONJ-f1-score = 0.8725868725868726
  CCONJ-support = 122
  DET-precision = 0.6232876712328768
  DET-recall = 0.5759493670886076
  DET-f1-score = 0.5986842105263158
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7931449188214071
  NOUN-recall = 0.8101965601965602
  NOUN-f1-score = 0.801580066848982
  NOUN-support = 1628
  NUM-precision = 0.9018181818181819
  NUM-recall = 0.9219330855018587
  NUM-f1-score = 0.9117647058823529
  NUM-support = 269
  PART-precision = 0.8650137741046832
  PART-recall = 0.8870056497175142
  PART-f1-score = 0.8758716875871687
  PART-support = 354
  PRON-precision = 0.828125
  PRON-recall = 0.7969924812030075
  PRON-f1-score = 0.8122605363984673
  PRON-support = 133
  PROPN-precision = 0.7862407862407862
  PROPN-recall = 0.7766990291262136
  PROPN-f1-score = 0.7814407814407814
  PROPN-support = 412
  PUNCT-precision = 0.9703476482617587
  PUNCT-recall = 0.9958027282266527
  PUNCT-f1-score = 0.9829104091144485
  PUNCT-support = 953
  SCONJ-precision = 0.8194444444444444
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8489208633093526
  SCONJ-support = 67
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 13
  VERB-precision = 0.7951456310679612
  VERB-recall = 0.7990243902439025
  VERB-f1-score = 0.797080291970803
  VERB-support = 1025
  loss = 23.253583908081055
  dataset = dev
***** Epoch end: 7 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.7090541777623259
  micro_f1 = 0.8216127335126342
  support = 6364
  ADJ-precision = 0.6428571428571429
  ADJ-recall = 0.6823104693140795
  ADJ-f1-score = 0.6619964973730298
  ADJ-support = 277
  ADP-precision = 0.7325581395348837
  ADP-recall = 0.75
  ADP-f1-score = 0.7411764705882353
  ADP-support = 252
  ADV-precision = 0.7717391304347826
  ADV-recall = 0.8160919540229885
  ADV-f1-score = 0.7932960893854749
  ADV-support = 522
  AUX-precision = 0.7564766839378239
  AUX-recall = 0.8295454545454546
  AUX-f1-score = 0.7913279132791328
  AUX-support = 176
  CCONJ-precision = 0.8396946564885496
  CCONJ-recall = 0.9016393442622951
  CCONJ-f1-score = 0.8695652173913043
  CCONJ-support = 122
  DET-precision = 0.5961538461538461
  DET-recall = 0.5886075949367089
  DET-f1-score = 0.5923566878980892
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7995169082125604
  NOUN-recall = 0.8132678132678133
  NOUN-f1-score = 0.8063337393422656
  NOUN-support = 1628
  NUM-precision = 0.9104477611940298
  NUM-recall = 0.9070631970260223
  NUM-f1-score = 0.9087523277467411
  NUM-support = 269
  PART-precision = 0.8461538461538461
  PART-recall = 0.9011299435028248
  PART-f1-score = 0.8727770177838576
  PART-support = 354
  PRON-precision = 0.85
  PRON-recall = 0.7669172932330827
  PRON-f1-score = 0.8063241106719368
  PRON-support = 133
  PROPN-precision = 0.7875894988066826
  PROPN-recall = 0.8009708737864077
  PROPN-f1-score = 0.7942238267148015
  PROPN-support = 412
  PUNCT-precision = 0.9663608562691132
  PUNCT-recall = 0.9947534102833159
  PUNCT-f1-score = 0.9803516028955533
  PUNCT-support = 953
  SCONJ-precision = 0.855072463768116
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8676470588235295
  SCONJ-support = 67
  SYM-precision = 0.2
  SYM-recall = 0.07692307692307693
  SYM-f1-score = 0.1111111111111111
  SYM-support = 13
  VERB-precision = 0.7927308447937131
  VERB-recall = 0.7873170731707317
  VERB-f1-score = 0.7900146842878121
  VERB-support = 1025
  loss = 24.07814073562622
  dataset = dev
***** Epoch end: 8 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.7298795024427608
  micro_f1 = 0.828081601305445
  support = 6364
  ADJ-precision = 0.6549295774647887
  ADJ-recall = 0.6714801444043321
  ADJ-f1-score = 0.6631016042780749
  ADJ-support = 277
  ADP-precision = 0.7787234042553192
  ADP-recall = 0.7261904761904762
  ADP-f1-score = 0.7515400410677618
  ADP-support = 252
  ADV-precision = 0.7869158878504673
  ADV-recall = 0.8065134099616859
  ADV-f1-score = 0.7965941343424787
  ADV-support = 522
  AUX-precision = 0.8055555555555556
  AUX-recall = 0.8238636363636364
  AUX-f1-score = 0.8146067415730336
  AUX-support = 176
  CCONJ-precision = 0.8842975206611571
  CCONJ-recall = 0.8770491803278688
  CCONJ-f1-score = 0.8806584362139916
  CCONJ-support = 122
  DET-precision = 0.6442953020134228
  DET-recall = 0.6075949367088608
  DET-f1-score = 0.6254071661237784
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.8008398320335933
  NOUN-recall = 0.8200245700245701
  NOUN-f1-score = 0.8103186646433992
  NOUN-support = 1628
  NUM-precision = 0.8960573476702509
  NUM-recall = 0.929368029739777
  NUM-f1-score = 0.9124087591240876
  NUM-support = 269
  PART-precision = 0.8936781609195402
  PART-recall = 0.8785310734463276
  PART-f1-score = 0.8860398860398861
  PART-support = 354
  PRON-precision = 0.8938053097345132
  PRON-recall = 0.7593984962406015
  PRON-f1-score = 0.8211382113821138
  PRON-support = 133
  PROPN-precision = 0.7801418439716312
  PROPN-recall = 0.8009708737864077
  PROPN-f1-score = 0.7904191616766467
  PROPN-support = 412
  PUNCT-precision = 0.9721074380165289
  PUNCT-recall = 0.9874081846799581
  PUNCT-f1-score = 0.9796980739198334
  PUNCT-support = 953
  SCONJ-precision = 0.8309859154929577
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8550724637681161
  SCONJ-support = 67
  SYM-precision = 0.75
  SYM-recall = 0.23076923076923078
  SYM-f1-score = 0.3529411764705882
  SYM-support = 13
  VERB-precision = 0.7866541353383458
  VERB-recall = 0.8165853658536585
  VERB-f1-score = 0.8013403542364769
  VERB-support = 1025
  loss = 25.080612659454346
  dataset = dev
***** Epoch end: 9 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.7232916368061658
  micro_f1 = 0.8227551030857838
  support = 6364
  ADJ-precision = 0.6512455516014235
  ADJ-recall = 0.6606498194945848
  ADJ-f1-score = 0.6559139784946235
  ADJ-support = 277
  ADP-precision = 0.7180451127819549
  ADP-recall = 0.7579365079365079
  ADP-f1-score = 0.7374517374517374
  ADP-support = 252
  ADV-precision = 0.7747252747252747
  ADV-recall = 0.8103448275862069
  ADV-f1-score = 0.7921348314606742
  ADV-support = 522
  AUX-precision = 0.7409326424870466
  AUX-recall = 0.8125
  AUX-f1-score = 0.7750677506775067
  AUX-support = 176
  CCONJ-precision = 0.8538461538461538
  CCONJ-recall = 0.9098360655737705
  CCONJ-f1-score = 0.880952380952381
  CCONJ-support = 122
  DET-precision = 0.6533333333333333
  DET-recall = 0.620253164556962
  DET-f1-score = 0.6363636363636364
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.790946992257296
  NOUN-recall = 0.8157248157248157
  NOUN-f1-score = 0.8031448442697309
  NOUN-support = 1628
  NUM-precision = 0.9047619047619048
  NUM-recall = 0.9182156133828996
  NUM-f1-score = 0.911439114391144
  NUM-support = 269
  PART-precision = 0.8777777777777778
  PART-recall = 0.8926553672316384
  PART-f1-score = 0.8851540616246499
  PART-support = 354
  PRON-precision = 0.8947368421052632
  PRON-recall = 0.7669172932330827
  PRON-f1-score = 0.8259109311740891
  PRON-support = 133
  PROPN-precision = 0.7831325301204819
  PROPN-recall = 0.7888349514563107
  PROPN-f1-score = 0.7859733978234583
  PROPN-support = 412
  PUNCT-precision = 0.9743326488706365
  PUNCT-recall = 0.9958027282266527
  PUNCT-f1-score = 0.9849507005708354
  PUNCT-support = 953
  SCONJ-precision = 0.8194444444444444
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8489208633093526
  SCONJ-support = 67
  SYM-precision = 0.5
  SYM-recall = 0.23076923076923078
  SYM-f1-score = 0.3157894736842105
  SYM-support = 13
  VERB-precision = 0.8
  VERB-recall = 0.7804878048780488
  VERB-f1-score = 0.7901234567901235
  VERB-support = 1025
  loss = 25.679097652435303
  dataset = dev
***** Epoch end: 10 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.6821689620069304
  micro_f1 = 0.8229330013137639
  support = 6364
  ADJ-precision = 0.6715328467153284
  ADJ-recall = 0.6642599277978339
  ADJ-f1-score = 0.6678765880217786
  ADJ-support = 277
  ADP-precision = 0.7094339622641509
  ADP-recall = 0.746031746031746
  ADP-f1-score = 0.7272727272727273
  ADP-support = 252
  ADV-precision = 0.7650273224043715
  ADV-recall = 0.8045977011494253
  ADV-f1-score = 0.784313725490196
  ADV-support = 522
  AUX-precision = 0.7747252747252747
  AUX-recall = 0.8011363636363636
  AUX-f1-score = 0.7877094972067039
  AUX-support = 176
  CCONJ-precision = 0.8861788617886179
  CCONJ-recall = 0.8934426229508197
  CCONJ-f1-score = 0.8897959183673471
  CCONJ-support = 122
  DET-precision = 0.6621621621621622
  DET-recall = 0.620253164556962
  DET-f1-score = 0.6405228758169935
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7980711271850512
  NOUN-recall = 0.8132678132678133
  NOUN-f1-score = 0.8055978095527837
  NOUN-support = 1628
  NUM-precision = 0.8992805755395683
  NUM-recall = 0.929368029739777
  NUM-f1-score = 0.9140767824497258
  NUM-support = 269
  PART-precision = 0.8725212464589235
  PART-recall = 0.8700564971751412
  PART-f1-score = 0.8712871287128712
  PART-support = 354
  PRON-precision = 0.7954545454545454
  PRON-recall = 0.7894736842105263
  PRON-f1-score = 0.7924528301886792
  PRON-support = 133
  PROPN-precision = 0.7798594847775175
  PROPN-recall = 0.808252427184466
  PROPN-f1-score = 0.7938021454112038
  PROPN-support = 412
  PUNCT-precision = 0.9743326488706365
  PUNCT-recall = 0.9958027282266527
  PUNCT-f1-score = 0.9849507005708354
  PUNCT-support = 953
  SCONJ-precision = 0.8428571428571429
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8613138686131387
  SCONJ-support = 67
  SYM-precision = 0.42857142857142855
  SYM-recall = 0.23076923076923078
  SYM-f1-score = 0.3
  SYM-support = 13
  URL-precision = 0.0
  URL-recall = 0.0
  URL-f1-score = 0.0
  URL-support = 0
  VERB-precision = 0.7925636007827789
  VERB-recall = 0.7902439024390244
  VERB-f1-score = 0.7914020517830973
  VERB-support = 1025
  loss = 26.740792274475098
  dataset = dev
***** Epoch end: 11 *****
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.723410274141779
  micro_f1 = 0.8230902847243058
  support = 6364
  ADJ-precision = 0.6821705426356589
  ADJ-recall = 0.6353790613718412
  ADJ-f1-score = 0.6579439252336449
  ADJ-support = 277
  ADP-precision = 0.7078651685393258
  ADP-recall = 0.75
  ADP-f1-score = 0.7283236994219654
  ADP-support = 252
  ADV-precision = 0.7682481751824818
  ADV-recall = 0.8065134099616859
  ADV-f1-score = 0.7869158878504673
  ADV-support = 522
  AUX-precision = 0.7988826815642458
  AUX-recall = 0.8125
  AUX-f1-score = 0.8056338028169014
  AUX-support = 176
  CCONJ-precision = 0.873015873015873
  CCONJ-recall = 0.9016393442622951
  CCONJ-f1-score = 0.8870967741935485
  CCONJ-support = 122
  DET-precision = 0.6266666666666667
  DET-recall = 0.5949367088607594
  DET-f1-score = 0.6103896103896105
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.7923627684964201
  NOUN-recall = 0.8157248157248157
  NOUN-f1-score = 0.8038740920096853
  NOUN-support = 1628
  NUM-precision = 0.9097472924187726
  NUM-recall = 0.9368029739776952
  NUM-f1-score = 0.9230769230769231
  NUM-support = 269
  PART-precision = 0.8774928774928775
  PART-recall = 0.8700564971751412
  PART-f1-score = 0.8737588652482271
  PART-support = 354
  PRON-precision = 0.8091603053435115
  PRON-recall = 0.7969924812030075
  PRON-f1-score = 0.803030303030303
  PRON-support = 133
  PROPN-precision = 0.7767441860465116
  PROPN-recall = 0.8106796116504854
  PROPN-f1-score = 0.7933491686460807
  PROPN-support = 412
  PUNCT-precision = 0.9723360655737705
  PUNCT-recall = 0.9958027282266527
  PUNCT-f1-score = 0.9839294971487818
  PUNCT-support = 953
  SCONJ-precision = 0.8805970149253731
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8805970149253731
  SCONJ-support = 67
  SYM-precision = 0.42857142857142855
  SYM-recall = 0.23076923076923078
  SYM-f1-score = 0.3
  SYM-support = 13
  VERB-precision = 0.7906976744186046
  VERB-recall = 0.7960975609756098
  VERB-f1-score = 0.7933884297520661
  VERB-support = 1025
  loss = 27.215710639953613
  dataset = dev
***** Training end *****
  Model path = ../output/cws_canton_20210621_bert/model/model.pt
***** Loading data *****
  Data path = ../data/datasets/canton_ws/test.json
  Number of raw samples = 245
  Number of loaded samples = 245
***** Running evaluation *****
  Num examples = 1956
  Batch size = 64
  macro_f1 = 0.7644798993936371
  micro_f1 = 0.9592627622645441
  support = 50219
  ADJ-precision = 0.9343589743589743
  ADJ-recall = 0.946985446985447
  ADJ-f1-score = 0.940629839958699
  ADJ-support = 1924
  ADP-precision = 0.9257246376811594
  ADP-recall = 0.9333333333333333
  ADP-f1-score = 0.9295134151887221
  ADP-support = 2190
  ADV-precision = 0.9356921487603306
  ADV-recall = 0.9432439468888311
  ADV-f1-score = 0.9394528717749255
  ADV-support = 3841
  AT-precision = 0.0
  AT-recall = 0.0
  AT-f1-score = 0.0
  AT-support = 2
  AUX-precision = 0.9261006289308176
  AUX-recall = 0.9203125
  AUX-f1-score = 0.9231974921630093
  AUX-support = 1280
  CCONJ-precision = 0.9659533073929961
  CCONJ-recall = 0.9612778315585673
  CCONJ-f1-score = 0.9636098981077147
  CCONJ-support = 1033
  DET-precision = 0.8147554129911788
  DET-recall = 0.8487886382623224
  DET-f1-score = 0.8314238952536824
  DET-support = 1197
  EMO-precision = 0.9090909090909091
  EMO-recall = 0.7692307692307693
  EMO-f1-score = 0.8333333333333333
  EMO-support = 13
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 3
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 3
  NOUN-precision = 0.9673821063158704
  NOUN-recall = 0.9685742894554418
  NOUN-f1-score = 0.9679778308059426
  NOUN-support = 12983
  NUM-precision = 0.9782157676348547
  NUM-recall = 0.9792315680166147
  NUM-f1-score = 0.9787234042553191
  NUM-support = 1926
  PART-precision = 0.9627177700348432
  PART-recall = 0.9494845360824742
  PART-f1-score = 0.9560553633217993
  PART-support = 2910
  PRON-precision = 0.9606625258799172
  PRON-recall = 0.8444040036396724
  PRON-f1-score = 0.8987893462469733
  PRON-support = 1099
  PROPN-precision = 0.9734361610968295
  PROPN-recall = 0.9795918367346939
  PROPN-f1-score = 0.9765042979942694
  PROPN-support = 3479
  PUNCT-precision = 0.9960666054805297
  PUNCT-recall = 0.9986854213224662
  PUNCT-f1-score = 0.9973742943416043
  PUNCT-support = 7607
  SCONJ-precision = 0.9154471544715447
  SCONJ-recall = 0.959114139693356
  SCONJ-f1-score = 0.9367720465890182
  SCONJ-support = 587
  SYM-precision = 0.9375
  SYM-recall = 0.5769230769230769
  SYM-f1-score = 0.7142857142857143
  SYM-support = 26
  URL-precision = 0.42857142857142855
  URL-recall = 0.75
  URL-f1-score = 0.5454545454545454
  URL-support = 4
  VERB-precision = 0.9521192133870771
  VERB-recall = 0.9609220907297831
  VERB-f1-score = 0.9565003987974723
  VERB-support = 8112
  loss = 3.9290756179440405
  dataset = train
***** Running evaluation *****
  Num examples = 244
  Batch size = 64
  macro_f1 = 0.7298795024427608
  micro_f1 = 0.828081601305445
  support = 6364
  ADJ-precision = 0.6549295774647887
  ADJ-recall = 0.6714801444043321
  ADJ-f1-score = 0.6631016042780749
  ADJ-support = 277
  ADP-precision = 0.7787234042553192
  ADP-recall = 0.7261904761904762
  ADP-f1-score = 0.7515400410677618
  ADP-support = 252
  ADV-precision = 0.7869158878504673
  ADV-recall = 0.8065134099616859
  ADV-f1-score = 0.7965941343424787
  ADV-support = 522
  AUX-precision = 0.8055555555555556
  AUX-recall = 0.8238636363636364
  AUX-f1-score = 0.8146067415730336
  AUX-support = 176
  CCONJ-precision = 0.8842975206611571
  CCONJ-recall = 0.8770491803278688
  CCONJ-f1-score = 0.8806584362139916
  CCONJ-support = 122
  DET-precision = 0.6442953020134228
  DET-recall = 0.6075949367088608
  DET-f1-score = 0.6254071661237784
  DET-support = 158
  EMO-precision = 1.0
  EMO-recall = 0.5
  EMO-f1-score = 0.6666666666666666
  EMO-support = 2
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 1
  NOUN-precision = 0.8008398320335933
  NOUN-recall = 0.8200245700245701
  NOUN-f1-score = 0.8103186646433992
  NOUN-support = 1628
  NUM-precision = 0.8960573476702509
  NUM-recall = 0.929368029739777
  NUM-f1-score = 0.9124087591240876
  NUM-support = 269
  PART-precision = 0.8936781609195402
  PART-recall = 0.8785310734463276
  PART-f1-score = 0.8860398860398861
  PART-support = 354
  PRON-precision = 0.8938053097345132
  PRON-recall = 0.7593984962406015
  PRON-f1-score = 0.8211382113821138
  PRON-support = 133
  PROPN-precision = 0.7801418439716312
  PROPN-recall = 0.8009708737864077
  PROPN-f1-score = 0.7904191616766467
  PROPN-support = 412
  PUNCT-precision = 0.9721074380165289
  PUNCT-recall = 0.9874081846799581
  PUNCT-f1-score = 0.9796980739198334
  PUNCT-support = 953
  SCONJ-precision = 0.8309859154929577
  SCONJ-recall = 0.8805970149253731
  SCONJ-f1-score = 0.8550724637681161
  SCONJ-support = 67
  SYM-precision = 0.75
  SYM-recall = 0.23076923076923078
  SYM-f1-score = 0.3529411764705882
  SYM-support = 13
  VERB-precision = 0.7866541353383458
  VERB-recall = 0.8165853658536585
  VERB-f1-score = 0.8013403542364769
  VERB-support = 1025
  loss = 25.080612659454346
  dataset = dev
***** Running evaluation *****
  Num examples = 245
  Batch size = 64
  macro_f1 = 0.606802784169795
  micro_f1 = 0.8124061159896987
  support = 6395
  ADJ-precision = 0.5963636363636363
  ADJ-recall = 0.5963636363636363
  ADJ-f1-score = 0.5963636363636363
  ADJ-support = 275
  ADP-precision = 0.8157894736842105
  ADP-recall = 0.7948717948717948
  ADP-f1-score = 0.8051948051948051
  ADP-support = 273
  ADV-precision = 0.7410526315789474
  ADV-recall = 0.7635574837310195
  ADV-f1-score = 0.7521367521367521
  ADV-support = 461
  AUX-precision = 0.7463768115942029
  AUX-recall = 0.7744360902255639
  AUX-f1-score = 0.7601476014760149
  AUX-support = 133
  CCONJ-precision = 0.9027777777777778
  CCONJ-recall = 0.8904109589041096
  CCONJ-f1-score = 0.896551724137931
  CCONJ-support = 146
  DET-precision = 0.5454545454545454
  DET-recall = 0.6081081081081081
  DET-f1-score = 0.5750798722044728
  DET-support = 148
  EMO-precision = 0.5
  EMO-recall = 0.5
  EMO-f1-score = 0.5
  EMO-support = 4
  HT-precision = 0.0
  HT-recall = 0.0
  HT-f1-score = 0.0
  HT-support = 4
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 1
  NOUN-precision = 0.7849079025549613
  NOUN-recall = 0.8054878048780488
  NOUN-f1-score = 0.7950647005717725
  NOUN-support = 1640
  NUM-precision = 0.8577405857740585
  NUM-recall = 0.9192825112107623
  NUM-f1-score = 0.8874458874458875
  NUM-support = 223
  PART-precision = 0.889487870619946
  PART-recall = 0.859375
  PART-f1-score = 0.8741721854304636
  PART-support = 384
  PRON-precision = 0.8666666666666667
  PRON-recall = 0.65
  PRON-f1-score = 0.7428571428571429
  PRON-support = 140
  PROPN-precision = 0.7586912065439673
  PROPN-recall = 0.7618069815195072
  PROPN-f1-score = 0.7602459016393444
  PROPN-support = 487
  PUNCT-precision = 0.9897645854657113
  PUNCT-recall = 0.9938335046248715
  PUNCT-f1-score = 0.9917948717948719
  PUNCT-support = 973
  SCONJ-precision = 0.7926829268292683
  SCONJ-recall = 0.8125
  SCONJ-f1-score = 0.8024691358024691
  SCONJ-support = 80
  SYM-precision = 0.0
  SYM-recall = 0.0
  SYM-f1-score = 0.0
  SYM-support = 3
  URL-precision = 0.0
  URL-recall = 0.0
  URL-f1-score = 0.0
  URL-support = 1
  VERB-precision = 0.7799043062200957
  VERB-recall = 0.7998037291462218
  VERB-f1-score = 0.7897286821705425
  VERB-support = 1019
  loss = 29.60579252243042
  dataset = test
