2021-07-08 05:49:32 ***** Args *****
2021-07-08 05:49:32    task: chinese_word_segmentation
2021-07-08 05:49:32    device: 0
2021-07-08 05:49:32    data: {'output_dir': '../output/canton_ws_20210708_bert_tiny', 'data_dir': '../data/datasets/canton_ws', 'train': 'train.json', 'dev': 'dev.json', 'test': 'test.json'}
2021-07-08 05:49:32    text_prepro: {'steps': ['full_to_half']}
2021-07-08 05:49:32    eval: {'batch_size': 64, 'model_file': 'model.pt'}
2021-07-08 05:49:32    train: {'model_class': 'BERT_CRF', 'kd': {'use_kd': False, 'teacher_dir': '../output/post_sentiment_20210707_bert_avg/model', 'loss_type': 'mse', 'soft_lambda': 0.5, 'kl_T': 5}, 'seed': 42, 'log_steps': 100, 'batch_size': 32, 'final_model': 'best', 'optimization_metric': 'macro_f1', 'early_stop': 5}
2021-07-08 05:49:32    explanation: {'batch_size': 8, 'model_class': 'LayerIntegratedGradients'}
2021-07-08 05:49:32    model_params: {'num_train_epochs': 15, 'embedding_trainable': True, 'tokenizer_name': 'clue/albert_chinese_tiny', 'pretrained_lm': 'clue/albert_chinese_tiny'}
2021-07-08 05:49:32 ***** Loading tokenizer *****
2021-07-08 05:49:32   Tokenizer source = 'transformers'
2021-07-08 05:49:36 ***** Initializing model *****
2021-07-08 05:49:36   Task = chinese_word_segmentation
2021-07-08 05:49:36   Model class = BERT_CRF
2021-07-08 05:49:43 ***** Loading data *****
2021-07-08 05:49:43   Data path = ../data/datasets/canton_ws/test.json
2021-07-08 05:49:44   Loaded samples = 245
2021-07-08 05:49:44 ***** Running evaluation *****
2021-07-08 05:49:44   Num examples = 245
2021-07-08 05:49:44   Batch size = 64
2021-07-08 05:49:47   macro_f1 = 0.845138241689966
2021-07-08 05:49:47   micro_f1 = 0.845138241689966
2021-07-08 05:49:47   support = 6401
2021-07-08 05:49:47   O-precision = 0.8403088803088803
2021-07-08 05:49:47   O-recall = 0.8500234338384628
2021-07-08 05:49:47   O-f1-score = 0.845138241689966
2021-07-08 05:49:47   O-support = 6401
2021-07-08 05:49:47   loss = 8.32294487953186
2021-07-08 05:49:47   dataset = test
2021-07-08 05:49:48 ***** Running explanation *****
2021-07-08 05:49:48   Num examples = 245
