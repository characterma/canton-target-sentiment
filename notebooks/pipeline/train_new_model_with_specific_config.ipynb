{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import scrapbook as sb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "src_dir = \"../../src\"  # Ignore this!\n",
    "\n",
    "# Pipeline settings\n",
    "task = \"sequence_classification\"  # chinese_word_segmentation OR target_classification, OR sequence_classification\n",
    "model = 'BERT_CLS'  # None: Default model \n",
    "device = 0\n",
    "text_prepro = None  # None: Default steps \n",
    "\n",
    "model_params = {\n",
    "    'num_train_epochs': 5, \n",
    "    'max_length': 256,\n",
    "#     'tokenizer_name': \"bert-base-chinese\" \n",
    "#     'pretrained_lm': \"bert-base-chinese\" \n",
    "#     'embedding_trainable': True, \n",
    "#     'output_hidden_act_func': \"PReLU\", \n",
    "#     'output_hidden_dim': 128, \n",
    "#     'output_use_bn': False, \n",
    "#     'optimizer': \"AdamW\",\n",
    "#     'learning_rate': 2e-5,\n",
    "#     'weight_decay': 0.0,\n",
    "#     'gradient_accumulation_steps': 1,\n",
    "#     'adam_epsilon': 1e-8,\n",
    "#     'max_grad_norm': 1.0,\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 16, \n",
    "    'seed': 42, \n",
    "    'optimization_metric': \"macro_f1\", \n",
    "    'early_stop': None\n",
    "}\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "model_dir = f\"../output/test_pipeline_{task}_tmp\"  # output dir for new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(src_dir)\n",
    "from pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '<p> zaia係咩, 我都想睇水舞間, 朋友睇完都話好睇!', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "dev_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "test_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "print(train_raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:22 ***** Model class is specified for sequence_classification. *****\n",
      "2021-11-29 02:22:22   Model = BERT_CLS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/examples/sequence_classification/BERT_CLS\n",
      "['.ipynb_checkpoints', 'model', 'result', 'logs', 'run.yaml']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    task=task, \n",
    "    model=model, \n",
    "    device=device, \n",
    "    text_prepro=text_prepro\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:23 ***** Initializing pipeline *****\n",
      "2021-11-29 02:22:23 ***** Loading tokenizer *****\n",
      "2021-11-29 02:22:23   Tokenizer source = 'transformers'\n",
      "2021-11-29 02:22:23 ***** Initializing model *****\n",
      "2021-11-29 02:22:23   Task = sequence_classification\n",
      "2021-11-29 02:22:23   Model class = BERT_CLS\n",
      "2021-11-29 02:22:23   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenizer', 'label_to_id.json', 'model.pt', 'run.yaml', 'model.yaml']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:32 ***** Loading data *****\n",
      "2021-11-29 02:22:32   Raw data is provided.\n",
      "3it [00:00, 86.38it/s]\n",
      "2021-11-29 02:22:32   Loaded samples = 3\n",
      "2021-11-29 02:22:32 ***** Loading data *****\n",
      "2021-11-29 02:22:32   Raw data is provided.\n",
      "3it [00:00, 131.16it/s]\n",
      "2021-11-29 02:22:32   Loaded samples = 3\n",
      "2021-11-29 02:22:32 ***** Running training *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Num Epochs = 5\n",
      "2021-11-29 02:22:32   Sampler = \n",
      "2021-11-29 02:22:32   Batch size = 16\n",
      "2021-11-29 02:22:32   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.619]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, tr_loss=0.619]\u001b[A\n",
      "2021-11-29 02:22:32 ***** Epoch end: 0 *****\n",
      "2021-11-29 02:22:32 ***** Running evaluation *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 46.50it/s]\n",
      "2021-11-29 02:22:32   accuracy = 1.0\n",
      "2021-11-29 02:22:32   macro_f1 = 1.0\n",
      "2021-11-29 02:22:32   micro_f1 = 1.0\n",
      "2021-11-29 02:22:32   support = 3\n",
      "2021-11-29 02:22:32   -1-precision = 1.0\n",
      "2021-11-29 02:22:32   -1-recall = 1.0\n",
      "2021-11-29 02:22:32   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   -1-support = 1\n",
      "2021-11-29 02:22:32   0-precision = 1.0\n",
      "2021-11-29 02:22:32   0-recall = 1.0\n",
      "2021-11-29 02:22:32   0-f1-score = 1.0\n",
      "2021-11-29 02:22:32   0-support = 1\n",
      "2021-11-29 02:22:32   1-precision = 1.0\n",
      "2021-11-29 02:22:32   1-recall = 1.0\n",
      "2021-11-29 02:22:32   1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   1-support = 1\n",
      "2021-11-29 02:22:32   loss = 0.49821820855140686\n",
      "2021-11-29 02:22:32   dataset = dev\n",
      "Epoch:  20%|██        | 1/5 [00:00<00:00,  5.25it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.701]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, tr_loss=0.701]\u001b[A\n",
      "2021-11-29 02:22:32 ***** Epoch end: 1 *****\n",
      "2021-11-29 02:22:32 ***** Running evaluation *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 45.54it/s]\n",
      "2021-11-29 02:22:32   accuracy = 1.0\n",
      "2021-11-29 02:22:32   macro_f1 = 1.0\n",
      "2021-11-29 02:22:32   micro_f1 = 1.0\n",
      "2021-11-29 02:22:32   support = 3\n",
      "2021-11-29 02:22:32   -1-precision = 1.0\n",
      "2021-11-29 02:22:32   -1-recall = 1.0\n",
      "2021-11-29 02:22:32   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   -1-support = 1\n",
      "2021-11-29 02:22:32   0-precision = 1.0\n",
      "2021-11-29 02:22:32   0-recall = 1.0\n",
      "2021-11-29 02:22:32   0-f1-score = 1.0\n",
      "2021-11-29 02:22:32   0-support = 1\n",
      "2021-11-29 02:22:32   1-precision = 1.0\n",
      "2021-11-29 02:22:32   1-recall = 1.0\n",
      "2021-11-29 02:22:32   1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   1-support = 1\n",
      "2021-11-29 02:22:32   loss = 0.40934228897094727\n",
      "2021-11-29 02:22:32   dataset = dev\n",
      "Epoch:  40%|████      | 2/5 [00:00<00:00,  5.52it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, tr_loss=0.399]\n",
      "2021-11-29 02:22:32 ***** Epoch end: 2 *****\n",
      "2021-11-29 02:22:32 ***** Running evaluation *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.46it/s]\n",
      "2021-11-29 02:22:32   accuracy = 1.0\n",
      "2021-11-29 02:22:32   macro_f1 = 1.0\n",
      "2021-11-29 02:22:32   micro_f1 = 1.0\n",
      "2021-11-29 02:22:32   support = 3\n",
      "2021-11-29 02:22:32   -1-precision = 1.0\n",
      "2021-11-29 02:22:32   -1-recall = 1.0\n",
      "2021-11-29 02:22:32   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   -1-support = 1\n",
      "2021-11-29 02:22:32   0-precision = 1.0\n",
      "2021-11-29 02:22:32   0-recall = 1.0\n",
      "2021-11-29 02:22:32   0-f1-score = 1.0\n",
      "2021-11-29 02:22:32   0-support = 1\n",
      "2021-11-29 02:22:32   1-precision = 1.0\n",
      "2021-11-29 02:22:32   1-recall = 1.0\n",
      "2021-11-29 02:22:32   1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   1-support = 1\n",
      "2021-11-29 02:22:32   loss = 0.3296729624271393\n",
      "2021-11-29 02:22:32   dataset = dev\n",
      "Epoch:  60%|██████    | 3/5 [00:00<00:00,  5.91it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.437]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, tr_loss=0.437]\u001b[A\n",
      "2021-11-29 02:22:33 ***** Epoch end: 3 *****\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 48.07it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.28001585602760315\n",
      "2021-11-29 02:22:33   dataset = dev\n",
      "Epoch:  80%|████████  | 4/5 [00:00<00:00,  6.09it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, tr_loss=0.438]\n",
      "2021-11-29 02:22:33 ***** Epoch end: 4 *****\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 48.01it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.25824984908103943\n",
      "2021-11-29 02:22:33   dataset = dev\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n",
      "2021-11-29 02:22:33 ***** Training end *****\n",
      "2021-11-29 02:22:33   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BERT_CLS. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline.train(\n",
    "    model_dir, \n",
    "    train_raw_data=train_raw_data, \n",
    "    dev_raw_data=dev_raw_data, \n",
    "    model_params=model_params,\n",
    "    train_params=train_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:33 ***** Loading data *****\n",
      "2021-11-29 02:22:33   Raw data is provided.\n",
      "3it [00:00, 117.46it/s]\n",
      "2021-11-29 02:22:33   Loaded samples = 3\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 32\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 46.04it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.49821820855140686\n",
      "2021-11-29 02:22:33   dataset = train\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 32\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 48.07it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.49821820855140686\n",
      "2021-11-29 02:22:33   dataset = dev\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 32\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.27it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.49821820855140686\n",
      "2021-11-29 02:22:33   dataset = test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = pipeline.test(\n",
    "    test_raw_data=test_raw_data,\n",
    "    eval_params=eval_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:50:57 ***** Existing model is provided. *****\n",
      "2021-11-29 02:50:57   Model directory = ../output/test_pipeline_sequence_classification_tmp\n",
      "2021-11-29 02:50:57 ***** Initializing pipeline *****\n",
      "2021-11-29 02:50:57 ***** Loading tokenizer *****\n",
      "2021-11-29 02:50:57   Tokenizer source = 'transformers'\n",
      "2021-11-29 02:50:57 ***** Initializing model *****\n",
      "2021-11-29 02:50:57   Task = sequence_classification\n",
      "2021-11-29 02:50:57   Model class = BERT_CLS\n",
      "2021-11-29 02:50:57   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/test_pipeline_sequence_classification_tmp/model\n",
      "['tokenizer', 'label_to_id.json', 'model.pt', 'run.yaml', 'model.yaml']\n",
      "['tokenizer', 'label_to_id.json', 'model.pt', 'run.yaml', 'model.yaml']\n",
      "Input:\n",
      "{'content': '<p> zaia係咩, 我都想睇水舞間, 朋友睇完都話好睇!', 'label': 1}\n",
      "Output:\n",
      "{'prediction_id': 0, 'prediction': '1'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    model_dir=model_dir, \n",
    "    device=device, \n",
    ")\n",
    "\n",
    "print(\"Input:\")\n",
    "print(test_raw_data[0])\n",
    "\n",
    "output = pipeline.predict(\n",
    "    data_dict=test_raw_data[0],\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "scores = pipeline.explain(\n",
    "    data_dict=test_raw_data[0],\n",
    "    method='IntegratedGradients',\n",
    "    layer='pretrained_model.embeddings.word_embeddings', \n",
    "    norm='l2'\n",
    ")\n",
    "\n",
    "# print(scores)\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 0.02911902405321598),\n",
       " ('<', 0.020030846819281578),\n",
       " ('p', 0.0189193207770586),\n",
       " ('>', 0.018668590113520622),\n",
       " ('z', 0.014856795780360699),\n",
       " ('##ai', 0.015659550204873085),\n",
       " ('##a', 0.015582692809402943),\n",
       " ('系', 0.016651133075356483),\n",
       " ('咩', 0.024479681625962257),\n",
       " (',', 0.016806714236736298),\n",
       " ('我', 0.01255938783288002),\n",
       " ('都', 0.012607353739440441),\n",
       " ('想', 0.016966380178928375),\n",
       " ('睇', 0.018306516110897064),\n",
       " ('水', 0.017799602821469307),\n",
       " ('舞', 0.021416891366243362),\n",
       " ('间', 0.01682175137102604),\n",
       " (',', 0.01767466403543949),\n",
       " ('朋', 0.011837850324809551),\n",
       " ('友', 0.011017942801117897),\n",
       " ('睇', 0.01700235903263092),\n",
       " ('完', 0.015345368534326553),\n",
       " ('都', 0.01331076119095087),\n",
       " ('话', 0.013242393732070923),\n",
       " ('好', 0.012461753562092781),\n",
       " ('睇', 0.021983789280056953),\n",
       " ('!', 0.026536865159869194),\n",
       " ('[SEP]', 0.0717211440205574)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "\n",
    "def show_text_attr(scores):\n",
    "    rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "    alpha = lambda x: abs(x) ** 0.5\n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in scores\n",
    "    ]\n",
    "    \n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.17064297246946908)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,0.14153037419325076)\"><</mark> <mark style=\"background-color:rgba(0,255,0,0.137547521886287)\">p</mark> <mark style=\"background-color:rgba(0,255,0,0.1366330491261928)\">></mark> <mark style=\"background-color:rgba(0,255,0,0.12188845630477359)\">z</mark> <mark style=\"background-color:rgba(0,255,0,0.12513812450597572)\">##ai</mark> <mark style=\"background-color:rgba(0,255,0,0.12483065652876678)\">##a</mark> <mark style=\"background-color:rgba(0,255,0,0.12903926950876807)\">系</mark> <mark style=\"background-color:rgba(0,255,0,0.15645984029763757)\">咩</mark> <mark style=\"background-color:rgba(0,255,0,0.1296407121113437)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.11206867462801556)\">我</mark> <mark style=\"background-color:rgba(0,255,0,0.1122824729841681)\">都</mark> <mark style=\"background-color:rgba(0,255,0,0.13025505817022376)\">想</mark> <mark style=\"background-color:rgba(0,255,0,0.13530157468003493)\">睇</mark> <mark style=\"background-color:rgba(0,255,0,0.1334151521434852)\">水</mark> <mark style=\"background-color:rgba(0,255,0,0.14634511049653612)\">舞</mark> <mark style=\"background-color:rgba(0,255,0,0.1296986945617651)\">间</mark> <mark style=\"background-color:rgba(0,255,0,0.13294609447230668)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.1088018856675267)\">朋</mark> <mark style=\"background-color:rgba(0,255,0,0.1049663889114887)\">友</mark> <mark style=\"background-color:rgba(0,255,0,0.1303930942674148)\">睇</mark> <mark style=\"background-color:rgba(0,255,0,0.1238764244492331)\">完</mark> <mark style=\"background-color:rgba(0,255,0,0.11537227219289248)\">都</mark> <mark style=\"background-color:rgba(0,255,0,0.11507560007260846)\">话</mark> <mark style=\"background-color:rgba(0,255,0,0.11163222456841385)\">好</mark> <mark style=\"background-color:rgba(0,255,0,0.14826931334587395)\">睇</mark> <mark style=\"background-color:rgba(0,255,0,0.1629013970470149)\">!</mark> <mark style=\"background-color:rgba(0,255,0,0.2678080357654665)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_text_attr(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d35f7baa4e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 1,
       "encoder": "json",
       "name": "macro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "macro_f1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 1,
       "encoder": "json",
       "name": "micro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "micro_f1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue(\"macro_f1\", metrics['macro_f1'])\n",
    "sb.glue(\"micro_f1\", metrics['micro_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
