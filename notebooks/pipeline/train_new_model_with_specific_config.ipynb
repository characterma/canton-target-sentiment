{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import scrapbook as sb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "src_dir = \"../../src\"  # Ignore this!\n",
    "\n",
    "# Pipeline settings\n",
    "task = \"chinese_word_segmentation\"  # chinese_word_segmentation OR target_classification, OR sequence_classification\n",
    "model = None  # None: Default model \n",
    "device = 0\n",
    "text_prepro = None  # None: Default steps \n",
    "model_params = {'num_train_epochs': 15}\n",
    "train_params = {'batch_size': 16}\n",
    "eval_params = {'batch_size': 32}\n",
    "model_dir = \"../output/test_pipeline_tmp\"  # output dir for new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c3666d5ffcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'src_dir' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(src_dir)\n",
    "from pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'docid': 'S_00000235', 'content': '佢指，最大機會係有患者進入街市，經佢嘅糞便或者口水傳播，但究竟點傳播，係因為口水或者係由老鼠將病毒帶到四周圍，暫時未知道。', 'words': ['佢', '指', '，', '最', '大', '機會', '係', '有', '患者', '進入', '街市', '，', '經', '佢', '嘅', '糞便', '或者', '口水', '傳播', '，', '但', '究竟', '點', '傳播', '，', '係', '因為', '口水', '或者', '係', '由', '老鼠', '將', '病毒', '帶', '到', '四周圍', '，', '暫時', '未', '知道', '。'], 'postags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'sent_indexs': [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 7], [7, 8], [8, 9], [9, 11], [11, 13], [13, 15], [15, 16], [16, 17], [17, 18], [18, 19], [19, 21], [21, 23], [23, 25], [25, 27], [27, 28], [28, 29], [29, 31], [31, 32], [32, 34], [34, 35], [35, 36], [36, 38], [38, 40], [40, 42], [42, 43], [43, 44], [44, 46], [46, 47], [47, 49], [49, 50], [50, 51], [51, 54], [54, 55], [55, 57], [57, 58], [58, 60], [60, 61]]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "dev_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "test_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "print(train_raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 01:32:22 ***** Model class is not provided for chinese_word_segmentation. *****\n",
      "2021-11-25 01:32:22   Default model = BERT_CRF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/examples/chinese_word_segmentation/BERT_CRF\n",
      "['.ipynb_checkpoints', 'run.yaml', 'model', 'result', 'logs']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    task=task, \n",
    "    model=model, \n",
    "    device=device, \n",
    "    text_prepro=text_prepro\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 01:32:24 ***** Initializing pipeline *****\n",
      "2021-11-25 01:32:24 ***** Loading tokenizer *****\n",
      "2021-11-25 01:32:24   Tokenizer source = 'transformers'\n",
      "2021-11-25 01:32:26 ***** Initializing model *****\n",
      "2021-11-25 01:32:26   Task = chinese_word_segmentation\n",
      "2021-11-25 01:32:26   Model class = BERT_CRF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenizer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 01:32:27 ***** Loading pretrained language model *****\n",
      "2021-11-25 01:32:27   Pretrained BERT = 'bert-base-chinese'\n",
      "2021-11-25 01:32:39 ***** Loading data *****\n",
      "2021-11-25 01:32:39   Raw data is provided.\n",
      "32it [00:00, 227.13it/s]\n",
      "2021-11-25 01:32:39   Loaded samples = 32\n",
      "2021-11-25 01:32:39 ***** Loading data *****\n",
      "2021-11-25 01:32:39   Raw data is provided.\n",
      "32it [00:00, 172.57it/s]\n",
      "2021-11-25 01:32:39   Loaded samples = 32\n",
      "2021-11-25 01:32:39 ***** Running training *****\n",
      "2021-11-25 01:32:39   Num examples = 32\n",
      "2021-11-25 01:32:39   Num Epochs = 15\n",
      "2021-11-25 01:32:39   Sampler = \n",
      "2021-11-25 01:32:39   Batch size = 16\n",
      "2021-11-25 01:32:39   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=43.5]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.56it/s, tr_loss=43.5]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.56it/s, tr_loss=47.1]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.57it/s, tr_loss=47.1]\u001b[A\n",
      "2021-11-25 01:32:40 ***** Epoch end: 0 *****\n",
      "2021-11-25 01:32:40 ***** Running evaluation *****\n",
      "2021-11-25 01:32:40   Num examples = 32\n",
      "2021-11-25 01:32:40   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\u001b[A\n",
      "2021-11-25 01:32:41   macro_f1 = 0.49410698096101535\n",
      "2021-11-25 01:32:41   micro_f1 = 0.4941069809610153\n",
      "2021-11-25 01:32:41   support = 884\n",
      "2021-11-25 01:32:41   O-precision = 0.4122541603630862\n",
      "2021-11-25 01:32:41   O-recall = 0.6165158371040724\n",
      "2021-11-25 01:32:41   O-f1-score = 0.49410698096101535\n",
      "2021-11-25 01:32:41   O-support = 884\n",
      "2021-11-25 01:32:41   loss = 35.27431869506836\n",
      "2021-11-25 01:32:41   dataset = dev\n",
      "Epoch:   7%|▋         | 1/15 [00:02<00:33,  2.40s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=36.8]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.59it/s, tr_loss=36.8]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.59it/s, tr_loss=31.8]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s, tr_loss=31.8]\u001b[A\n",
      "2021-11-25 01:32:43 ***** Epoch end: 1 *****\n",
      "2021-11-25 01:32:43 ***** Running evaluation *****\n",
      "2021-11-25 01:32:43   Num examples = 32\n",
      "2021-11-25 01:32:43   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\u001b[A\n",
      "2021-11-25 01:32:44   macro_f1 = 0.5078776645041705\n",
      "2021-11-25 01:32:44   micro_f1 = 0.5078776645041705\n",
      "2021-11-25 01:32:44   support = 884\n",
      "2021-11-25 01:32:44   O-precision = 0.4301412872841444\n",
      "2021-11-25 01:32:44   O-recall = 0.6199095022624435\n",
      "2021-11-25 01:32:44   O-f1-score = 0.5078776645041705\n",
      "2021-11-25 01:32:44   O-support = 884\n",
      "2021-11-25 01:32:44   loss = 28.05567741394043\n",
      "2021-11-25 01:32:44   dataset = dev\n",
      "Epoch:  13%|█▎        | 2/15 [00:05<00:33,  2.59s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=31.4]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.60it/s, tr_loss=31.4]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.60it/s, tr_loss=25]  \u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s, tr_loss=25]\u001b[A\n",
      "2021-11-25 01:32:46 ***** Epoch end: 2 *****\n",
      "2021-11-25 01:32:46 ***** Running evaluation *****\n",
      "2021-11-25 01:32:46   Num examples = 32\n",
      "2021-11-25 01:32:46   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\u001b[A\n",
      "2021-11-25 01:32:47   macro_f1 = 0.6356275303643726\n",
      "2021-11-25 01:32:47   micro_f1 = 0.6356275303643726\n",
      "2021-11-25 01:32:47   support = 884\n",
      "2021-11-25 01:32:47   O-precision = 0.575091575091575\n",
      "2021-11-25 01:32:47   O-recall = 0.7104072398190046\n",
      "2021-11-25 01:32:47   O-f1-score = 0.6356275303643726\n",
      "2021-11-25 01:32:47   O-support = 884\n",
      "2021-11-25 01:32:47   loss = 23.037792205810547\n",
      "2021-11-25 01:32:47   dataset = dev\n",
      "Epoch:  20%|██        | 3/15 [00:08<00:31,  2.60s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=26]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.57it/s, tr_loss=26]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.57it/s, tr_loss=21.2]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.56it/s, tr_loss=21.2]\u001b[A\n",
      "2021-11-25 01:32:48 ***** Epoch end: 3 *****\n",
      "2021-11-25 01:32:48 ***** Running evaluation *****\n",
      "2021-11-25 01:32:48   Num examples = 32\n",
      "2021-11-25 01:32:48   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\u001b[A\n",
      "2021-11-25 01:32:49   macro_f1 = 0.72\n",
      "2021-11-25 01:32:49   micro_f1 = 0.72\n",
      "2021-11-25 01:32:49   support = 884\n",
      "2021-11-25 01:32:49   O-precision = 0.6657060518731989\n",
      "2021-11-25 01:32:49   O-recall = 0.7839366515837104\n",
      "2021-11-25 01:32:49   O-f1-score = 0.72\n",
      "2021-11-25 01:32:49   O-support = 884\n",
      "2021-11-25 01:32:49   loss = 19.014102935791016\n",
      "2021-11-25 01:32:49   dataset = dev\n",
      "Epoch:  27%|██▋       | 4/15 [00:10<00:28,  2.60s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=19.9]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.51it/s, tr_loss=19.9]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.51it/s, tr_loss=19.5]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s, tr_loss=19.5]\u001b[A\n",
      "2021-11-25 01:32:51 ***** Epoch end: 4 *****\n",
      "2021-11-25 01:32:51 ***** Running evaluation *****\n",
      "2021-11-25 01:32:51   Num examples = 32\n",
      "2021-11-25 01:32:51   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\u001b[A\n",
      "2021-11-25 01:32:52   macro_f1 = 0.7745302713987473\n",
      "2021-11-25 01:32:52   micro_f1 = 0.7745302713987472\n",
      "2021-11-25 01:32:52   support = 884\n",
      "2021-11-25 01:32:52   O-precision = 0.7189922480620154\n",
      "2021-11-25 01:32:52   O-recall = 0.8393665158371041\n",
      "2021-11-25 01:32:52   O-f1-score = 0.7745302713987473\n",
      "2021-11-25 01:32:52   O-support = 884\n",
      "2021-11-25 01:32:52   loss = 15.451005935668945\n",
      "2021-11-25 01:32:52   dataset = dev\n",
      "Epoch:  33%|███▎      | 5/15 [00:13<00:25,  2.60s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=18]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.62it/s, tr_loss=18]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.62it/s, tr_loss=14.8]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s, tr_loss=14.8]\u001b[A\n",
      "2021-11-25 01:32:54 ***** Epoch end: 5 *****\n",
      "2021-11-25 01:32:54 ***** Running evaluation *****\n",
      "2021-11-25 01:32:54   Num examples = 32\n",
      "2021-11-25 01:32:54   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\u001b[A\n",
      "2021-11-25 01:32:54   macro_f1 = 0.8677595628415301\n",
      "2021-11-25 01:32:54   micro_f1 = 0.8677595628415301\n",
      "2021-11-25 01:32:54   support = 884\n",
      "2021-11-25 01:32:54   O-precision = 0.8393234672304439\n",
      "2021-11-25 01:32:54   O-recall = 0.8981900452488688\n",
      "2021-11-25 01:32:54   O-f1-score = 0.8677595628415301\n",
      "2021-11-25 01:32:54   O-support = 884\n",
      "2021-11-25 01:32:54   loss = 11.772443771362305\n",
      "2021-11-25 01:32:54   dataset = dev\n",
      "Epoch:  40%|████      | 6/15 [00:15<00:23,  2.56s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=13.1]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.64it/s, tr_loss=13.1]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.64it/s, tr_loss=12.1]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s, tr_loss=12.1]\u001b[A\n",
      "2021-11-25 01:32:56 ***** Epoch end: 6 *****\n",
      "2021-11-25 01:32:56 ***** Running evaluation *****\n",
      "2021-11-25 01:32:56   Num examples = 32\n",
      "2021-11-25 01:32:56   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\u001b[A\n",
      "2021-11-25 01:32:57   macro_f1 = 0.9208309938236946\n",
      "2021-11-25 01:32:57   micro_f1 = 0.9208309938236946\n",
      "2021-11-25 01:32:57   support = 884\n",
      "2021-11-25 01:32:57   O-precision = 0.9141583054626533\n",
      "2021-11-25 01:32:57   O-recall = 0.9276018099547512\n",
      "2021-11-25 01:32:57   O-f1-score = 0.9208309938236946\n",
      "2021-11-25 01:32:57   O-support = 884\n",
      "2021-11-25 01:32:57   loss = 8.645366668701172\n",
      "2021-11-25 01:32:57   dataset = dev\n",
      "Epoch:  47%|████▋     | 7/15 [00:18<00:20,  2.56s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=11.4]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.61it/s, tr_loss=11.4]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.61it/s, tr_loss=7.42]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.57it/s, tr_loss=7.42]\u001b[A\n",
      "2021-11-25 01:32:59 ***** Epoch end: 7 *****\n",
      "2021-11-25 01:32:59 ***** Running evaluation *****\n",
      "2021-11-25 01:32:59   Num examples = 32\n",
      "2021-11-25 01:32:59   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\u001b[A\n",
      "2021-11-25 01:32:59   macro_f1 = 0.9319842608206858\n",
      "2021-11-25 01:32:59   micro_f1 = 0.9319842608206858\n",
      "2021-11-25 01:32:59   support = 884\n",
      "2021-11-25 01:32:59   O-precision = 0.9262569832402234\n",
      "2021-11-25 01:32:59   O-recall = 0.9377828054298643\n",
      "2021-11-25 01:32:59   O-f1-score = 0.9319842608206858\n",
      "2021-11-25 01:32:59   O-support = 884\n",
      "2021-11-25 01:32:59   loss = 5.982212066650391\n",
      "2021-11-25 01:32:59   dataset = dev\n",
      "Epoch:  53%|█████▎    | 8/15 [00:20<00:17,  2.54s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=7.14]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.64it/s, tr_loss=7.14]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.64it/s, tr_loss=6.84]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s, tr_loss=6.84]\u001b[A\n",
      "2021-11-25 01:33:01 ***** Epoch end: 8 *****\n",
      "2021-11-25 01:33:01 ***** Running evaluation *****\n",
      "2021-11-25 01:33:01   Num examples = 32\n",
      "2021-11-25 01:33:01   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
      "2021-11-25 01:33:02   macro_f1 = 0.9409116488463702\n",
      "2021-11-25 01:33:02   micro_f1 = 0.9409116488463702\n",
      "2021-11-25 01:33:02   support = 884\n",
      "2021-11-25 01:33:02   O-precision = 0.9361702127659575\n",
      "2021-11-25 01:33:02   O-recall = 0.9457013574660633\n",
      "2021-11-25 01:33:02   O-f1-score = 0.9409116488463702\n",
      "2021-11-25 01:33:02   O-support = 884\n",
      "2021-11-25 01:33:02   loss = 4.239134788513184\n",
      "2021-11-25 01:33:02   dataset = dev\n",
      "Epoch:  60%|██████    | 9/15 [00:23<00:15,  2.53s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=5.56]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.52it/s, tr_loss=5.56]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.52it/s, tr_loss=5.38]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.57it/s, tr_loss=5.38]\u001b[A\n",
      "2021-11-25 01:33:04 ***** Epoch end: 9 *****\n",
      "2021-11-25 01:33:04 ***** Running evaluation *****\n",
      "2021-11-25 01:33:04   Num examples = 32\n",
      "2021-11-25 01:33:04   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\u001b[A\n",
      "2021-11-25 01:33:04   macro_f1 = 0.9508196721311475\n",
      "2021-11-25 01:33:04   micro_f1 = 0.9508196721311475\n",
      "2021-11-25 01:33:04   support = 884\n",
      "2021-11-25 01:33:04   O-precision = 0.9502824858757062\n",
      "2021-11-25 01:33:04   O-recall = 0.9513574660633484\n",
      "2021-11-25 01:33:04   O-f1-score = 0.9508196721311475\n",
      "2021-11-25 01:33:04   O-support = 884\n",
      "2021-11-25 01:33:04   loss = 2.9481043815612793\n",
      "2021-11-25 01:33:04   dataset = dev\n",
      "Epoch:  67%|██████▋   | 10/15 [00:25<00:12,  2.53s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=3.74]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.63it/s, tr_loss=3.74]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.63it/s, tr_loss=3.54]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s, tr_loss=3.54]\u001b[A\n",
      "2021-11-25 01:33:06 ***** Epoch end: 10 *****\n",
      "2021-11-25 01:33:06 ***** Running evaluation *****\n",
      "2021-11-25 01:33:06   Num examples = 32\n",
      "2021-11-25 01:33:06   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\u001b[A\n",
      "2021-11-25 01:33:07   macro_f1 = 0.9711048158640226\n",
      "2021-11-25 01:33:07   micro_f1 = 0.9711048158640226\n",
      "2021-11-25 01:33:07   support = 884\n",
      "2021-11-25 01:33:07   O-precision = 0.9727582292849035\n",
      "2021-11-25 01:33:07   O-recall = 0.9694570135746606\n",
      "2021-11-25 01:33:07   O-f1-score = 0.9711048158640226\n",
      "2021-11-25 01:33:07   O-support = 884\n",
      "2021-11-25 01:33:07   loss = 1.9133050441741943\n",
      "2021-11-25 01:33:07   dataset = dev\n",
      "Epoch:  73%|███████▎  | 11/15 [00:28<00:10,  2.52s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=2.37]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.55it/s, tr_loss=2.37]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.55it/s, tr_loss=2.32]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s, tr_loss=2.32]\u001b[A\n",
      "2021-11-25 01:33:09 ***** Epoch end: 11 *****\n",
      "2021-11-25 01:33:09 ***** Running evaluation *****\n",
      "2021-11-25 01:33:09   Num examples = 32\n",
      "2021-11-25 01:33:09   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\u001b[A\n",
      "2021-11-25 01:33:10   macro_f1 = 0.9813664596273292\n",
      "2021-11-25 01:33:10   micro_f1 = 0.9813664596273292\n",
      "2021-11-25 01:33:10   support = 884\n",
      "2021-11-25 01:33:10   O-precision = 0.979706877113867\n",
      "2021-11-25 01:33:10   O-recall = 0.9830316742081447\n",
      "2021-11-25 01:33:10   O-f1-score = 0.9813664596273292\n",
      "2021-11-25 01:33:10   O-support = 884\n",
      "2021-11-25 01:33:10   loss = 1.0586302280426025\n",
      "2021-11-25 01:33:10   dataset = dev\n",
      "Epoch:  80%|████████  | 12/15 [00:30<00:07,  2.54s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=1.71]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.61it/s, tr_loss=1.71]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.61it/s, tr_loss=1.66]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s, tr_loss=1.66]\u001b[A\n",
      "2021-11-25 01:33:11 ***** Epoch end: 12 *****\n",
      "2021-11-25 01:33:11 ***** Running evaluation *****\n",
      "2021-11-25 01:33:11   Num examples = 32\n",
      "2021-11-25 01:33:11   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\u001b[A\n",
      "2021-11-25 01:33:13   macro_f1 = 0.9949066213921903\n",
      "2021-11-25 01:33:13   micro_f1 = 0.9949066213921904\n",
      "2021-11-25 01:33:13   support = 884\n",
      "2021-11-25 01:33:13   O-precision = 0.9954699886749717\n",
      "2021-11-25 01:33:13   O-recall = 0.994343891402715\n",
      "2021-11-25 01:33:13   O-f1-score = 0.9949066213921903\n",
      "2021-11-25 01:33:13   O-support = 884\n",
      "2021-11-25 01:33:13   loss = 0.6192595958709717\n",
      "2021-11-25 01:33:13   dataset = dev\n",
      "Epoch:  87%|████████▋ | 13/15 [00:33<00:05,  2.65s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=1.16]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.60it/s, tr_loss=1.16]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.60it/s, tr_loss=0.996]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s, tr_loss=0.996]\u001b[A\n",
      "2021-11-25 01:33:14 ***** Epoch end: 13 *****\n",
      "2021-11-25 01:33:14 ***** Running evaluation *****\n",
      "2021-11-25 01:33:14   Num examples = 32\n",
      "2021-11-25 01:33:14   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\u001b[A\n",
      "2021-11-25 01:33:15   macro_f1 = 0.9966024915062287\n",
      "2021-11-25 01:33:15   micro_f1 = 0.9966024915062287\n",
      "2021-11-25 01:33:15   support = 884\n",
      "2021-11-25 01:33:15   O-precision = 0.9977324263038548\n",
      "2021-11-25 01:33:15   O-recall = 0.995475113122172\n",
      "2021-11-25 01:33:15   O-f1-score = 0.9966024915062287\n",
      "2021-11-25 01:33:15   O-support = 884\n",
      "2021-11-25 01:33:15   loss = 0.44840025901794434\n",
      "2021-11-25 01:33:15   dataset = dev\n",
      "Epoch:  93%|█████████▎| 14/15 [00:36<00:02,  2.58s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s, tr_loss=0.832]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:00<00:00,  1.60it/s, tr_loss=0.832]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:00,  1.60it/s, tr_loss=0.739]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s, tr_loss=0.739]\u001b[A\n",
      "2021-11-25 01:33:17 ***** Epoch end: 14 *****\n",
      "2021-11-25 01:33:17 ***** Running evaluation *****\n",
      "2021-11-25 01:33:17   Num examples = 32\n",
      "2021-11-25 01:33:17   Batch size = 64\n",
      "\n",
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\u001b[A\n",
      "2021-11-25 01:33:18   macro_f1 = 1.0\n",
      "2021-11-25 01:33:18   micro_f1 = 1.0\n",
      "2021-11-25 01:33:18   support = 884\n",
      "2021-11-25 01:33:18   O-precision = 1.0\n",
      "2021-11-25 01:33:18   O-recall = 1.0\n",
      "2021-11-25 01:33:18   O-f1-score = 1.0\n",
      "2021-11-25 01:33:18   O-support = 884\n",
      "2021-11-25 01:33:18   loss = 0.2163243293762207\n",
      "2021-11-25 01:33:18   dataset = dev\n",
      "Epoch: 100%|██████████| 15/15 [00:38<00:00,  2.58s/it]\n",
      "2021-11-25 01:33:18 ***** Training end *****\n",
      "2021-11-25 01:33:18   Model path = ../output/test_pipeline_tmp/model/model.pt\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BERT_CRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LinearChainCRF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline.train(\n",
    "    model_dir, \n",
    "    train_raw_data=train_raw_data, \n",
    "    dev_raw_data=dev_raw_data, \n",
    "    model_params=model_params,\n",
    "    train_params=train_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 01:16:31 ***** Loading data *****\n",
      "2021-11-25 01:16:31   Raw data is provided.\n",
      "32it [00:00, 211.66it/s]\n",
      "2021-11-25 01:16:31   Loaded samples = 32\n",
      "2021-11-25 01:16:31 ***** Running evaluation *****\n",
      "2021-11-25 01:16:31   Num examples = 32\n",
      "2021-11-25 01:16:31   Batch size = 32\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "2021-11-25 01:16:32   macro_f1 = 0.9983041266252121\n",
      "2021-11-25 01:16:32   micro_f1 = 0.9983041266252121\n",
      "2021-11-25 01:16:32   support = 884\n",
      "2021-11-25 01:16:32   O-precision = 0.9977401129943503\n",
      "2021-11-25 01:16:32   O-recall = 0.998868778280543\n",
      "2021-11-25 01:16:32   O-f1-score = 0.9983041266252121\n",
      "2021-11-25 01:16:32   O-support = 884\n",
      "2021-11-25 01:16:32   loss = 0.4514961242675781\n",
      "2021-11-25 01:16:32   dataset = train\n",
      "2021-11-25 01:16:32 ***** Running evaluation *****\n",
      "2021-11-25 01:16:32   Num examples = 32\n",
      "2021-11-25 01:16:32   Batch size = 32\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "2021-11-25 01:16:33   macro_f1 = 0.9983041266252121\n",
      "2021-11-25 01:16:33   micro_f1 = 0.9983041266252121\n",
      "2021-11-25 01:16:33   support = 884\n",
      "2021-11-25 01:16:33   O-precision = 0.9977401129943503\n",
      "2021-11-25 01:16:33   O-recall = 0.998868778280543\n",
      "2021-11-25 01:16:33   O-f1-score = 0.9983041266252121\n",
      "2021-11-25 01:16:33   O-support = 884\n",
      "2021-11-25 01:16:33   loss = 0.4514961242675781\n",
      "2021-11-25 01:16:33   dataset = dev\n",
      "2021-11-25 01:16:33 ***** Running evaluation *****\n",
      "2021-11-25 01:16:33   Num examples = 32\n",
      "2021-11-25 01:16:33   Batch size = 32\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "2021-11-25 01:16:34   macro_f1 = 0.9983041266252121\n",
      "2021-11-25 01:16:34   micro_f1 = 0.9983041266252121\n",
      "2021-11-25 01:16:34   support = 884\n",
      "2021-11-25 01:16:34   O-precision = 0.9977401129943503\n",
      "2021-11-25 01:16:34   O-recall = 0.998868778280543\n",
      "2021-11-25 01:16:34   O-f1-score = 0.9983041266252121\n",
      "2021-11-25 01:16:34   O-support = 884\n",
      "2021-11-25 01:16:34   loss = 0.4514961242675781\n",
      "2021-11-25 01:16:34   dataset = test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = pipeline.test(\n",
    "    test_raw_data=test_raw_data,\n",
    "    eval_params=eval_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.9983041266252121,
       "encoder": "json",
       "name": "macro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "macro_f1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.9983041266252121,
       "encoder": "json",
       "name": "micro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "micro_f1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue(\"macro_f1\", metrics['macro_f1'])\n",
    "sb.glue(\"micro_f1\", metrics['micro_f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
