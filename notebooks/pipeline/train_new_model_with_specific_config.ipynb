{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import scrapbook as sb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "src_dir = \"../../src\"  # Ignore this!\n",
    "\n",
    "# Pipeline settings\n",
    "task = \"sequence_classification\"  # chinese_word_segmentation OR target_classification, OR sequence_classification\n",
    "model = 'BERT_CLS'  # None: Default model \n",
    "device = 0\n",
    "text_prepro = None  # None: Default steps \n",
    "\n",
    "model_params = {\n",
    "    'num_train_epochs': 5, \n",
    "    'max_length': 256,\n",
    "#     'tokenizer_name': \"bert-base-chinese\" \n",
    "#     'pretrained_lm': \"bert-base-chinese\" \n",
    "#     'embedding_trainable': True, \n",
    "#     'output_hidden_act_func': \"PReLU\", \n",
    "#     'output_hidden_dim': 128, \n",
    "#     'output_use_bn': False, \n",
    "#     'optimizer': \"AdamW\",\n",
    "#     'learning_rate': 2e-5,\n",
    "#     'weight_decay': 0.0,\n",
    "#     'gradient_accumulation_steps': 1,\n",
    "#     'adam_epsilon': 1e-8,\n",
    "#     'max_grad_norm': 1.0,\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 16, \n",
    "    'seed': 42, \n",
    "    'optimization_metric': \"macro_f1\", \n",
    "    'early_stop': None\n",
    "}\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "model_dir = f\"../output/test_pipeline_{task}_tmp\"  # output dir for new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(src_dir)\n",
    "from pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '<p> zaia係咩, 我都想睇水舞間, 朋友睇完都話好睇!', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "dev_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "test_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "print(train_raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:22 ***** Model class is specified for sequence_classification. *****\n",
      "2021-11-29 02:22:22   Model = BERT_CLS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/examples/sequence_classification/BERT_CLS\n",
      "['.ipynb_checkpoints', 'model', 'result', 'logs', 'run.yaml']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    task=task, \n",
    "    model=model, \n",
    "    device=device, \n",
    "    text_prepro=text_prepro\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:23 ***** Initializing pipeline *****\n",
      "2021-11-29 02:22:23 ***** Loading tokenizer *****\n",
      "2021-11-29 02:22:23   Tokenizer source = 'transformers'\n",
      "2021-11-29 02:22:23 ***** Initializing model *****\n",
      "2021-11-29 02:22:23   Task = sequence_classification\n",
      "2021-11-29 02:22:23   Model class = BERT_CLS\n",
      "2021-11-29 02:22:23   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenizer', 'label_to_id.json', 'model.pt', 'run.yaml', 'model.yaml']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 02:22:32 ***** Loading data *****\n",
      "2021-11-29 02:22:32   Raw data is provided.\n",
      "3it [00:00, 86.38it/s]\n",
      "2021-11-29 02:22:32   Loaded samples = 3\n",
      "2021-11-29 02:22:32 ***** Loading data *****\n",
      "2021-11-29 02:22:32   Raw data is provided.\n",
      "3it [00:00, 131.16it/s]\n",
      "2021-11-29 02:22:32   Loaded samples = 3\n",
      "2021-11-29 02:22:32 ***** Running training *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Num Epochs = 5\n",
      "2021-11-29 02:22:32   Sampler = \n",
      "2021-11-29 02:22:32   Batch size = 16\n",
      "2021-11-29 02:22:32   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.619]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, tr_loss=0.619]\u001b[A\n",
      "2021-11-29 02:22:32 ***** Epoch end: 0 *****\n",
      "2021-11-29 02:22:32 ***** Running evaluation *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 46.50it/s]\n",
      "2021-11-29 02:22:32   accuracy = 1.0\n",
      "2021-11-29 02:22:32   macro_f1 = 1.0\n",
      "2021-11-29 02:22:32   micro_f1 = 1.0\n",
      "2021-11-29 02:22:32   support = 3\n",
      "2021-11-29 02:22:32   -1-precision = 1.0\n",
      "2021-11-29 02:22:32   -1-recall = 1.0\n",
      "2021-11-29 02:22:32   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   -1-support = 1\n",
      "2021-11-29 02:22:32   0-precision = 1.0\n",
      "2021-11-29 02:22:32   0-recall = 1.0\n",
      "2021-11-29 02:22:32   0-f1-score = 1.0\n",
      "2021-11-29 02:22:32   0-support = 1\n",
      "2021-11-29 02:22:32   1-precision = 1.0\n",
      "2021-11-29 02:22:32   1-recall = 1.0\n",
      "2021-11-29 02:22:32   1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   1-support = 1\n",
      "2021-11-29 02:22:32   loss = 0.49821820855140686\n",
      "2021-11-29 02:22:32   dataset = dev\n",
      "Epoch:  20%|██        | 1/5 [00:00<00:00,  5.25it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.701]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, tr_loss=0.701]\u001b[A\n",
      "2021-11-29 02:22:32 ***** Epoch end: 1 *****\n",
      "2021-11-29 02:22:32 ***** Running evaluation *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 45.54it/s]\n",
      "2021-11-29 02:22:32   accuracy = 1.0\n",
      "2021-11-29 02:22:32   macro_f1 = 1.0\n",
      "2021-11-29 02:22:32   micro_f1 = 1.0\n",
      "2021-11-29 02:22:32   support = 3\n",
      "2021-11-29 02:22:32   -1-precision = 1.0\n",
      "2021-11-29 02:22:32   -1-recall = 1.0\n",
      "2021-11-29 02:22:32   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   -1-support = 1\n",
      "2021-11-29 02:22:32   0-precision = 1.0\n",
      "2021-11-29 02:22:32   0-recall = 1.0\n",
      "2021-11-29 02:22:32   0-f1-score = 1.0\n",
      "2021-11-29 02:22:32   0-support = 1\n",
      "2021-11-29 02:22:32   1-precision = 1.0\n",
      "2021-11-29 02:22:32   1-recall = 1.0\n",
      "2021-11-29 02:22:32   1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   1-support = 1\n",
      "2021-11-29 02:22:32   loss = 0.40934228897094727\n",
      "2021-11-29 02:22:32   dataset = dev\n",
      "Epoch:  40%|████      | 2/5 [00:00<00:00,  5.52it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, tr_loss=0.399]\n",
      "2021-11-29 02:22:32 ***** Epoch end: 2 *****\n",
      "2021-11-29 02:22:32 ***** Running evaluation *****\n",
      "2021-11-29 02:22:32   Num examples = 3\n",
      "2021-11-29 02:22:32   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.46it/s]\n",
      "2021-11-29 02:22:32   accuracy = 1.0\n",
      "2021-11-29 02:22:32   macro_f1 = 1.0\n",
      "2021-11-29 02:22:32   micro_f1 = 1.0\n",
      "2021-11-29 02:22:32   support = 3\n",
      "2021-11-29 02:22:32   -1-precision = 1.0\n",
      "2021-11-29 02:22:32   -1-recall = 1.0\n",
      "2021-11-29 02:22:32   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   -1-support = 1\n",
      "2021-11-29 02:22:32   0-precision = 1.0\n",
      "2021-11-29 02:22:32   0-recall = 1.0\n",
      "2021-11-29 02:22:32   0-f1-score = 1.0\n",
      "2021-11-29 02:22:32   0-support = 1\n",
      "2021-11-29 02:22:32   1-precision = 1.0\n",
      "2021-11-29 02:22:32   1-recall = 1.0\n",
      "2021-11-29 02:22:32   1-f1-score = 1.0\n",
      "2021-11-29 02:22:32   1-support = 1\n",
      "2021-11-29 02:22:32   loss = 0.3296729624271393\n",
      "2021-11-29 02:22:32   dataset = dev\n",
      "Epoch:  60%|██████    | 3/5 [00:00<00:00,  5.91it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.437]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, tr_loss=0.437]\u001b[A\n",
      "2021-11-29 02:22:33 ***** Epoch end: 3 *****\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 48.07it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.28001585602760315\n",
      "2021-11-29 02:22:33   dataset = dev\n",
      "Epoch:  80%|████████  | 4/5 [00:00<00:00,  6.09it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, tr_loss=0.438]\n",
      "2021-11-29 02:22:33 ***** Epoch end: 4 *****\n",
      "2021-11-29 02:22:33 ***** Running evaluation *****\n",
      "2021-11-29 02:22:33   Num examples = 3\n",
      "2021-11-29 02:22:33   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 48.01it/s]\n",
      "2021-11-29 02:22:33   accuracy = 1.0\n",
      "2021-11-29 02:22:33   macro_f1 = 1.0\n",
      "2021-11-29 02:22:33   micro_f1 = 1.0\n",
      "2021-11-29 02:22:33   support = 3\n",
      "2021-11-29 02:22:33   -1-precision = 1.0\n",
      "2021-11-29 02:22:33   -1-recall = 1.0\n",
      "2021-11-29 02:22:33   -1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   -1-support = 1\n",
      "2021-11-29 02:22:33   0-precision = 1.0\n",
      "2021-11-29 02:22:33   0-recall = 1.0\n",
      "2021-11-29 02:22:33   0-f1-score = 1.0\n",
      "2021-11-29 02:22:33   0-support = 1\n",
      "2021-11-29 02:22:33   1-precision = 1.0\n",
      "2021-11-29 02:22:33   1-recall = 1.0\n",
      "2021-11-29 02:22:33   1-f1-score = 1.0\n",
      "2021-11-29 02:22:33   1-support = 1\n",
      "2021-11-29 02:22:33   loss = 0.25824984908103943\n",
      "2021-11-29 02:22:33   dataset = dev\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n",
      "2021-11-29 02:22:33 ***** Training end *****\n",
      "2021-11-29 02:22:33   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BERT_CLS. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline.train(\n",
    "    model_dir, \n",
    "    train_raw_data=train_raw_data, \n",
    "    dev_raw_data=dev_raw_data, \n",
    "    model_params=model_params,\n",
    "    train_params=train_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 02:57:45 ***** Loading data *****\n",
      "2021-11-30 02:57:45   Raw data is provided.\n",
      "1821it [00:07, 237.49it/s]\n",
      "2021-11-30 02:57:53   Loaded samples = 1821\n",
      "2021-11-30 02:57:53 ***** Running evaluation *****\n",
      "2021-11-30 02:57:53   Num examples = 1821\n",
      "2021-11-30 02:57:53   Batch size = 32\n",
      "Evaluating: 100%|██████████| 57/57 [00:09<00:00,  5.97it/s]\n",
      "2021-11-30 02:58:02   accuracy = 0.9104887424492037\n",
      "2021-11-30 02:58:02   macro_f1 = 0.9104212080067818\n",
      "2021-11-30 02:58:02   micro_f1 = 0.9104171559402365\n",
      "2021-11-30 02:58:02   support = 1821\n",
      "2021-11-30 02:58:02   0-precision = 0.9359720605355064\n",
      "2021-11-30 02:58:02   0-recall = 0.881578947368421\n",
      "2021-11-30 02:58:02   0-f1-score = 0.9079616036137775\n",
      "2021-11-30 02:58:02   0-support = 912\n",
      "2021-11-30 02:58:02   1-precision = 0.8877338877338877\n",
      "2021-11-30 02:58:02   1-recall = 0.9394939493949395\n",
      "2021-11-30 02:58:02   1-f1-score = 0.9128808123997861\n",
      "2021-11-30 02:58:02   1-support = 909\n",
      "2021-11-30 02:58:02   loss = 0.2819006933520238\n",
      "2021-11-30 02:58:02   dataset = test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = pipeline.test(\n",
    "    test_raw_data=test_raw_data,\n",
    "    eval_params=eval_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 02:57:33 ***** Existing model is provided. *****\n",
      "2021-11-30 02:57:33   Model directory = ../output/explainable_ai_paper/bert_cls_sst\n",
      "2021-11-30 02:57:33 ***** Initializing pipeline *****\n",
      "2021-11-30 02:57:33 ***** Loading tokenizer *****\n",
      "2021-11-30 02:57:33   Tokenizer source = 'transformers'\n",
      "2021-11-30 02:57:33 ***** Initializing model *****\n",
      "2021-11-30 02:57:33   Task = sequence_classification\n",
      "2021-11-30 02:57:33   Model class = BERT_CLS\n",
      "2021-11-30 02:57:33   Model path = ../output/explainable_ai_paper/bert_cls_sst/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/explainable_ai_paper/bert_cls_sst/model\n",
      "['run.yaml', 'model.yaml', 'tokenizer', 'label_to_id.json', 'model.pt']\n",
      "['run.yaml', 'model.yaml', 'tokenizer', 'label_to_id.json', 'model.pt']\n",
      "Input:\n",
      "{'content': 'if you sometimes like to go to the movies to have fun wasabi is a good place to start', 'label': 1}\n",
      "Output:\n",
      "{'prediction_id': 0, 'prediction': '1'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    model_dir=model_dir, \n",
    "    device=device, \n",
    ")\n",
    "\n",
    "print(\"Input:\")\n",
    "print(test_raw_data[0])\n",
    "\n",
    "output = pipeline.predict(\n",
    "    data_dict=test_raw_data[0],\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from captum.attr import visualization as viz\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def visualize_data_record_bert(pipeline, raw_data):\n",
    "    \n",
    "#     true_class = raw_data['label']\n",
    "\n",
    "#     tokens, scores, attr_target, attr_target_prob = pipeline.explain(\n",
    "#         data_dict=raw_data,\n",
    "#         method='IntegratedGradients',\n",
    "#         layer='pretrained_model.embeddings.word_embeddings', \n",
    "#         norm='sum'\n",
    "#     )\n",
    "    \n",
    "#     attr_class = pipeline.args.label_to_id_inv[attr_target]\n",
    "#     start_position_vis = viz.VisualizationDataRecord(\n",
    "#                             scores,\n",
    "#                             pred_prob=attr_target_prob,\n",
    "#                             pred_class=attr_class,\n",
    "#                             true_class=true_class,\n",
    "#                             attr_class=attr_class,\n",
    "#                             attr_score=np.sum(scores),       \n",
    "#                             raw_input=tokens,\n",
    "#                             convergence_score=None)\n",
    "#     viz.visualize_text([start_position_vis])\n",
    "\n",
    "# raw_data = test_raw_data[1]\n",
    "# visualize_data_record_bert(pipeline, raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d35f7baa4e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 1,
       "encoder": "json",
       "name": "macro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "macro_f1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 1,
       "encoder": "json",
       "name": "micro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "micro_f1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue(\"macro_f1\", metrics['macro_f1'])\n",
    "sb.glue(\"micro_f1\", metrics['micro_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
