{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import scrapbook as sb\n",
    "os.chdir(\"../../nlp_pipeline\")\n",
    "from nlp_pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 0\n",
    "model_dir = \"../output/test_pipeline_sequence_classification_tmp\"  # input dir for old model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '<p> zaia係咩, 我都想睇水舞間, 朋友睇完都話好睇!', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_raw_data = json.load(open(f\"../data/datasets/sample/sequence_classification/train_sample.json\", 'r'))\n",
    "dev_raw_data = json.load(open(f\"../data/datasets/sample/sequence_classification/train_sample.json\", 'r'))\n",
    "test_raw_data = json.load(open(f\"../data/datasets/sample/sequence_classification/train_sample.json\", 'r'))\n",
    "print(train_raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline (included loading existing model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 01:39:21 ***** Existing model is provided. *****\n",
      "2021-11-26 01:39:21   Model directory = ../output/test_pipeline_sequence_classification_tmp\n",
      "2021-11-26 01:39:21 ***** Initializing pipeline *****\n",
      "2021-11-26 01:39:21 ***** Loading tokenizer *****\n",
      "2021-11-26 01:39:21   Tokenizer source = 'transformers'\n",
      "2021-11-26 01:39:21 ***** Initializing model *****\n",
      "2021-11-26 01:39:21   Task = sequence_classification\n",
      "2021-11-26 01:39:21   Model class = BERT_CLS\n",
      "2021-11-26 01:39:21   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/test_pipeline_sequence_classification_tmp/model\n",
      "['tokenizer', 'label_to_id.json', 'model.pt', 'run.yaml', 'model.yaml']\n",
      "['tokenizer', 'label_to_id.json', 'model.pt', 'run.yaml', 'model.yaml']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    model_dir=model_dir, \n",
    "    device=device, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 01:39:28 ***** Loading data *****\n",
      "2021-11-26 01:39:28   Raw data is provided.\n",
      "3it [00:00, 112.48it/s]\n",
      "2021-11-26 01:39:28   Loaded samples = 3\n",
      "2021-11-26 01:39:28 ***** Running evaluation *****\n",
      "2021-11-26 01:39:28   Num examples = 3\n",
      "2021-11-26 01:39:28   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 35.48it/s]\n",
      "2021-11-26 01:39:28   accuracy = 1.0\n",
      "2021-11-26 01:39:28   macro_f1 = 1.0\n",
      "2021-11-26 01:39:28   micro_f1 = 1.0\n",
      "2021-11-26 01:39:28   support = 3\n",
      "2021-11-26 01:39:28   -1-precision = 1.0\n",
      "2021-11-26 01:39:28   -1-recall = 1.0\n",
      "2021-11-26 01:39:28   -1-f1-score = 1.0\n",
      "2021-11-26 01:39:28   -1-support = 1\n",
      "2021-11-26 01:39:28   0-precision = 1.0\n",
      "2021-11-26 01:39:28   0-recall = 1.0\n",
      "2021-11-26 01:39:28   0-f1-score = 1.0\n",
      "2021-11-26 01:39:28   0-support = 1\n",
      "2021-11-26 01:39:28   1-precision = 1.0\n",
      "2021-11-26 01:39:28   1-recall = 1.0\n",
      "2021-11-26 01:39:28   1-f1-score = 1.0\n",
      "2021-11-26 01:39:28   1-support = 1\n",
      "2021-11-26 01:39:28   loss = 0.7164847254753113\n",
      "2021-11-26 01:39:28   dataset = test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'macro_f1': 1.0,\n",
       " 'micro_f1': 1.0,\n",
       " 'support': 3,\n",
       " '-1-precision': 1.0,\n",
       " '-1-recall': 1.0,\n",
       " '-1-f1-score': 1.0,\n",
       " '-1-support': 1,\n",
       " '0-precision': 1.0,\n",
       " '0-recall': 1.0,\n",
       " '0-f1-score': 1.0,\n",
       " '0-support': 1,\n",
       " '1-precision': 1.0,\n",
       " '1-recall': 1.0,\n",
       " '1-f1-score': 1.0,\n",
       " '1-support': 1,\n",
       " 'loss': 0.7164847254753113,\n",
       " 'dataset': 'test'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.test(\n",
    "    test_raw_data=test_raw_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "{'content': '<p> zaia係咩, 我都想睇水舞間, 朋友睇完都話好睇!', 'label': 1}\n",
      "Output:\n",
      "{'prediction_id': 0, 'prediction': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "print(test_raw_data[0])\n",
    "\n",
    "output = pipeline.predict(\n",
    "    data_dict=test_raw_data[0],\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
