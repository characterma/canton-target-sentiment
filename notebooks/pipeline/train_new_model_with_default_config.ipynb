{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import scrapbook as sb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "src_dir = \"../../src\"  # Ignore this!\n",
    "\n",
    "# Pipeline settings\n",
    "task = \"sequence_classification\"  # chinese_word_segmentation OR target_classification, OR sequence_classification\n",
    "device = 0\n",
    "model_params = {'num_train_epochs': 5}\n",
    "model_dir = \"../output/test_pipeline_sequence_classification_tmp\"  # output dir for new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(src_dir)\n",
    "from pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '<p> zaia係咩, 我都想睇水舞間, 朋友睇完都話好睇!', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "dev_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "test_raw_data = json.load(open(f\"../data/datasets/sample/{task}/train_sample.json\", 'r'))\n",
    "print(train_raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 02:14:26 ***** Model class is not specified for sequence_classification. *****\n",
      "2021-11-25 02:14:26   Default model = BERT_CLS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../config/examples/sequence_classification/BERT_CLS\n",
      "['.ipynb_checkpoints', 'run.yaml', 'model', 'result', 'logs']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    task=task, \n",
    "    device=device, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 02:14:35 ***** Initializing pipeline *****\n",
      "2021-11-25 02:14:35 ***** Loading tokenizer *****\n",
      "2021-11-25 02:14:35   Tokenizer source = 'transformers'\n",
      "2021-11-25 02:14:38 ***** Initializing model *****\n",
      "2021-11-25 02:14:38   Task = sequence_classification\n",
      "2021-11-25 02:14:38   Model class = BERT_CLS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenizer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 02:14:39 ***** Loading pretrained language model *****\n",
      "2021-11-25 02:14:39   Pretrained BERT = 'bert-base-chinese'\n",
      "2021-11-25 02:14:49 ***** Loading data *****\n",
      "2021-11-25 02:14:49   Raw data is provided.\n",
      "3it [00:00, 80.61it/s]\n",
      "2021-11-25 02:14:49   Loaded samples = 3\n",
      "2021-11-25 02:14:49 ***** Loading data *****\n",
      "2021-11-25 02:14:49   Raw data is provided.\n",
      "3it [00:00, 109.68it/s]\n",
      "2021-11-25 02:14:49   Loaded samples = 3\n",
      "2021-11-25 02:14:49 ***** Running training *****\n",
      "2021-11-25 02:14:49   Num examples = 3\n",
      "2021-11-25 02:14:49   Num Epochs = 5\n",
      "2021-11-25 02:14:49   Sampler = \n",
      "2021-11-25 02:14:49   Batch size = 32\n",
      "2021-11-25 02:14:49   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=1.21]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, tr_loss=1.21]\u001b[A\n",
      "2021-11-25 02:14:49 ***** Epoch end: 0 *****\n",
      "2021-11-25 02:14:49 ***** Running evaluation *****\n",
      "2021-11-25 02:14:49   Num examples = 3\n",
      "2021-11-25 02:14:49   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-11-25 02:14:49   accuracy = 0.3333333333333333\n",
      "2021-11-25 02:14:49   macro_f1 = 0.16666666666666666\n",
      "2021-11-25 02:14:49   micro_f1 = 0.16666666666666666\n",
      "2021-11-25 02:14:49   support = 3\n",
      "2021-11-25 02:14:49   -1-precision = 0.3333333333333333\n",
      "2021-11-25 02:14:49   -1-recall = 1.0\n",
      "2021-11-25 02:14:49   -1-f1-score = 0.5\n",
      "2021-11-25 02:14:49   -1-support = 1\n",
      "2021-11-25 02:14:49   0-precision = 0.0\n",
      "2021-11-25 02:14:49   0-recall = 0.0\n",
      "2021-11-25 02:14:49   0-f1-score = 0.0\n",
      "2021-11-25 02:14:49   0-support = 1\n",
      "2021-11-25 02:14:49   1-precision = 0.0\n",
      "2021-11-25 02:14:49   1-recall = 0.0\n",
      "2021-11-25 02:14:49   1-f1-score = 0.0\n",
      "2021-11-25 02:14:49   1-support = 1\n",
      "2021-11-25 02:14:49   loss = 1.0279189348220825\n",
      "2021-11-25 02:14:49   dataset = dev\n",
      "Epoch:  20%|██        | 1/5 [00:00<00:00,  5.37it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=1.1]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, tr_loss=1.1]\u001b[A\n",
      "2021-11-25 02:14:50 ***** Epoch end: 1 *****\n",
      "2021-11-25 02:14:50 ***** Running evaluation *****\n",
      "2021-11-25 02:14:50   Num examples = 3\n",
      "2021-11-25 02:14:50   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.50it/s]\n",
      "2021-11-25 02:14:50   accuracy = 0.6666666666666666\n",
      "2021-11-25 02:14:50   macro_f1 = 0.5555555555555555\n",
      "2021-11-25 02:14:50   micro_f1 = 0.5555555555555555\n",
      "2021-11-25 02:14:50   support = 3\n",
      "2021-11-25 02:14:50   -1-precision = 0.5\n",
      "2021-11-25 02:14:50   -1-recall = 1.0\n",
      "2021-11-25 02:14:50   -1-f1-score = 0.6666666666666666\n",
      "2021-11-25 02:14:50   -1-support = 1\n",
      "2021-11-25 02:14:50   0-precision = 0.0\n",
      "2021-11-25 02:14:50   0-recall = 0.0\n",
      "2021-11-25 02:14:50   0-f1-score = 0.0\n",
      "2021-11-25 02:14:50   0-support = 1\n",
      "2021-11-25 02:14:50   1-precision = 1.0\n",
      "2021-11-25 02:14:50   1-recall = 1.0\n",
      "2021-11-25 02:14:50   1-f1-score = 1.0\n",
      "2021-11-25 02:14:50   1-support = 1\n",
      "2021-11-25 02:14:50   loss = 0.9230960011482239\n",
      "2021-11-25 02:14:50   dataset = dev\n",
      "Epoch:  40%|████      | 2/5 [00:00<00:00,  5.53it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=0.9]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, tr_loss=0.9]\u001b[A\n",
      "2021-11-25 02:14:50 ***** Epoch end: 2 *****\n",
      "2021-11-25 02:14:50 ***** Running evaluation *****\n",
      "2021-11-25 02:14:50   Num examples = 3\n",
      "2021-11-25 02:14:50   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.48it/s]\n",
      "2021-11-25 02:14:50   accuracy = 0.6666666666666666\n",
      "2021-11-25 02:14:50   macro_f1 = 0.5555555555555555\n",
      "2021-11-25 02:14:50   micro_f1 = 0.5555555555555555\n",
      "2021-11-25 02:14:50   support = 3\n",
      "2021-11-25 02:14:50   -1-precision = 0.5\n",
      "2021-11-25 02:14:50   -1-recall = 1.0\n",
      "2021-11-25 02:14:50   -1-f1-score = 0.6666666666666666\n",
      "2021-11-25 02:14:50   -1-support = 1\n",
      "2021-11-25 02:14:50   0-precision = 0.0\n",
      "2021-11-25 02:14:50   0-recall = 0.0\n",
      "2021-11-25 02:14:50   0-f1-score = 0.0\n",
      "2021-11-25 02:14:50   0-support = 1\n",
      "2021-11-25 02:14:50   1-precision = 1.0\n",
      "2021-11-25 02:14:50   1-recall = 1.0\n",
      "2021-11-25 02:14:50   1-f1-score = 1.0\n",
      "2021-11-25 02:14:50   1-support = 1\n",
      "2021-11-25 02:14:50   loss = 0.8435149192810059\n",
      "2021-11-25 02:14:50   dataset = dev\n",
      "Epoch:  60%|██████    | 3/5 [00:00<00:00,  5.86it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, tr_loss=0.704]\n",
      "2021-11-25 02:14:50 ***** Epoch end: 3 *****\n",
      "2021-11-25 02:14:50 ***** Running evaluation *****\n",
      "2021-11-25 02:14:50   Num examples = 3\n",
      "2021-11-25 02:14:50   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.01it/s]\n",
      "2021-11-25 02:14:50   accuracy = 0.6666666666666666\n",
      "2021-11-25 02:14:50   macro_f1 = 0.5555555555555555\n",
      "2021-11-25 02:14:50   micro_f1 = 0.5555555555555555\n",
      "2021-11-25 02:14:50   support = 3\n",
      "2021-11-25 02:14:50   -1-precision = 0.5\n",
      "2021-11-25 02:14:50   -1-recall = 1.0\n",
      "2021-11-25 02:14:50   -1-f1-score = 0.6666666666666666\n",
      "2021-11-25 02:14:50   -1-support = 1\n",
      "2021-11-25 02:14:50   0-precision = 0.0\n",
      "2021-11-25 02:14:50   0-recall = 0.0\n",
      "2021-11-25 02:14:50   0-f1-score = 0.0\n",
      "2021-11-25 02:14:50   0-support = 1\n",
      "2021-11-25 02:14:50   1-precision = 1.0\n",
      "2021-11-25 02:14:50   1-recall = 1.0\n",
      "2021-11-25 02:14:50   1-f1-score = 1.0\n",
      "2021-11-25 02:14:50   1-support = 1\n",
      "2021-11-25 02:14:50   loss = 0.7668281197547913\n",
      "2021-11-25 02:14:50   dataset = dev\n",
      "Epoch:  80%|████████  | 4/5 [00:00<00:00,  6.15it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, tr_loss=0.794]\n",
      "2021-11-25 02:14:50 ***** Epoch end: 4 *****\n",
      "2021-11-25 02:14:50 ***** Running evaluation *****\n",
      "2021-11-25 02:14:50   Num examples = 3\n",
      "2021-11-25 02:14:50   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 47.19it/s]\n",
      "2021-11-25 02:14:50   accuracy = 1.0\n",
      "2021-11-25 02:14:50   macro_f1 = 1.0\n",
      "2021-11-25 02:14:50   micro_f1 = 1.0\n",
      "2021-11-25 02:14:50   support = 3\n",
      "2021-11-25 02:14:50   -1-precision = 1.0\n",
      "2021-11-25 02:14:50   -1-recall = 1.0\n",
      "2021-11-25 02:14:50   -1-f1-score = 1.0\n",
      "2021-11-25 02:14:50   -1-support = 1\n",
      "2021-11-25 02:14:50   0-precision = 1.0\n",
      "2021-11-25 02:14:50   0-recall = 1.0\n",
      "2021-11-25 02:14:50   0-f1-score = 1.0\n",
      "2021-11-25 02:14:50   0-support = 1\n",
      "2021-11-25 02:14:50   1-precision = 1.0\n",
      "2021-11-25 02:14:50   1-recall = 1.0\n",
      "2021-11-25 02:14:50   1-f1-score = 1.0\n",
      "2021-11-25 02:14:50   1-support = 1\n",
      "2021-11-25 02:14:50   loss = 0.7164847254753113\n",
      "2021-11-25 02:14:50   dataset = dev\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  6.18it/s]\n",
      "2021-11-25 02:14:50 ***** Training end *****\n",
      "2021-11-25 02:14:50   Model path = ../output/test_pipeline_sequence_classification_tmp/model/model.pt\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BERT_CLS. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline.train(\n",
    "    model_dir, \n",
    "    train_raw_data=train_raw_data, \n",
    "    dev_raw_data=dev_raw_data, \n",
    "    model_params=model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 02:14:51 ***** Loading data *****\n",
      "2021-11-25 02:14:51   Raw data is provided.\n",
      "3it [00:00, 114.58it/s]\n",
      "2021-11-25 02:14:51   Loaded samples = 3\n",
      "2021-11-25 02:14:51 ***** Running evaluation *****\n",
      "2021-11-25 02:14:51   Num examples = 3\n",
      "2021-11-25 02:14:51   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 45.95it/s]\n",
      "2021-11-25 02:14:51   accuracy = 1.0\n",
      "2021-11-25 02:14:51   macro_f1 = 1.0\n",
      "2021-11-25 02:14:51   micro_f1 = 1.0\n",
      "2021-11-25 02:14:51   support = 3\n",
      "2021-11-25 02:14:51   -1-precision = 1.0\n",
      "2021-11-25 02:14:51   -1-recall = 1.0\n",
      "2021-11-25 02:14:51   -1-f1-score = 1.0\n",
      "2021-11-25 02:14:51   -1-support = 1\n",
      "2021-11-25 02:14:51   0-precision = 1.0\n",
      "2021-11-25 02:14:51   0-recall = 1.0\n",
      "2021-11-25 02:14:51   0-f1-score = 1.0\n",
      "2021-11-25 02:14:51   0-support = 1\n",
      "2021-11-25 02:14:51   1-precision = 1.0\n",
      "2021-11-25 02:14:51   1-recall = 1.0\n",
      "2021-11-25 02:14:51   1-f1-score = 1.0\n",
      "2021-11-25 02:14:51   1-support = 1\n",
      "2021-11-25 02:14:51   loss = 0.7164847254753113\n",
      "2021-11-25 02:14:51   dataset = train\n",
      "2021-11-25 02:14:51 ***** Running evaluation *****\n",
      "2021-11-25 02:14:51   Num examples = 3\n",
      "2021-11-25 02:14:51   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 46.21it/s]\n",
      "2021-11-25 02:14:51   accuracy = 1.0\n",
      "2021-11-25 02:14:51   macro_f1 = 1.0\n",
      "2021-11-25 02:14:51   micro_f1 = 1.0\n",
      "2021-11-25 02:14:51   support = 3\n",
      "2021-11-25 02:14:51   -1-precision = 1.0\n",
      "2021-11-25 02:14:51   -1-recall = 1.0\n",
      "2021-11-25 02:14:51   -1-f1-score = 1.0\n",
      "2021-11-25 02:14:51   -1-support = 1\n",
      "2021-11-25 02:14:51   0-precision = 1.0\n",
      "2021-11-25 02:14:51   0-recall = 1.0\n",
      "2021-11-25 02:14:51   0-f1-score = 1.0\n",
      "2021-11-25 02:14:51   0-support = 1\n",
      "2021-11-25 02:14:51   1-precision = 1.0\n",
      "2021-11-25 02:14:51   1-recall = 1.0\n",
      "2021-11-25 02:14:51   1-f1-score = 1.0\n",
      "2021-11-25 02:14:51   1-support = 1\n",
      "2021-11-25 02:14:51   loss = 0.7164847254753113\n",
      "2021-11-25 02:14:51   dataset = dev\n",
      "2021-11-25 02:14:51 ***** Running evaluation *****\n",
      "2021-11-25 02:14:51   Num examples = 3\n",
      "2021-11-25 02:14:51   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 45.88it/s]\n",
      "2021-11-25 02:14:51   accuracy = 1.0\n",
      "2021-11-25 02:14:51   macro_f1 = 1.0\n",
      "2021-11-25 02:14:51   micro_f1 = 1.0\n",
      "2021-11-25 02:14:51   support = 3\n",
      "2021-11-25 02:14:51   -1-precision = 1.0\n",
      "2021-11-25 02:14:51   -1-recall = 1.0\n",
      "2021-11-25 02:14:51   -1-f1-score = 1.0\n",
      "2021-11-25 02:14:51   -1-support = 1\n",
      "2021-11-25 02:14:51   0-precision = 1.0\n",
      "2021-11-25 02:14:51   0-recall = 1.0\n",
      "2021-11-25 02:14:51   0-f1-score = 1.0\n",
      "2021-11-25 02:14:51   0-support = 1\n",
      "2021-11-25 02:14:51   1-precision = 1.0\n",
      "2021-11-25 02:14:51   1-recall = 1.0\n",
      "2021-11-25 02:14:51   1-f1-score = 1.0\n",
      "2021-11-25 02:14:51   1-support = 1\n",
      "2021-11-25 02:14:51   loss = 0.7164847254753113\n",
      "2021-11-25 02:14:51   dataset = test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = pipeline.test(\n",
    "    test_raw_data=test_raw_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/test_pipeline_sequence_classification_tmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d35f7baa4e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/test_pipeline_sequence_classification_tmp'"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.9983041266252121,
       "encoder": "json",
       "name": "macro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "macro_f1"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.9983041266252121,
       "encoder": "json",
       "name": "micro_f1",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "micro_f1"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue(\"macro_f1\", metrics['macro_f1'])\n",
    "sb.glue(\"micro_f1\", metrics['micro_f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
