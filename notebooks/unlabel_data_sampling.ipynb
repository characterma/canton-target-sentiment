{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User can sample label ratio based on the ratio of train set, or request desired label ratio. It depends on existence of argument (either input this argument or not):\n",
    "\n",
    "- label_ratio (if required desired label ratio)\n",
    "\n",
    "remarks: Model directory is required to predict labels for unlabel data in order to sample data which includes\n",
    "- model directory\n",
    "    - run.yaml\n",
    "    - model.yaml\n",
    "    - label_to_id.json\n",
    "    - model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment if user samples label ratio based on the ratio of train set\n",
    "label_ratio = {'-1': 0.4, '0': 0.2, '1': 0.4} # optional \n",
    "\n",
    "# unlabel path (json file name included)\n",
    "unlabel_path = '../data/datasets/sample/sequence_classification/unlabeled_sample.json' \n",
    "\n",
    "# model directory, must include above files\n",
    "model_dir = '../config/examples/sequence_classification/BERT_AVG_explain' # required argument \n",
    "\n",
    "# save directory\n",
    "save_dir = '../data/datasets/sample/sequence_classification' # required \n",
    "save_data_file = 'sampled_unlabel_data.json' # required \n",
    "save_logit_file = 'sampled_unlabel_logits.pkl' # required \n",
    "\n",
    "# sample size and certainty\n",
    "sample_size = 10 # required, integer and smaller than size of unlabeled data\n",
    "certainty = 0 # optional, only select the data that max(p)>certainty, \n",
    "                # p is the predicted probabilities (0 - 1) over the label space\n",
    "                # default certainty is 0\n",
    "\n",
    "device = 0\n",
    "\n",
    "src_dir = '../nlp_pipeline' # optional, default source directory is nlp_pipeline folder\n",
    "\n",
    "# unlabel_logits_path = '../data/datasets/sample/sequence_classification/sampled_unlabel_logits.pkl' # optional, use to extract logit information instead of prediction for saving time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "From data augmentation experiment for Apple Care 2 dataset, highlighted factors can ensure the quality of unlabeled dataset which enhance the performance of model.\n",
    "\n",
    "Experiment details in [2022_01_13 biweekly discussion.pptx](https://jira.wisers.com:18090/download/attachments/82808396/2022_01_13%20biweekly%20discussion.pptx?version=1&modificationDate=1642063801000&api=v2)\n",
    "\n",
    "For code design please browse [Confluence Proposed Module](https://jira.wisers.com:18090/display/RES/Proposed+Module2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "src_dir = '../nlp_pipeline'\n",
    "os.chdir(src_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generation\n",
    "\n",
    "- train a demo model for predict unlabel data in demonstration\n",
    "\n",
    "If you have specified trained model path:\n",
    "- comment below cell\n",
    "- comment the last cell (used to remove demo model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None **********************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *********************************************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *****\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model/tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 01:46:36 ***** Args *****\n",
      "2022-03-30 01:46:36    task: sequence_classification\n",
      "2022-03-30 01:46:36    device: 0\n",
      "2022-03-30 01:46:36    data: {'output_dir': '../config/examples/sequence_classification/BERT_AVG_explain', 'data_dir': '../data/datasets/sample/sequence_classification', 'train': 'train_sample.json', 'dev': 'train_sample.json', 'test': 'train_sample.json'}\n",
      "2022-03-30 01:46:36    text_prepro: {'steps': ['utf8_replace', 'simplified_chinese', 'lower_case', 'full_to_half']}\n",
      "2022-03-30 01:46:36    eval: {'batch_size': 64, 'model_file': 'model.pt'}\n",
      "2022-03-30 01:46:36    train: {'model_class': 'BERT_AVG', 'seed': 42, 'log_steps': 100, 'batch_size': 32, 'final_model': 'best', 'optimization_metric': 'macro_f1', 'early_stop': 5}\n",
      "2022-03-30 01:46:36    model_params: {'num_train_epochs': 2, 'embedding_trainable': True, 'output_hidden_act_func': 'PReLU', 'output_hidden_dim': 128, 'tokenizer_name': 'clue/albert_chinese_tiny', 'pretrained_lm': 'clue/albert_chinese_tiny'}\n",
      "2022-03-30 01:46:36    explanation: {'Random': {'method': 'Random'}, 'Lime': {'method': 'Lime'}, 'WordOmission': {'method': 'WordOmission'}, 'SaliencyAvg': {'method': 'Saliency', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'SaliencyL2': {'method': 'Saliency', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'GradientXActivationAvg': {'method': 'GradientXActivation', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'GradientXActivationL2': {'method': 'GradientXActivation', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'IntegratedGradientsAvg': {'method': 'IntegratedGradients', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'IntegratedGradientsL2': {'method': 'IntegratedGradients', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'DeepLiftAvg': {'method': 'DeepLift', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'DeepLiftL2': {'method': 'DeepLift', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}}\n",
      "2022-03-30 01:46:36 ***** Loading tokenizer *****\n",
      "2022-03-30 01:46:36   Tokenizer source = 'transformers'\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n",
      "The class this function is called from is 'BertTokenizerFast'.\n",
      "2022-03-30 01:46:43 ***** Initializing model *****\n",
      "2022-03-30 01:46:43   Task = sequence_classification\n",
      "2022-03-30 01:46:43   Model class = BERT_AVG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run.yaml', 'model.yaml', 'tokenizer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 01:46:44 ***** Loading pretrained language model *****\n",
      "2022-03-30 01:46:44   Pretrained BERT = 'clue/albert_chinese_tiny'\n",
      "Some weights of the model checkpoint at clue/albert_chinese_tiny were not used when initializing AlbertModel: ['predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-03-30 01:46:49 ***** Loading data *****\n",
      "2022-03-30 01:46:49   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 79.37it/s]\n",
      "2022-03-30 01:46:49   Loaded samples = 3\n",
      "2022-03-30 01:46:49 ***** Loading data *****\n",
      "2022-03-30 01:46:49   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 129.04it/s]\n",
      "2022-03-30 01:46:49   Loaded samples = 3\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "2022-03-30 01:46:49 ***** Running training *****\n",
      "2022-03-30 01:46:49   Num examples = 3\n",
      "2022-03-30 01:46:49   Num Epochs = 2\n",
      "2022-03-30 01:46:49   Sampler = \n",
      "2022-03-30 01:46:49   Batch size = 32\n",
      "2022-03-30 01:46:49   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s, tr_loss=1.09]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, tr_loss=1.09]\u001b[A\n",
      "2022-03-30 01:46:49 ***** Epoch end: 0 *****\n",
      "2022-03-30 01:46:49 ***** Running evaluation *****\n",
      "2022-03-30 01:46:49   Num examples = 3\n",
      "2022-03-30 01:46:49   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 171.47it/s]\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-03-30 01:46:49   accuracy = 0.3333333333333333\n",
      "2022-03-30 01:46:49   macro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   micro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   support = 3\n",
      "2022-03-30 01:46:49   -1-precision = 0.0\n",
      "2022-03-30 01:46:49   -1-recall = 0.0\n",
      "2022-03-30 01:46:49   -1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   -1-support = 1\n",
      "2022-03-30 01:46:49   0-precision = 0.3333333333333333\n",
      "2022-03-30 01:46:49   0-recall = 1.0\n",
      "2022-03-30 01:46:49   0-f1-score = 0.5\n",
      "2022-03-30 01:46:49   0-support = 1\n",
      "2022-03-30 01:46:49   1-precision = 0.0\n",
      "2022-03-30 01:46:49   1-recall = 0.0\n",
      "2022-03-30 01:46:49   1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   1-support = 1\n",
      "2022-03-30 01:46:49   loss = 1.0584701299667358\n",
      "2022-03-30 01:46:49   dataset = dev\n",
      "Epoch:  50%|█████     | 1/2 [00:00<00:00,  1.56it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 43.13it/s, tr_loss=1.06]\n",
      "2022-03-30 01:46:49 ***** Epoch end: 1 *****\n",
      "2022-03-30 01:46:49 ***** Running evaluation *****\n",
      "2022-03-30 01:46:49   Num examples = 3\n",
      "2022-03-30 01:46:49   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 200.44it/s]\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-03-30 01:46:49   accuracy = 0.3333333333333333\n",
      "2022-03-30 01:46:49   macro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   micro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   support = 3\n",
      "2022-03-30 01:46:49   -1-precision = 0.0\n",
      "2022-03-30 01:46:49   -1-recall = 0.0\n",
      "2022-03-30 01:46:49   -1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   -1-support = 1\n",
      "2022-03-30 01:46:49   0-precision = 0.3333333333333333\n",
      "2022-03-30 01:46:49   0-recall = 1.0\n",
      "2022-03-30 01:46:49   0-f1-score = 0.5\n",
      "2022-03-30 01:46:49   0-support = 1\n",
      "2022-03-30 01:46:49   1-precision = 0.0\n",
      "2022-03-30 01:46:49   1-recall = 0.0\n",
      "2022-03-30 01:46:49   1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   1-support = 1\n",
      "2022-03-30 01:46:49   loss = 1.045488953590393\n",
      "2022-03-30 01:46:49   dataset = dev\n",
      "Epoch: 100%|██████████| 2/2 [00:00<00:00,  2.94it/s]\n",
      "2022-03-30 01:46:49 ***** Training end *****\n",
      "2022-03-30 01:46:49   Model path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model/model.pt\n",
      "2022-03-30 01:46:49 ***** Loading data *****\n",
      "2022-03-30 01:46:49   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 114.89it/s]\n",
      "2022-03-30 01:46:49   Loaded samples = 3\n",
      "2022-03-30 01:46:49 ***** Running evaluation *****\n",
      "2022-03-30 01:46:49   Num examples = 3\n",
      "2022-03-30 01:46:49   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 167.24it/s]\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-03-30 01:46:49   accuracy = 0.3333333333333333\n",
      "2022-03-30 01:46:49   macro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   micro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   support = 3\n",
      "2022-03-30 01:46:49   -1-precision = 0.0\n",
      "2022-03-30 01:46:49   -1-recall = 0.0\n",
      "2022-03-30 01:46:49   -1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   -1-support = 1\n",
      "2022-03-30 01:46:49   0-precision = 0.3333333333333333\n",
      "2022-03-30 01:46:49   0-recall = 1.0\n",
      "2022-03-30 01:46:49   0-f1-score = 0.5\n",
      "2022-03-30 01:46:49   0-support = 1\n",
      "2022-03-30 01:46:49   1-precision = 0.0\n",
      "2022-03-30 01:46:49   1-recall = 0.0\n",
      "2022-03-30 01:46:49   1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   1-support = 1\n",
      "2022-03-30 01:46:49   loss = 1.0584701299667358\n",
      "2022-03-30 01:46:49   dataset = train\n",
      "2022-03-30 01:46:49 ***** Running evaluation *****\n",
      "2022-03-30 01:46:49   Num examples = 3\n",
      "2022-03-30 01:46:49   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 184.71it/s]\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-03-30 01:46:49   accuracy = 0.3333333333333333\n",
      "2022-03-30 01:46:49   macro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   micro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   support = 3\n",
      "2022-03-30 01:46:49   -1-precision = 0.0\n",
      "2022-03-30 01:46:49   -1-recall = 0.0\n",
      "2022-03-30 01:46:49   -1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   -1-support = 1\n",
      "2022-03-30 01:46:49   0-precision = 0.3333333333333333\n",
      "2022-03-30 01:46:49   0-recall = 1.0\n",
      "2022-03-30 01:46:49   0-f1-score = 0.5\n",
      "2022-03-30 01:46:49   0-support = 1\n",
      "2022-03-30 01:46:49   1-precision = 0.0\n",
      "2022-03-30 01:46:49   1-recall = 0.0\n",
      "2022-03-30 01:46:49   1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   1-support = 1\n",
      "2022-03-30 01:46:49   loss = 1.0584701299667358\n",
      "2022-03-30 01:46:49   dataset = dev\n",
      "2022-03-30 01:46:49 ***** Running evaluation *****\n",
      "2022-03-30 01:46:49   Num examples = 3\n",
      "2022-03-30 01:46:49   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 196.16it/s]\n",
      "2022-03-30 01:46:49   accuracy = 0.3333333333333333\n",
      "2022-03-30 01:46:49   macro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   micro_f1 = 0.16666666666666666\n",
      "2022-03-30 01:46:49   support = 3\n",
      "2022-03-30 01:46:49   -1-precision = 0.0\n",
      "2022-03-30 01:46:49   -1-recall = 0.0\n",
      "2022-03-30 01:46:49   -1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   -1-support = 1\n",
      "2022-03-30 01:46:49   0-precision = 0.3333333333333333\n",
      "2022-03-30 01:46:49   0-recall = 1.0\n",
      "2022-03-30 01:46:49   0-f1-score = 0.5\n",
      "2022-03-30 01:46:49   0-support = 1\n",
      "2022-03-30 01:46:49   1-precision = 0.0\n",
      "2022-03-30 01:46:49   1-recall = 0.0\n",
      "2022-03-30 01:46:49   1-f1-score = 0.0\n",
      "2022-03-30 01:46:49   1-support = 1\n",
      "2022-03-30 01:46:49   loss = 1.0584701299667358\n",
      "2022-03-30 01:46:49   dataset = test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"python run.py --config_dir={'../config/examples/sequence_classification/BERT_AVG_explain'}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# comment train_raw_data and label if label_ratio is defined (self defined)\n",
    "\n",
    "# train_raw_data = json.load(open(f\"../data/datasets/sample/sequence_classification/train_sample.json\", 'r'))\n",
    "# label = [str(train_raw_data[i]['label']) for i in range(len(train_raw_data))]\n",
    "# print('The first three labels of trainset: \\n', label[:3])\n",
    "\n",
    "unlabel_raw_data = json.load(open(unlabel_path, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get label ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ratio of train set: \n",
      " {'-1': 0.4, '0': 0.2, '1': 0.4}\n"
     ]
    }
   ],
   "source": [
    "def get_label_ratio(label = None):\n",
    "    '''\n",
    "        input:\n",
    "        - label: list\n",
    "\n",
    "        output:\n",
    "        - label_ratio: dict\n",
    "    '''\n",
    "    if label is None and 'label_ratio' in globals():\n",
    "        return label_ratio\n",
    "    result = {}\n",
    "    for i in label:\n",
    "        # i will be replaced get_label_ratio directly\n",
    "        key = i\n",
    "        if key not in result:\n",
    "            result[key] = 0\n",
    "        result[key] = result[key] + 1/len(label)\n",
    "\n",
    "    for key in result.keys():\n",
    "        result[key] = round(result[key], 2)\n",
    "    return result\n",
    "\n",
    "# comment if user self define label ratio\n",
    "# label_ratio = get_label_ratio(label)\n",
    "\n",
    "# comment if follow train set label ratio\n",
    "label_ratio = get_label_ratio(None)\n",
    "\n",
    "print('label ratio of train set: \\n',label_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run pipeline (Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 01:46:54 ***** Existing model is provided. *****\n",
      "2022-03-30 01:46:54   Model directory = ../config/examples/sequence_classification/BERT_AVG_explain\n",
      "2022-03-30 01:46:54 ***** Initializing pipeline *****\n",
      "2022-03-30 01:46:54 ***** Loading tokenizer *****\n",
      "2022-03-30 01:46:54   Tokenizer source = 'transformers'\n",
      "2022-03-30 01:46:54 ***** Initializing model *****\n",
      "2022-03-30 01:46:54   Task = sequence_classification\n",
      "2022-03-30 01:46:54   Model class = BERT_AVG\n",
      "2022-03-30 01:46:55   Model path = ../config/examples/sequence_classification/BERT_AVG_explain/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None **********************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *********************************************************\n",
      "../config/examples/sequence_classification/BERT_AVG_explain/model/tokenizer\n",
      "['run.yaml', 'model.yaml', 'tokenizer', 'label_to_id.json', 'model.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 01:46:55 ***** Loading pretrained language model *****\n",
      "2022-03-30 01:46:55   Pretrained BERT = 'clue/albert_chinese_tiny'\n",
      "Some weights of the model checkpoint at clue/albert_chinese_tiny were not used when initializing AlbertModel: ['predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from nlp_pipeline.pipeline import Pipeline\n",
    "pipeline = Pipeline(\n",
    "    model_dir=model_dir, \n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "{'content': '\\n\\n2月9日，網上反映“一醫院領導拒絕戴口罩，途經卡點引發爭執”的視頻，新鄭市委高度重視，對此事進行了初步調查核實：\\n\\n2月8日22：00，新鄭市第三人民醫院副院長楚明輝從集中留觀隔離點結束工作返家途中，在龍湖雙湖大道疫情卡點接受檢查時，與卡點工作人員發生爭執，拒戴口罩，存在不當言行，造成了不良影響。新鄭市衛健委已經責成新鄭市第三人民醫院暫停楚明輝副院長職務。新鄭市紀委監委已成立調查組進行調查，調查結果及時向社會公佈。\\n\\n編輯：王淑\\n\\n聯繫記者\\n'}\n",
      "Output:\n",
      "{'prediction_id': 1, 'prediction': '0', 'logits': [-0.05503015220165253, 0.20401690900325775, 0.07279051840305328]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "print(unlabel_raw_data[0])\n",
    "\n",
    "output = pipeline.predict(\n",
    "    data_dict=unlabel_raw_data[0],\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits Loading (optional)\n",
    "\n",
    "loaded logit for saving prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def predict_label(dataset, pipeline):\n",
    "    '''\n",
    "        input:\n",
    "        - dataset: list\n",
    "        - pipeline\n",
    "        \n",
    "        output:\n",
    "        - list\n",
    "    '''\n",
    "    result = []\n",
    "    if 'unlabel_logits_path' in globals():\n",
    "        with open(unlabel_logits_path, 'rb') as outfile:\n",
    "            unlabel_logits = pickle.load(\n",
    "            outfile\n",
    "        )\n",
    "        for logit in unlabel_logits:\n",
    "            result.append({'probabilities': logit, 'prediction': pipeline.args.label_to_id_inv[np.argmax(logit)]})\n",
    "        return result\n",
    "    for raw_data in dataset:\n",
    "        output = pipeline.predict(\n",
    "            data_dict=raw_data,\n",
    "        )\n",
    "        output['probabilities'] = F.softmax(torch.tensor(output[\"logits\"]), dim=-1).cpu().tolist()\n",
    "        result.append(output)\n",
    "    return result\n",
    "prediction = predict_label(unlabel_raw_data, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudo label ratio of unlabel set: \n",
      " {'0': 1.0}\n"
     ]
    }
   ],
   "source": [
    "pseudo_label_id = [pred['prediction'] for pred in prediction]\n",
    "pseudo_label_ratio = get_label_ratio(pseudo_label_id)\n",
    "print('pseudo label ratio of unlabel set: \\n',pseudo_label_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of pseudo label (left column label, right column count): \n",
      " [['0' '64']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "(unique, counts) = np.unique(np.array(pseudo_label_id), return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('Frequency of pseudo label (left column label, right column count): \\n', frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def collect_probability(prediction):\n",
    "    # collect probability of prediction\n",
    "    prob_ls = []\n",
    "    for batch_pred in prediction:\n",
    "            prob_ls.append(batch_pred['probabilities'])\n",
    "    prob_np = np.array(prob_ls)\n",
    "    return prob_np\n",
    "\n",
    "def get_sampled_idx(prob_np, label_ratio, certainty, sample_size, label_to_id):\n",
    "    # sample size for labels\n",
    "    ss_idx = []\n",
    "    label_collection = {}\n",
    "    remain_size = sample_size\n",
    "    summary = {}\n",
    "    print('Important: Sampling Statistics')\n",
    "\n",
    "    for i, key in enumerate(label_ratio.keys()):\n",
    "        key_id = label_to_id[key]\n",
    "\n",
    "        # sample size computation\n",
    "        if i != len(label_ratio.keys()) - 1:\n",
    "            # sample size follows label ratio\n",
    "            key_size = int(sample_size * label_ratio[key])\n",
    "            remain_size = remain_size - key_size\n",
    "        else:\n",
    "            key_size = remain_size\n",
    "\n",
    "        # basic information of label data\n",
    "        summary[key] = []\n",
    "        label_idx = np.argwhere((prob_np.argmax(axis=1)==key_id)).flatten()\n",
    "        summary[key].append(label_idx.shape[0])\n",
    "\n",
    "        # certainty index\n",
    "        key_certain_idx = np.argwhere((prob_np.argmax(axis=1)==key_id) & (prob_np.max(axis=1)>certainty)).flatten()\n",
    "        summary[key].append(key_certain_idx.shape[0])\n",
    "\n",
    "        summary[key].append(key_size)\n",
    "\n",
    "        # warning if not able to sample enough data (filtered size is smaller than required size)\n",
    "        if key_size > key_certain_idx.shape[0]:\n",
    "            print('\\t(Warning: only sample ',key_certain_idx.shape[0], ' example(s) for label ',key,' because required size > filtered size)')\n",
    "            if key_size <= label_idx.shape[0]:\n",
    "                print('label ',key,':\\t(Suggested Certainty for label ', key,': ', np.sort(prob_np.max(axis=1)[(prob_np.argmax(axis=1)==key_id)])[-key_size], ')')\n",
    "            else:\n",
    "                print('label ',key,':\\t(Suggested Ratio for label ', key,': ', label_idx.shape[0]/sample_size,')')\n",
    "            key_size = key_certain_idx.shape[0]\n",
    "\n",
    "        # append sampled index to list\n",
    "        ss_idx = ss_idx + (random.sample(key_certain_idx.tolist(), key_size))\n",
    "        label_collection[key] = key_size\n",
    "\n",
    "    summary['total'] = ['', len(ss_idx), sample_size]\n",
    "    print (\"\\nSummary Table:\\n{:<25} {:<25} {:<25} {:<25}\".format('label\\size','all','filtered (certainty>'+str(certainty)+')','required'))\n",
    "    for k, v in summary.items():\n",
    "        total, filtered, required = v\n",
    "        print (\"{:<25} {:<25} {:<25} {:<25}\".format(k, total, filtered, required))\n",
    "    return ss_idx\n",
    "\n",
    "def extract_data(data, idx):\n",
    "    # indexing unlabel data\n",
    "    unlabel_data = np.array(data)\n",
    "    return unlabel_data[idx].tolist()\n",
    "\n",
    "def extract_logits(prop_np, idx):\n",
    "    return prop_np[idx].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling Statisitcs\n",
    "\n",
    "Important summary of sampling results, required data size is calculated by sample size times label ratio. Generally, total filtered data size (> certainty) should be the same with required size. Else, warning will be popped up.\n",
    "\n",
    "- required size > label size : suggest to edit the label ratio\n",
    "- required size <= label size & required size >= filtered size (> certainty) : suggest to edit certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important: Sampling Statistics\n",
      "\t(Warning: only sample  0  example(s) for label  -1  because required size > filtered size)\n",
      "label  -1 :\t(Suggested Ratio for label  -1 :  0.0 )\n",
      "\t(Warning: only sample  0  example(s) for label  1  because required size > filtered size)\n",
      "label  1 :\t(Suggested Ratio for label  1 :  0.0 )\n",
      "\n",
      "Summary Table:\n",
      "label\\size                all                       filtered (certainty>0)    required                 \n",
      "-1                        0                         0                         4                        \n",
      "0                         64                        64                        2                        \n",
      "1                         0                         0                         4                        \n",
      "total                                               2                         10                       \n"
     ]
    }
   ],
   "source": [
    "def sampling(unlabel_dataset, prediction, label_ratio, certainty, sample_size, label_to_id):\n",
    "    '''\n",
    "        input:\n",
    "        - unlabel_dataset: list\n",
    "        - pseudo_label: list\n",
    "        - label_ratio: dict\n",
    "        - certainty: float\n",
    "        - label_to_id: dict\n",
    "\n",
    "        output:\n",
    "        - list\n",
    "    '''\n",
    "    # collect probability of prediction\n",
    "    prob_np = collect_probability(prediction)\n",
    "\n",
    "    # get sampled index\n",
    "    idx = get_sampled_idx(prob_np, label_ratio, certainty, sample_size, label_to_id)\n",
    "\n",
    "    # indexing unlabel data\n",
    "    sampled_data = extract_data(unlabel_dataset, idx)\n",
    "\n",
    "    # indexing unlabel logits\n",
    "    sampled_logits = extract_logits(prob_np, idx)\n",
    "\n",
    "    return sampled_data, sampled_logits\n",
    "\n",
    "sampled_data, sampled_logits = sampling(\n",
    "    unlabel_dataset = unlabel_raw_data, \n",
    "    prediction = prediction, \n",
    "    label_ratio = label_ratio, \n",
    "    certainty = certainty,\n",
    "    sample_size = sample_size,\n",
    "    label_to_id = pipeline.args.label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of sampled data:  2\n",
      "Overview of first sampled data {'content': '\\u3000\\u30008日，廣東省藥品監督管理局發佈最新消息稱，同意廣州市第八人民醫院申報的透解祛瘟顆粒（“肺炎1號方”）醫療機構製劑備案和調劑使用有關事宜，允許廣東省新冠肺炎30家定點救治醫院，根據臨床需要直接調劑使用該方。\\n\\n\\u3000\\u3000（陳澤雲）\\n'} \n",
      "\n",
      "Total size of sampled logits:  2\n",
      "Overview of first sampled logits [0.29616403579711914, 0.3757517635822296, 0.32808417081832886]\n"
     ]
    }
   ],
   "source": [
    "print('Total size of sampled data: ', len(sampled_data))\n",
    "print('Overview of first sampled data', sampled_data[0],'\\n')\n",
    "print('Total size of sampled logits: ', len(sampled_logits))\n",
    "print('Overview of first sampled logits', sampled_logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save dataset and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(sample_data: list, save_path: str):\n",
    "    with open(save_path, 'w') as outfile:\n",
    "        json.dump(sample_data, outfile)\n",
    "\n",
    "def save_logit(sample_logits: list, save_path: str):\n",
    "    import pickle\n",
    "    with open(save_path, 'wb') as outfile:\n",
    "        pickle.dump(sample_logits, outfile)\n",
    "\n",
    "save_data_path = save_dir + '/' + save_data_file\n",
    "save_logit_path = save_dir + '/' + save_logit_file\n",
    "save_data(sampled_data, save_data_path)\n",
    "save_logit(sampled_logits, save_logit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of samples:  2\n",
      "First sample of result:  {'content': '\\u3000\\u30008日，廣東省藥品監督管理局發佈最新消息稱，同意廣州市第八人民醫院申報的透解祛瘟顆粒（“肺炎1號方”）醫療機構製劑備案和調劑使用有關事宜，允許廣東省新冠肺炎30家定點救治醫院，根據臨床需要直接調劑使用該方。\\n\\n\\u3000\\u3000（陳澤雲）\\n'}\n"
     ]
    }
   ],
   "source": [
    "with open(save_data_path, 'rb') as outfile:\n",
    "    result = json.load(outfile)\n",
    "print('Total num of samples: ',len(result))\n",
    "print('First sample of result: ', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export variables for (unittest)\n",
    "- test_length\n",
    "- test_pseudo_label_ratio\n",
    "- test_certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_certainty(prob):\n",
    "    min_prob = 1.0\n",
    "    for p in prob:\n",
    "        if max(p) < min_prob:\n",
    "            min_prob = max(p)\n",
    "    return min_prob\n",
    "\n",
    "prediction = predict_label(result, pipeline)\n",
    "result_probability = [pred['probabilities'] for pred in prediction]\n",
    "min_certainty = get_min_certainty(result_probability)\n",
    "result_label_id = [pred['prediction'] for pred in prediction]\n",
    "result_label_ratio = get_label_ratio(result_label_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_label_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 2,
       "encoder": "json",
       "name": "length",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "length"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "0": 1
       },
       "encoder": "json",
       "name": "label_ratio",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "label_ratio"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.3757517635822296,
       "encoder": "json",
       "name": "min_certainty",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "min_certainty"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scrapbook as sb\n",
    "sb.glue(\"length\", len(result))\n",
    "sb.glue(\"label_ratio\", result_label_ratio)\n",
    "sb.glue(\"min_certainty\", min_certainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove file\n",
    "\n",
    "This part removes saved files and cleans direcotry, skip below if saving data and model\n",
    "- code 0: sucessful removal\n",
    "- code 256: failed removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove saved result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(f\"rm {save_data_path}\"))\n",
    "print(os.system(f\"rm {save_logit_path}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove trained model (if demo model is existed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(f\"rm -rf {model_dir}/result\"))\n",
    "print(os.system(f\"rm -rf {model_dir}/model\"))\n",
    "print(os.system(f\"rm -rf {model_dir}/logs\"))\n",
    "print(os.system(f\"rm {model_dir}/log\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
