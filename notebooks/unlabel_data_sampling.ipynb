{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User can sample label ratio based on the ratio of train set, or request desired label ratio. It depends on existence of argument (either input this argument or not):\n",
    "\n",
    "- label_ratio (if required desired label ratio)\n",
    "\n",
    "remarks: Model directory is required to predict labels for unlabel data in order to sample data which includes\n",
    "- model directory\n",
    "    - run.yaml\n",
    "    - model.yaml\n",
    "    - label_to_id.json\n",
    "    - model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment if user samples label ratio based on the ratio of train set\n",
    "label_ratio = {'-1': 0.4, '0': 0.2, '1': 0.4} # optional \n",
    "\n",
    "# unlabel path (json file name included)\n",
    "unlabel_path = '../data/datasets/sample/sequence_classification/unlabeled_sample.json' \n",
    "\n",
    "# model directory, must include above files\n",
    "model_dir = '../config/examples/sequence_classification/BERT_AVG_explain' # required argument \n",
    "\n",
    "# save directory\n",
    "save_dir = '../data/datasets/sample/sequence_classification' # required \n",
    "save_data_file = 'sampled_unlabel_data.json' # required \n",
    "save_logit_file = 'sampled_unlabel_logits.pkl' # required \n",
    "\n",
    "# sample size and certainty\n",
    "sample_size = 10 # required, integer and smaller than size of unlabeled data\n",
    "certainty = 0 # optional, only select the data that max(p)>certainty, \n",
    "                # p is the predicted probabilities (0 - 1) over the label space\n",
    "                # default certainty is 0\n",
    "\n",
    "device = 0\n",
    "\n",
    "src_dir = '../nlp_pipeline' # optional, default source directory is nlp_pipeline folder\n",
    "\n",
    "# unlabel_logits_path = '../data/datasets/sample/sequence_classification/sampled_unlabel_logits.pkl' # optional, use to extract logit information instead of prediction for saving time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "From data augmentation experiment for Apple Care 2 dataset, highlighted factors can ensure the quality of unlabeled dataset which enhance the performance of model.\n",
    "\n",
    "Experiment details in [2022_01_13 biweekly discussion.pptx](https://jira.wisers.com:18090/download/attachments/82808396/2022_01_13%20biweekly%20discussion.pptx?version=1&modificationDate=1642063801000&api=v2)\n",
    "\n",
    "For code design please browse [Confluence Proposed Module](https://jira.wisers.com:18090/display/RES/Proposed+Module2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "src_dir = '../nlp_pipeline'\n",
    "os.chdir(src_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generation\n",
    "\n",
    "- train a demo model for predict unlabel data in demonstration\n",
    "\n",
    "If you have specified trained model path:\n",
    "- comment below cell\n",
    "- comment the last cell (used to remove demo model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None **********************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *********************************************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *****\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model/tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 07:25:11 ***** Args *****\n",
      "2022-03-28 07:25:11    task: sequence_classification\n",
      "2022-03-28 07:25:11    device: 0\n",
      "2022-03-28 07:25:11    data: {'output_dir': '../config/examples/sequence_classification/BERT_AVG_explain', 'data_dir': '../data/datasets/sample/sequence_classification', 'train': 'train_sample.json', 'dev': 'train_sample.json', 'test': 'train_sample.json'}\n",
      "2022-03-28 07:25:11    text_prepro: {'steps': ['utf8_replace', 'simplified_chinese', 'lower_case', 'full_to_half']}\n",
      "2022-03-28 07:25:11    eval: {'batch_size': 64, 'model_file': 'model.pt'}\n",
      "2022-03-28 07:25:11    train: {'model_class': 'BERT_AVG', 'seed': 42, 'log_steps': 100, 'batch_size': 32, 'final_model': 'best', 'optimization_metric': 'macro_f1', 'early_stop': 5}\n",
      "2022-03-28 07:25:11    model_params: {'num_train_epochs': 2, 'embedding_trainable': True, 'output_hidden_act_func': 'PReLU', 'output_hidden_dim': 128, 'tokenizer_name': 'clue/albert_chinese_tiny', 'pretrained_lm': 'clue/albert_chinese_tiny'}\n",
      "2022-03-28 07:25:11    explanation: {'Random': {'method': 'Random'}, 'Lime': {'method': 'Lime'}, 'WordOmission': {'method': 'WordOmission'}, 'SaliencyAvg': {'method': 'Saliency', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'SaliencyL2': {'method': 'Saliency', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'GradientXActivationAvg': {'method': 'GradientXActivation', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'GradientXActivationL2': {'method': 'GradientXActivation', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'IntegratedGradientsAvg': {'method': 'IntegratedGradients', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'IntegratedGradientsL2': {'method': 'IntegratedGradients', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'DeepLiftAvg': {'method': 'DeepLift', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'DeepLiftL2': {'method': 'DeepLift', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}}\n",
      "2022-03-28 07:25:11 ***** Loading tokenizer *****\n",
      "2022-03-28 07:25:11   Tokenizer source = 'transformers'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run.yaml', 'model.yaml', 'tokenizer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 07:25:16 ***** Initializing model *****\n",
      "2022-03-28 07:25:16   Task = sequence_classification\n",
      "2022-03-28 07:25:16   Model class = BERT_AVG\n",
      "2022-03-28 07:25:17 ***** Loading pretrained language model *****\n",
      "2022-03-28 07:25:17   Pretrained BERT = 'clue/albert_chinese_tiny'\n",
      "2022-03-28 07:25:24 ***** Loading data *****\n",
      "2022-03-28 07:25:24   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 81.32it/s]\n",
      "2022-03-28 07:25:24   Loaded samples = 3\n",
      "2022-03-28 07:25:24 ***** Loading data *****\n",
      "2022-03-28 07:25:24   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 110.17it/s]\n",
      "2022-03-28 07:25:24   Loaded samples = 3\n",
      "2022-03-28 07:25:24 ***** Running training *****\n",
      "2022-03-28 07:25:24   Num examples = 3\n",
      "2022-03-28 07:25:24   Num Epochs = 2\n",
      "2022-03-28 07:25:24   Sampler = \n",
      "2022-03-28 07:25:24   Batch size = 32\n",
      "2022-03-28 07:25:24   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.64it/s, tr_loss=1.06]\n",
      "2022-03-28 07:25:24 ***** Epoch end: 0 *****\n",
      "2022-03-28 07:25:24 ***** Running evaluation *****\n",
      "2022-03-28 07:25:24   Num examples = 3\n",
      "2022-03-28 07:25:24   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 180.25it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-03-28 07:25:24   accuracy = 0.6666666666666666\n",
      "2022-03-28 07:25:24   macro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   micro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   support = 3\n",
      "2022-03-28 07:25:24   -1-precision = 1.0\n",
      "2022-03-28 07:25:24   -1-recall = 1.0\n",
      "2022-03-28 07:25:24   -1-f1-score = 1.0\n",
      "2022-03-28 07:25:24   -1-support = 1\n",
      "2022-03-28 07:25:24   0-precision = 0.0\n",
      "2022-03-28 07:25:24   0-recall = 0.0\n",
      "2022-03-28 07:25:24   0-f1-score = 0.0\n",
      "2022-03-28 07:25:24   0-support = 1\n",
      "2022-03-28 07:25:24   1-precision = 0.5\n",
      "2022-03-28 07:25:24   1-recall = 1.0\n",
      "2022-03-28 07:25:24   1-f1-score = 0.6666666666666666\n",
      "2022-03-28 07:25:24   1-support = 1\n",
      "2022-03-28 07:25:24   loss = 1.0365409851074219\n",
      "2022-03-28 07:25:24   dataset = dev\n",
      "\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 53.65it/s, tr_loss=1.04]\n",
      "2022-03-28 07:25:24 ***** Epoch end: 1 *****\n",
      "2022-03-28 07:25:24 ***** Running evaluation *****\n",
      "2022-03-28 07:25:24   Num examples = 3\n",
      "2022-03-28 07:25:24   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 191.92it/s]\n",
      "2022-03-28 07:25:24   accuracy = 0.6666666666666666\n",
      "2022-03-28 07:25:24   macro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   micro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   support = 3\n",
      "2022-03-28 07:25:24   -1-precision = 1.0\n",
      "2022-03-28 07:25:24   -1-recall = 1.0\n",
      "2022-03-28 07:25:24   -1-f1-score = 1.0\n",
      "2022-03-28 07:25:24   -1-support = 1\n",
      "2022-03-28 07:25:24   0-precision = 0.0\n",
      "2022-03-28 07:25:24   0-recall = 0.0\n",
      "2022-03-28 07:25:24   0-f1-score = 0.0\n",
      "2022-03-28 07:25:24   0-support = 1\n",
      "2022-03-28 07:25:24   1-precision = 0.5\n",
      "2022-03-28 07:25:24   1-recall = 1.0\n",
      "2022-03-28 07:25:24   1-f1-score = 0.6666666666666666\n",
      "2022-03-28 07:25:24   1-support = 1\n",
      "2022-03-28 07:25:24   loss = 1.0233073234558105\n",
      "2022-03-28 07:25:24   dataset = dev\n",
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 22.16it/s]\n",
      "2022-03-28 07:25:24 ***** Training end *****\n",
      "2022-03-28 07:25:24   Model path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model/model.pt\n",
      "2022-03-28 07:25:24 ***** Loading data *****\n",
      "2022-03-28 07:25:24   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 99.80it/s]\n",
      "2022-03-28 07:25:24   Loaded samples = 3\n",
      "2022-03-28 07:25:24 ***** Running evaluation *****\n",
      "2022-03-28 07:25:24   Num examples = 3\n",
      "2022-03-28 07:25:24   Batch size = 64\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 170.00it/s]\n",
      "2022-03-28 07:25:24   accuracy = 0.6666666666666666\n",
      "2022-03-28 07:25:24   macro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   micro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   support = 3\n",
      "2022-03-28 07:25:24   -1-precision = 1.0\n",
      "2022-03-28 07:25:24   -1-recall = 1.0\n",
      "2022-03-28 07:25:24   -1-f1-score = 1.0\n",
      "2022-03-28 07:25:24   -1-support = 1\n",
      "2022-03-28 07:25:24   0-precision = 0.0\n",
      "2022-03-28 07:25:24   0-recall = 0.0\n",
      "2022-03-28 07:25:24   0-f1-score = 0.0\n",
      "2022-03-28 07:25:24   0-support = 1\n",
      "2022-03-28 07:25:24   1-precision = 0.5\n",
      "2022-03-28 07:25:24   1-recall = 1.0\n",
      "2022-03-28 07:25:24   1-f1-score = 0.6666666666666666\n",
      "2022-03-28 07:25:24   1-support = 1\n",
      "2022-03-28 07:25:24   loss = 1.0365409851074219\n",
      "2022-03-28 07:25:24   dataset = train\n",
      "2022-03-28 07:25:24 ***** Running evaluation *****\n",
      "2022-03-28 07:25:24   Num examples = 3\n",
      "2022-03-28 07:25:24   Batch size = 64\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 207.61it/s]\n",
      "2022-03-28 07:25:24   accuracy = 0.6666666666666666\n",
      "2022-03-28 07:25:24   macro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   micro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   support = 3\n",
      "2022-03-28 07:25:24   -1-precision = 1.0\n",
      "2022-03-28 07:25:24   -1-recall = 1.0\n",
      "2022-03-28 07:25:24   -1-f1-score = 1.0\n",
      "2022-03-28 07:25:24   -1-support = 1\n",
      "2022-03-28 07:25:24   0-precision = 0.0\n",
      "2022-03-28 07:25:24   0-recall = 0.0\n",
      "2022-03-28 07:25:24   0-f1-score = 0.0\n",
      "2022-03-28 07:25:24   0-support = 1\n",
      "2022-03-28 07:25:24   1-precision = 0.5\n",
      "2022-03-28 07:25:24   1-recall = 1.0\n",
      "2022-03-28 07:25:24   1-f1-score = 0.6666666666666666\n",
      "2022-03-28 07:25:24   1-support = 1\n",
      "2022-03-28 07:25:24   loss = 1.0365409851074219\n",
      "2022-03-28 07:25:24   dataset = dev\n",
      "2022-03-28 07:25:24 ***** Running evaluation *****\n",
      "2022-03-28 07:25:24   Num examples = 3\n",
      "2022-03-28 07:25:24   Batch size = 64\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 196.73it/s]\n",
      "2022-03-28 07:25:24   accuracy = 0.6666666666666666\n",
      "2022-03-28 07:25:24   macro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   micro_f1 = 0.5555555555555555\n",
      "2022-03-28 07:25:24   support = 3\n",
      "2022-03-28 07:25:24   -1-precision = 1.0\n",
      "2022-03-28 07:25:24   -1-recall = 1.0\n",
      "2022-03-28 07:25:24   -1-f1-score = 1.0\n",
      "2022-03-28 07:25:24   -1-support = 1\n",
      "2022-03-28 07:25:24   0-precision = 0.0\n",
      "2022-03-28 07:25:24   0-recall = 0.0\n",
      "2022-03-28 07:25:24   0-f1-score = 0.0\n",
      "2022-03-28 07:25:24   0-support = 1\n",
      "2022-03-28 07:25:24   1-precision = 0.5\n",
      "2022-03-28 07:25:24   1-recall = 1.0\n",
      "2022-03-28 07:25:24   1-f1-score = 0.6666666666666666\n",
      "2022-03-28 07:25:24   1-support = 1\n",
      "2022-03-28 07:25:24   loss = 1.0365409851074219\n",
      "2022-03-28 07:25:24   dataset = test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"python run.py --config_dir={'../config/examples/sequence_classification/BERT_AVG_explain'}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# comment train_raw_data and label if label_ratio is defined (self defined)\n",
    "\n",
    "# train_raw_data = json.load(open(f\"../data/datasets/sample/sequence_classification/train_sample.json\", 'r'))\n",
    "# label = [str(train_raw_data[i]['label']) for i in range(len(train_raw_data))]\n",
    "# print('The first three labels of trainset: \\n', label[:3])\n",
    "\n",
    "unlabel_raw_data = json.load(open(unlabel_path, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get label ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ratio of train set: \n",
      " {'-1': 0.4, '0': 0.2, '1': 0.4}\n"
     ]
    }
   ],
   "source": [
    "def get_label_ratio(label = None):\n",
    "    '''\n",
    "        input:\n",
    "        - label: list\n",
    "\n",
    "        output:\n",
    "        - label_ratio: dict\n",
    "    '''\n",
    "    if label is None and 'label_ratio' in globals():\n",
    "        return label_ratio\n",
    "    result = {}\n",
    "    for i in label:\n",
    "        # i will be replaced get_label_ratio directly\n",
    "        key = i\n",
    "        if key not in result:\n",
    "            result[key] = 0\n",
    "        result[key] = result[key] + 1/len(label)\n",
    "\n",
    "    for key in result.keys():\n",
    "        result[key] = round(result[key], 2)\n",
    "    return result\n",
    "\n",
    "# comment if user self define label ratio\n",
    "# label_ratio = get_label_ratio(label)\n",
    "\n",
    "# comment if follow train set label ratio\n",
    "label_ratio = get_label_ratio(None)\n",
    "\n",
    "print('label ratio of train set: \\n',label_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run pipeline (Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 07:25:29 ***** Existing model is provided. *****\n",
      "2022-03-28 07:25:29   Model directory = ../config/examples/sequence_classification/BERT_AVG_explain\n",
      "2022-03-28 07:25:29 ***** Initializing pipeline *****\n",
      "2022-03-28 07:25:29 ***** Loading tokenizer *****\n",
      "2022-03-28 07:25:29   Tokenizer source = 'transformers'\n",
      "2022-03-28 07:25:29 ***** Initializing model *****\n",
      "2022-03-28 07:25:29   Task = sequence_classification\n",
      "2022-03-28 07:25:29   Model class = BERT_AVG\n",
      "2022-03-28 07:25:29   Model path = ../config/examples/sequence_classification/BERT_AVG_explain/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None **********************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *********************************************************\n",
      "../config/examples/sequence_classification/BERT_AVG_explain/model/tokenizer\n",
      "['run.yaml', 'model.yaml', 'tokenizer', 'label_to_id.json', 'model.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 07:25:30 ***** Loading pretrained language model *****\n",
      "2022-03-28 07:25:30   Pretrained BERT = 'clue/albert_chinese_tiny'\n"
     ]
    }
   ],
   "source": [
    "from nlp_pipeline.pipeline import Pipeline\n",
    "pipeline = Pipeline(\n",
    "    model_dir=model_dir, \n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "{'content': '\\n\\n2æœˆ9æ—¥ï¼Œç¶²ä¸Šåæ˜ â€œä¸€é†«é™¢é ˜å°æ‹’çµ•æˆ´å£ç½©ï¼Œé€”ç¶“å¡é»å¼•ç™¼çˆ­åŸ·â€çš„è¦–é »ï¼Œæ–°é„­å¸‚å§”é«˜åº¦é‡è¦–ï¼Œå°æ­¤äº‹é€²è¡Œäº†åˆæ­¥èª¿æŸ¥æ ¸å¯¦ï¼š\\n\\n2æœˆ8æ—¥22ï¼š00ï¼Œæ–°é„­å¸‚ç¬¬ä¸‰äººæ°‘é†«é™¢å‰¯é™¢é•·æ¥šæ˜è¼å¾é›†ä¸­ç•™è§€éš”é›¢é»çµæŸå·¥ä½œè¿”å®¶é€”ä¸­ï¼Œåœ¨é¾æ¹–é›™æ¹–å¤§é“ç–«æƒ…å¡é»æ¥å—æª¢æŸ¥æ™‚ï¼Œèˆ‡å¡é»å·¥ä½œäººå“¡ç™¼ç”Ÿçˆ­åŸ·ï¼Œæ‹’æˆ´å£ç½©ï¼Œå­˜åœ¨ä¸ç•¶è¨€è¡Œï¼Œé€ æˆäº†ä¸è‰¯å½±éŸ¿ã€‚æ–°é„­å¸‚è¡›å¥å§”å·²ç¶“è²¬æˆæ–°é„­å¸‚ç¬¬ä¸‰äººæ°‘é†«é™¢æš«åœæ¥šæ˜è¼å‰¯é™¢é•·è·å‹™ã€‚æ–°é„­å¸‚ç´€å§”ç›£å§”å·²æˆç«‹èª¿æŸ¥çµ„é€²è¡Œèª¿æŸ¥ï¼Œèª¿æŸ¥çµæœåŠæ™‚å‘ç¤¾æœƒå…¬ä½ˆã€‚\\n\\nç·¨è¼¯ï¼šç‹æ·‘\\n\\nè¯ç¹«è¨˜è€…\\n'}\n",
      "Output:\n",
      "{'prediction_id': 0, 'prediction': '1', 'logits': [0.06629689037799835, -0.08389206230640411, 0.03349928930401802]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "print(unlabel_raw_data[0])\n",
    "\n",
    "output = pipeline.predict(\n",
    "    data_dict=unlabel_raw_data[0],\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits Loading (optional)\n",
    "\n",
    "loaded logit for saving prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def predict_label(dataset, pipeline):\n",
    "    '''\n",
    "        input:\n",
    "        - dataset: list\n",
    "        - pipeline\n",
    "        \n",
    "        output:\n",
    "        - list\n",
    "    '''\n",
    "    result = []\n",
    "    if 'unlabel_logits_path' in globals():\n",
    "        with open(unlabel_logits_path, 'rb') as outfile:\n",
    "            unlabel_logits = pickle.load(\n",
    "            outfile\n",
    "        )\n",
    "        for logit in unlabel_logits:\n",
    "            result.append({'probabilities': logit, 'prediction': pipeline.args.label_to_id_inv[np.argmax(logit)]})\n",
    "        return result\n",
    "    for raw_data in dataset:\n",
    "        output = pipeline.predict(\n",
    "            data_dict=raw_data,\n",
    "        )\n",
    "        output['probabilities'] = F.softmax(torch.tensor(output[\"logits\"]), dim=-1).cpu().tolist()\n",
    "        result.append(output)\n",
    "    return result\n",
    "prediction = predict_label(unlabel_raw_data, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudo label ratio of unlabel set: \n",
      " {'1': 0.69, '-1': 0.28, '0': 0.03}\n"
     ]
    }
   ],
   "source": [
    "pseudo_label_id = [pred['prediction'] for pred in prediction]\n",
    "pseudo_label_ratio = get_label_ratio(pseudo_label_id)\n",
    "print('pseudo label ratio of unlabel set: \\n',pseudo_label_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of pseudo label (left column label, right column count): \n",
      " [['-1' '18']\n",
      " ['0' '2']\n",
      " ['1' '44']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "(unique, counts) = np.unique(np.array(pseudo_label_id), return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('Frequency of pseudo label (left column label, right column count): \\n', frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def collect_probability(prediction):\n",
    "    # collect probability of prediction\n",
    "    prob_ls = []\n",
    "    for batch_pred in prediction:\n",
    "            prob_ls.append(batch_pred['probabilities'])\n",
    "    prob_np = np.array(prob_ls)\n",
    "    return prob_np\n",
    "\n",
    "def get_sampled_idx(prob_np, label_ratio, certainty, sample_size, label_to_id):\n",
    "    # sample size for labels\n",
    "    ss_idx = []\n",
    "    label_collection = {}\n",
    "    remain_size = sample_size\n",
    "    summary = {}\n",
    "    print('Important: Sampling Statistics')\n",
    "\n",
    "    for i, key in enumerate(label_ratio.keys()):\n",
    "        key_id = label_to_id[key]\n",
    "\n",
    "        # sample size computation\n",
    "        if i != len(label_ratio.keys()) - 1:\n",
    "            # sample size follows label ratio\n",
    "            key_size = int(sample_size * label_ratio[key])\n",
    "            remain_size = remain_size - key_size\n",
    "        else:\n",
    "            key_size = remain_size\n",
    "\n",
    "        # basic information of label data\n",
    "        summary[key] = []\n",
    "        label_idx = np.argwhere((prob_np.argmax(axis=1)==key_id)).flatten()\n",
    "        summary[key].append(label_idx.shape[0])\n",
    "\n",
    "        # certainty index\n",
    "        key_certain_idx = np.argwhere((prob_np.argmax(axis=1)==key_id) & (prob_np.max(axis=1)>certainty)).flatten()\n",
    "        summary[key].append(key_certain_idx.shape[0])\n",
    "\n",
    "        summary[key].append(key_size)\n",
    "\n",
    "        # warning if not able to sample enough data (filtered size is smaller than required size)\n",
    "        if key_size > key_certain_idx.shape[0]:\n",
    "            print('\\t(Warning: only sample ',key_certain_idx.shape[0], ' example(s) for label ',key,' because required size > filtered size)')\n",
    "            if key_size <= label_idx.shape[0]:\n",
    "                print('label ',key,':\\t(Suggested Certainty for label ', key,': ', np.sort(prob_np.max(axis=1)[(prob_np.argmax(axis=1)==key_id)])[-key_size], ')')\n",
    "            else:\n",
    "                print('label ',key,':\\t(Suggested Ratio for label ', key,': ', label_idx.shape[0]/sample_size,')')\n",
    "            key_size = key_certain_idx.shape[0]\n",
    "\n",
    "        # append sampled index to list\n",
    "        ss_idx = ss_idx + (random.sample(key_certain_idx.tolist(), key_size))\n",
    "        label_collection[key] = key_size\n",
    "\n",
    "    summary['total'] = ['', len(ss_idx), sample_size]\n",
    "    print (\"\\nSummary Table:\\n{:<25} {:<25} {:<25} {:<25}\".format('label\\size','all','filtered (certainty>'+str(certainty)+')','required'))\n",
    "    for k, v in summary.items():\n",
    "        total, filtered, required = v\n",
    "        print (\"{:<25} {:<25} {:<25} {:<25}\".format(k, total, filtered, required))\n",
    "    return ss_idx\n",
    "\n",
    "def extract_data(data, idx):\n",
    "    # indexing unlabel data\n",
    "    unlabel_data = np.array(data)\n",
    "    return unlabel_data[idx].tolist()\n",
    "\n",
    "def extract_logits(prop_np, idx):\n",
    "    return prop_np[idx].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling Statisitcs\n",
    "\n",
    "Important summary of sampling results, required data size is calculated by sample size times label ratio. Generally, total filtered data size (> certainty) should be the same with required size. Else, warning will be popped up.\n",
    "\n",
    "- required size > label size : suggest to edit the label ratio\n",
    "- required size <= label size & required size >= filtered size (> certainty) : suggest to edit certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important: Sampling Statistics\n",
      "\n",
      "Summary Table:\n",
      "label\\size                all                       filtered (certainty>0)    required                 \n",
      "-1                        18                        18                        4                        \n",
      "0                         2                         2                         2                        \n",
      "1                         44                        44                        4                        \n",
      "total                                               10                        10                       \n"
     ]
    }
   ],
   "source": [
    "def sampling(unlabel_dataset, prediction, label_ratio, certainty, sample_size, label_to_id):\n",
    "    '''\n",
    "        input:\n",
    "        - unlabel_dataset: list\n",
    "        - pseudo_label: list\n",
    "        - label_ratio: dict\n",
    "        - certainty: float\n",
    "        - label_to_id: dict\n",
    "\n",
    "        output:\n",
    "        - list\n",
    "    '''\n",
    "    # collect probability of prediction\n",
    "    prob_np = collect_probability(prediction)\n",
    "\n",
    "    # get sampled index\n",
    "    idx = get_sampled_idx(prob_np, label_ratio, certainty, sample_size, label_to_id)\n",
    "\n",
    "    # indexing unlabel data\n",
    "    sampled_data = extract_data(unlabel_dataset, idx)\n",
    "\n",
    "    # indexing unlabel logits\n",
    "    sampled_logits = extract_logits(prob_np, idx)\n",
    "\n",
    "    return sampled_data, sampled_logits\n",
    "\n",
    "sampled_data, sampled_logits = sampling(\n",
    "    unlabel_dataset = unlabel_raw_data, \n",
    "    prediction = prediction, \n",
    "    label_ratio = label_ratio, \n",
    "    certainty = certainty,\n",
    "    sample_size = sample_size,\n",
    "    label_to_id = pipeline.args.label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of sampled data:  10\n",
      "Overview of first sampled data {'content': '\\n\\næˆ‘æƒ³è¦çš„æœªä¾†ï¼Œæ˜¯çœ‹å¾—åˆ°...............................................................................................................................................å®‰ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚å…¨ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚\\n\\nå¾æˆ‘åšèµ·\\n\\nç‚ºäº†å¤§å®¶çš„å®‰å…¨\\n\\nç‚ºäº†ä¸€ç·šçš„é€†è¡Œè€…\\n\\næ—©æ—¥å›å®¶åœ˜åœ“\\n\\nè«‹è‡ªè¦ºè‡ªé¡˜\\n\\nåœ¨å®¶é‡Œå®ˆä½ä¸€é¡†å¿ƒï¼Œ\\n\\né»˜é»˜ç¥ˆç¦ä¸­åœ‹å¹³å®‰ï¼\\n\\nä¸è¦å˜´é‡Œå–Šè‘—å£è™Ÿ\\n\\næ‰‹é‡Œæ•¸è‘—é»‘å¿ƒéŒ¢\\n\\næ›´ä¸è¦\\n\\néš¨æ„æŠŠè¬ è¨€äº‚æ’­äº‚å‚³\\n\\nè…³æ­¥éš¨ç”Ÿé¢¨\\n\\nåˆ°è™•äº‚è½‰äº‚ç«„\\n\\nå‘†åœ¨å®¶é‡Œç‚ºç¥–åœ‹å¥‰ç»\\n\\nä¸€èµ·åº¦éé›£é—œ\\n\\nç¥ˆç¦ä¸­åœ‹å¹³å®‰ï¼\\n\\nåšä¸€å€‹ç¨±è·çš„å¥½å…¬æ°‘\\n\\nä¸å¦„ç‚º\\n\\nä¸€ç”Ÿä¸€ä¸–çš„å¥½æ°£ç¯€ï¼\\n\\nä¸­åœ‹åŠ æ²¹ï¼\\n\\nä¸­åœ‹å¹³å®‰ï¼\\n\\næˆ‘æƒ³è¦çš„æœªä¾†ï¼Œæ˜¯çœ‹å¾—åˆ°...............................................................................................................................................å®‰ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚å…¨ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚\\n\\né»æ“Šç¹¼çºŒé–±è®€\\n\\nè¦ºå¾—ä¸éŒ¯ï¼Œè«‹é»å€‹åœ¨çœ‹ğŸ‘‡ğŸ‘‡\\n\\n\\n'} \n",
      "\n",
      "Total size of sampled logits:  10\n",
      "Overview of first sampled logits [0.295995831489563, 0.29114410281181335, 0.4128601551055908]\n"
     ]
    }
   ],
   "source": [
    "print('Total size of sampled data: ', len(sampled_data))\n",
    "print('Overview of first sampled data', sampled_data[0],'\\n')\n",
    "print('Total size of sampled logits: ', len(sampled_logits))\n",
    "print('Overview of first sampled logits', sampled_logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save dataset and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(sample_data: list, save_path: str):\n",
    "    with open(save_path, 'w') as outfile:\n",
    "        json.dump(sample_data, outfile)\n",
    "\n",
    "def save_logit(sample_logits: list, save_path: str):\n",
    "    import pickle\n",
    "    with open(save_path, 'wb') as outfile:\n",
    "        pickle.dump(sample_logits, outfile)\n",
    "\n",
    "save_data_path = save_dir + '/' + save_data_file\n",
    "save_logit_path = save_dir + '/' + save_logit_file\n",
    "save_data(sampled_data, save_data_path)\n",
    "save_logit(sampled_logits, save_logit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of samples:  10\n",
      "First sample of result:  {'content': '\\n\\næˆ‘æƒ³è¦çš„æœªä¾†ï¼Œæ˜¯çœ‹å¾—åˆ°...............................................................................................................................................å®‰ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚å…¨ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚\\n\\nå¾æˆ‘åšèµ·\\n\\nç‚ºäº†å¤§å®¶çš„å®‰å…¨\\n\\nç‚ºäº†ä¸€ç·šçš„é€†è¡Œè€…\\n\\næ—©æ—¥å›å®¶åœ˜åœ“\\n\\nè«‹è‡ªè¦ºè‡ªé¡˜\\n\\nåœ¨å®¶é‡Œå®ˆä½ä¸€é¡†å¿ƒï¼Œ\\n\\né»˜é»˜ç¥ˆç¦ä¸­åœ‹å¹³å®‰ï¼\\n\\nä¸è¦å˜´é‡Œå–Šè‘—å£è™Ÿ\\n\\næ‰‹é‡Œæ•¸è‘—é»‘å¿ƒéŒ¢\\n\\næ›´ä¸è¦\\n\\néš¨æ„æŠŠè¬ è¨€äº‚æ’­äº‚å‚³\\n\\nè…³æ­¥éš¨ç”Ÿé¢¨\\n\\nåˆ°è™•äº‚è½‰äº‚ç«„\\n\\nå‘†åœ¨å®¶é‡Œç‚ºç¥–åœ‹å¥‰ç»\\n\\nä¸€èµ·åº¦éé›£é—œ\\n\\nç¥ˆç¦ä¸­åœ‹å¹³å®‰ï¼\\n\\nåšä¸€å€‹ç¨±è·çš„å¥½å…¬æ°‘\\n\\nä¸å¦„ç‚º\\n\\nä¸€ç”Ÿä¸€ä¸–çš„å¥½æ°£ç¯€ï¼\\n\\nä¸­åœ‹åŠ æ²¹ï¼\\n\\nä¸­åœ‹å¹³å®‰ï¼\\n\\næˆ‘æƒ³è¦çš„æœªä¾†ï¼Œæ˜¯çœ‹å¾—åˆ°...............................................................................................................................................å®‰ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚å…¨ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚ã€‚\\n\\né»æ“Šç¹¼çºŒé–±è®€\\n\\nè¦ºå¾—ä¸éŒ¯ï¼Œè«‹é»å€‹åœ¨çœ‹ğŸ‘‡ğŸ‘‡\\n\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "with open(save_data_path, 'rb') as outfile:\n",
    "    result = json.load(outfile)\n",
    "print('Total num of samples: ',len(result))\n",
    "print('First sample of result: ', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export variables for (unittest)\n",
    "- test_length\n",
    "- test_pseudo_label_ratio\n",
    "- test_certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_certainty(prob):\n",
    "    min_prob = 1.0\n",
    "    for p in prob:\n",
    "        if max(p) < min_prob:\n",
    "            min_prob = max(p)\n",
    "    return min_prob\n",
    "\n",
    "prediction = predict_label(result, pipeline)\n",
    "result_probability = [pred['probabilities'] for pred in prediction]\n",
    "min_certainty = get_min_certainty(result_probability)\n",
    "result_label_id = [pred['prediction'] for pred in prediction]\n",
    "result_label_ratio = get_label_ratio(result_label_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1': 0.4, '0': 0.2, '1': 0.4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_label_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 10,
       "encoder": "json",
       "name": "length",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "length"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "0": 0.2,
        "1": 0.4,
        "-1": 0.4
       },
       "encoder": "json",
       "name": "label_ratio",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "label_ratio"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.334689199924469,
       "encoder": "json",
       "name": "min_certainty",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "min_certainty"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scrapbook as sb\n",
    "sb.glue(\"length\", len(result))\n",
    "sb.glue(\"label_ratio\", result_label_ratio)\n",
    "sb.glue(\"min_certainty\", min_certainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove file\n",
    "\n",
    "This part removes saved files and cleans direcotry, skip below if saving data and model\n",
    "- code 0: sucessful removal\n",
    "- code 256: failed removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove saved result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(f\"rm {save_data_path}\"))\n",
    "print(os.system(f\"rm {save_logit_path}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove trained model (if demo model is existed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(f\"rm -rf {model_dir}/result\"))\n",
    "print(os.system(f\"rm -rf {model_dir}/model\"))\n",
    "print(os.system(f\"rm -rf {model_dir}/logs\"))\n",
    "print(os.system(f\"rm {model_dir}/log\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
