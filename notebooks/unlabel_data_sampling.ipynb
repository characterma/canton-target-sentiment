{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "From data augmentation experiment for Apple Care 2 dataset, highlighted factors can ensure the quality of unlabeled dataset which enhance the performance of model.\n",
    "\n",
    "Experiment details in [2022_01_13 biweekly discussion.pptx](https://jira.wisers.com:18090/download/attachments/82808396/2022_01_13%20biweekly%20discussion.pptx?version=1&modificationDate=1642063801000&api=v2)\n",
    "\n",
    "For code design please browse [Confluence Proposed Module](https://jira.wisers.com:18090/display/RES/Proposed+Module2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/Users/hinova/canton-target-sentiment/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "src_dir = '../nlp_pipeline'\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(src_dir)\n",
    "from nlp_pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Generation\n",
    "\n",
    "- train a demo model for predict unlabel data in demonstration\n",
    "\n",
    "If you have specified trained model path:\n",
    "- comment below cell\n",
    "- comment the last cell (used to remove demo model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None **********************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *********************************************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *****\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model/tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 03:58:10 ***** Args *****\n",
      "2022-02-28 03:58:10    task: sequence_classification\n",
      "2022-02-28 03:58:10    device: 0\n",
      "2022-02-28 03:58:10    data: {'output_dir': '../config/examples/sequence_classification/BERT_AVG_explain', 'data_dir': '../data/datasets/sample/sequence_classification', 'train': 'train_sample.json', 'dev': 'train_sample.json', 'test': 'train_sample.json'}\n",
      "2022-02-28 03:58:10    text_prepro: {'steps': ['utf8_replace', 'simplified_chinese', 'lower_case', 'full_to_half']}\n",
      "2022-02-28 03:58:10    eval: {'batch_size': 64, 'model_file': 'model.pt'}\n",
      "2022-02-28 03:58:10    train: {'model_class': 'BERT_AVG', 'seed': 42, 'log_steps': 100, 'batch_size': 32, 'final_model': 'best', 'optimization_metric': 'macro_f1', 'early_stop': 5}\n",
      "2022-02-28 03:58:10    model_params: {'num_train_epochs': 2, 'embedding_trainable': True, 'output_hidden_act_func': 'PReLU', 'output_hidden_dim': 128, 'tokenizer_name': 'clue/albert_chinese_tiny', 'pretrained_lm': 'clue/albert_chinese_tiny'}\n",
      "2022-02-28 03:58:10    explanation: {'Random': {'method': 'Random'}, 'Lime': {'method': 'Lime'}, 'WordOmission': {'method': 'WordOmission'}, 'SaliencyAvg': {'method': 'Saliency', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'SaliencyL2': {'method': 'Saliency', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'GradientXActivationAvg': {'method': 'GradientXActivation', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'GradientXActivationL2': {'method': 'GradientXActivation', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'IntegratedGradientsAvg': {'method': 'IntegratedGradients', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'IntegratedGradientsL2': {'method': 'IntegratedGradients', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}, 'DeepLiftAvg': {'method': 'DeepLift', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': None}, 'DeepLiftL2': {'method': 'DeepLift', 'layer': 'pretrained_model.embeddings.word_embeddings', 'norm': 'l2'}}\n",
      "2022-02-28 03:58:10 ***** Loading tokenizer *****\n",
      "2022-02-28 03:58:10   Tokenizer source = 'transformers'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run.yaml', 'model.yaml', 'tokenizer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 03:58:15 ***** Initializing model *****\n",
      "2022-02-28 03:58:15   Task = sequence_classification\n",
      "2022-02-28 03:58:15   Model class = BERT_AVG\n",
      "2022-02-28 03:58:16 ***** Loading pretrained language model *****\n",
      "2022-02-28 03:58:16   Pretrained BERT = 'clue/albert_chinese_tiny'\n",
      "2022-02-28 03:58:22 ***** Loading data *****\n",
      "2022-02-28 03:58:22   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 82.61it/s]\n",
      "2022-02-28 03:58:22   Loaded samples = 3\n",
      "2022-02-28 03:58:22 ***** Loading data *****\n",
      "2022-02-28 03:58:22   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 118.25it/s]\n",
      "2022-02-28 03:58:22   Loaded samples = 3\n",
      "2022-02-28 03:58:22 ***** Running training *****\n",
      "2022-02-28 03:58:22   Num examples = 3\n",
      "2022-02-28 03:58:22   Num Epochs = 2\n",
      "2022-02-28 03:58:22   Sampler = \n",
      "2022-02-28 03:58:22   Batch size = 32\n",
      "2022-02-28 03:58:22   Gradient Accumulation steps = 1\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 20.21it/s, tr_loss=1.06]\n",
      "2022-02-28 03:58:22 ***** Epoch end: 0 *****\n",
      "2022-02-28 03:58:22 ***** Running evaluation *****\n",
      "2022-02-28 03:58:22   Num examples = 3\n",
      "2022-02-28 03:58:22   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 133.21it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2022-02-28 03:58:22   accuracy = 0.6666666666666666\n",
      "2022-02-28 03:58:22   macro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   micro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   support = 3\n",
      "2022-02-28 03:58:22   -1-precision = 1.0\n",
      "2022-02-28 03:58:22   -1-recall = 1.0\n",
      "2022-02-28 03:58:22   -1-f1-score = 1.0\n",
      "2022-02-28 03:58:22   -1-support = 1\n",
      "2022-02-28 03:58:22   0-precision = 0.0\n",
      "2022-02-28 03:58:22   0-recall = 0.0\n",
      "2022-02-28 03:58:22   0-f1-score = 0.0\n",
      "2022-02-28 03:58:22   0-support = 1\n",
      "2022-02-28 03:58:22   1-precision = 0.5\n",
      "2022-02-28 03:58:22   1-recall = 1.0\n",
      "2022-02-28 03:58:22   1-f1-score = 0.6666666666666666\n",
      "2022-02-28 03:58:22   1-support = 1\n",
      "2022-02-28 03:58:22   loss = 1.0365409851074219\n",
      "2022-02-28 03:58:22   dataset = dev\n",
      "\n",
      "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1/1 [00:00<00:00, 40.30it/s, tr_loss=1.04]\n",
      "2022-02-28 03:58:22 ***** Epoch end: 1 *****\n",
      "2022-02-28 03:58:22 ***** Running evaluation *****\n",
      "2022-02-28 03:58:22   Num examples = 3\n",
      "2022-02-28 03:58:22   Batch size = 64\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 173.30it/s]\n",
      "2022-02-28 03:58:22   accuracy = 0.6666666666666666\n",
      "2022-02-28 03:58:22   macro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   micro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   support = 3\n",
      "2022-02-28 03:58:22   -1-precision = 1.0\n",
      "2022-02-28 03:58:22   -1-recall = 1.0\n",
      "2022-02-28 03:58:22   -1-f1-score = 1.0\n",
      "2022-02-28 03:58:22   -1-support = 1\n",
      "2022-02-28 03:58:22   0-precision = 0.0\n",
      "2022-02-28 03:58:22   0-recall = 0.0\n",
      "2022-02-28 03:58:22   0-f1-score = 0.0\n",
      "2022-02-28 03:58:22   0-support = 1\n",
      "2022-02-28 03:58:22   1-precision = 0.5\n",
      "2022-02-28 03:58:22   1-recall = 1.0\n",
      "2022-02-28 03:58:22   1-f1-score = 0.6666666666666666\n",
      "2022-02-28 03:58:22   1-support = 1\n",
      "2022-02-28 03:58:22   loss = 1.0233073234558105\n",
      "2022-02-28 03:58:22   dataset = dev\n",
      "Epoch: 100%|██████████| 2/2 [00:00<00:00, 17.88it/s]\n",
      "2022-02-28 03:58:22 ***** Training end *****\n",
      "2022-02-28 03:58:22   Model path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model/model.pt\n",
      "2022-02-28 03:58:22 ***** Loading data *****\n",
      "2022-02-28 03:58:22   Data path = /home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../data/datasets/sample/sequence_classification/train_sample.json\n",
      "3it [00:00, 109.04it/s]\n",
      "2022-02-28 03:58:22   Loaded samples = 3\n",
      "2022-02-28 03:58:22 ***** Running evaluation *****\n",
      "2022-02-28 03:58:22   Num examples = 3\n",
      "2022-02-28 03:58:22   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 169.84it/s]\n",
      "2022-02-28 03:58:22   accuracy = 0.6666666666666666\n",
      "2022-02-28 03:58:22   macro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   micro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   support = 3\n",
      "2022-02-28 03:58:22   -1-precision = 1.0\n",
      "2022-02-28 03:58:22   -1-recall = 1.0\n",
      "2022-02-28 03:58:22   -1-f1-score = 1.0\n",
      "2022-02-28 03:58:22   -1-support = 1\n",
      "2022-02-28 03:58:22   0-precision = 0.0\n",
      "2022-02-28 03:58:22   0-recall = 0.0\n",
      "2022-02-28 03:58:22   0-f1-score = 0.0\n",
      "2022-02-28 03:58:22   0-support = 1\n",
      "2022-02-28 03:58:22   1-precision = 0.5\n",
      "2022-02-28 03:58:22   1-recall = 1.0\n",
      "2022-02-28 03:58:22   1-f1-score = 0.6666666666666666\n",
      "2022-02-28 03:58:22   1-support = 1\n",
      "2022-02-28 03:58:22   loss = 1.0365409851074219\n",
      "2022-02-28 03:58:22   dataset = train\n",
      "2022-02-28 03:58:22 ***** Running evaluation *****\n",
      "2022-02-28 03:58:22   Num examples = 3\n",
      "2022-02-28 03:58:22   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 199.07it/s]\n",
      "2022-02-28 03:58:22   accuracy = 0.6666666666666666\n",
      "2022-02-28 03:58:22   macro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   micro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   support = 3\n",
      "2022-02-28 03:58:22   -1-precision = 1.0\n",
      "2022-02-28 03:58:22   -1-recall = 1.0\n",
      "2022-02-28 03:58:22   -1-f1-score = 1.0\n",
      "2022-02-28 03:58:22   -1-support = 1\n",
      "2022-02-28 03:58:22   0-precision = 0.0\n",
      "2022-02-28 03:58:22   0-recall = 0.0\n",
      "2022-02-28 03:58:22   0-f1-score = 0.0\n",
      "2022-02-28 03:58:22   0-support = 1\n",
      "2022-02-28 03:58:22   1-precision = 0.5\n",
      "2022-02-28 03:58:22   1-recall = 1.0\n",
      "2022-02-28 03:58:22   1-f1-score = 0.6666666666666666\n",
      "2022-02-28 03:58:22   1-support = 1\n",
      "2022-02-28 03:58:22   loss = 1.0365409851074219\n",
      "2022-02-28 03:58:22   dataset = dev\n",
      "2022-02-28 03:58:22 ***** Running evaluation *****\n",
      "2022-02-28 03:58:22   Num examples = 3\n",
      "2022-02-28 03:58:22   Batch size = 64\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 198.41it/s]\n",
      "2022-02-28 03:58:22   accuracy = 0.6666666666666666\n",
      "2022-02-28 03:58:22   macro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   micro_f1 = 0.5555555555555555\n",
      "2022-02-28 03:58:22   support = 3\n",
      "2022-02-28 03:58:22   -1-precision = 1.0\n",
      "2022-02-28 03:58:22   -1-recall = 1.0\n",
      "2022-02-28 03:58:22   -1-f1-score = 1.0\n",
      "2022-02-28 03:58:22   -1-support = 1\n",
      "2022-02-28 03:58:22   0-precision = 0.0\n",
      "2022-02-28 03:58:22   0-recall = 0.0\n",
      "2022-02-28 03:58:22   0-f1-score = 0.0\n",
      "2022-02-28 03:58:22   0-support = 1\n",
      "2022-02-28 03:58:22   1-precision = 0.5\n",
      "2022-02-28 03:58:22   1-recall = 1.0\n",
      "2022-02-28 03:58:22   1-f1-score = 0.6666666666666666\n",
      "2022-02-28 03:58:22   1-support = 1\n",
      "2022-02-28 03:58:22   loss = 1.0365409851074219\n",
      "2022-02-28 03:58:22   dataset = test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"python run.py --config_dir={'../config/examples/sequence_classification/BERT_AVG_explain'}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User can sample label ratio based on the ratio of train set, or request desired label ratio. It depends on existence of argument (either input this argument or not):\n",
    "\n",
    "- label_ratio (if required desired label ratio)\n",
    "\n",
    "remarks: Model directory is required to predict labels for unlabel data in order to sample data which includes\n",
    "- model directory\n",
    "    - run.yaml\n",
    "    - model.yaml\n",
    "    - label_to_id.json\n",
    "    - model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# comment if user samples label ratio based on the ratio of train set\n",
    "label_ratio = {'-1': 0.4, '0': 0.2, '1': 0.4} # optional \n",
    "\n",
    "# unlabel path (json file name included)\n",
    "unlabel_path = '../data/datasets/sample/sequence_classification/unlabeled_sample.json' \n",
    "\n",
    "# model directory, must include above files\n",
    "model_dir = '../config/examples/sequence_classification/BERT_AVG_explain' # required argument \n",
    "\n",
    "# save directory\n",
    "save_dir = '../data/datasets/sample/sequence_classification' # required \n",
    "save_data_file = 'sampled_unlabel_data.json' # required \n",
    "save_logit_file = 'sampled_unlabel_logits.pkl' # required \n",
    "\n",
    "# sample size and certainty\n",
    "sample_size = 10 # required, integer and smaller than size of unlabeled data\n",
    "certainty = 0 # optional, only select the data that max(p)>certainty, \n",
    "                # p is the predicted probabilities (0 - 1) over the label space\n",
    "                # default certainty is 0\n",
    "\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# comment train_raw_data and label if label_ratio is defined (self defined)\n",
    "\n",
    "# train_raw_data = json.load(open(f\"../data/datasets/sample/sequence_classification/train_sample.json\", 'r'))\n",
    "# label = [str(train_raw_data[i]['label']) for i in range(len(train_raw_data))]\n",
    "# print('The first three labels of trainset: \\n', label[:3])\n",
    "\n",
    "unlabel_raw_data = json.load(open(unlabel_path, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get label ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ratio of train set: \n",
      " {'-1': 0.4, '0': 0.2, '1': 0.4}\n"
     ]
    }
   ],
   "source": [
    "def get_label_ratio(label = None):\n",
    "    '''\n",
    "        input:\n",
    "        - label: list\n",
    "\n",
    "        output:\n",
    "        - label_ratio: dict\n",
    "    '''\n",
    "    if label is None and 'label_ratio' in globals():\n",
    "        return label_ratio\n",
    "    result = {}\n",
    "    for i in label:\n",
    "        # i will be replaced get_label_ratio directly\n",
    "        key = i\n",
    "        if key not in result:\n",
    "            result[key] = 0\n",
    "        result[key] = result[key] + 1/len(label)\n",
    "\n",
    "    for key in result.keys():\n",
    "        result[key] = round(result[key], 2)\n",
    "    return result\n",
    "\n",
    "# comment if user self define label ratio\n",
    "# label_ratio = get_label_ratio(label)\n",
    "\n",
    "# comment if follow train set label ratio\n",
    "label_ratio = get_label_ratio(None)\n",
    "\n",
    "print('label ratio of train set: \\n',label_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run pipeline (Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 03:58:24 ***** Existing model is provided. *****\n",
      "2022-02-28 03:58:24   Model directory = ../config/examples/sequence_classification/BERT_AVG_explain\n",
      "2022-02-28 03:58:24 ***** Initializing pipeline *****\n",
      "2022-02-28 03:58:24 ***** Loading tokenizer *****\n",
      "2022-02-28 03:58:24   Tokenizer source = 'transformers'\n",
      "2022-02-28 03:58:24 ***** Initializing model *****\n",
      "2022-02-28 03:58:24   Task = sequence_classification\n",
      "2022-02-28 03:58:24   Model class = BERT_AVG\n",
      "2022-02-28 03:58:24   Model path = ../config/examples/sequence_classification/BERT_AVG_explain/model/model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None **********************************\n",
      "/home/developer/Users/hinova/canton-target-sentiment/nlp_pipeline/../config/examples/sequence_classification/BERT_AVG_explain/model *********************************************************\n",
      "../config/examples/sequence_classification/BERT_AVG_explain/model/tokenizer\n",
      "['run.yaml', 'model.yaml', 'tokenizer', 'label_to_id.json', 'model.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 03:58:25 ***** Loading pretrained language model *****\n",
      "2022-02-28 03:58:25   Pretrained BERT = 'clue/albert_chinese_tiny'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    model_dir=model_dir, \n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "{'content': '\\n\\n2月9日，網上反映“一醫院領導拒絕戴口罩，途經卡點引發爭執”的視頻，新鄭市委高度重視，對此事進行了初步調查核實：\\n\\n2月8日22：00，新鄭市第三人民醫院副院長楚明輝從集中留觀隔離點結束工作返家途中，在龍湖雙湖大道疫情卡點接受檢查時，與卡點工作人員發生爭執，拒戴口罩，存在不當言行，造成了不良影響。新鄭市衛健委已經責成新鄭市第三人民醫院暫停楚明輝副院長職務。新鄭市紀委監委已成立調查組進行調查，調查結果及時向社會公佈。\\n\\n編輯：王淑\\n\\n聯繫記者\\n'}\n",
      "Output:\n",
      "{'prediction_id': 0, 'prediction': '1', 'logits': [0.06629689037799835, -0.08389206230640411, 0.03349928930401802]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "print(unlabel_raw_data[0])\n",
    "\n",
    "output = pipeline.predict(\n",
    "    data_dict=unlabel_raw_data[0],\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def predict_label(dataset, pipeline):\n",
    "    '''\n",
    "        input:\n",
    "        - dataset: list\n",
    "        - pipeline\n",
    "        \n",
    "        output:\n",
    "        - list\n",
    "    '''\n",
    "    result = []\n",
    "    for raw_data in dataset:\n",
    "        output = pipeline.predict(\n",
    "            data_dict=raw_data,\n",
    "        )\n",
    "        output['probabilities'] = F.softmax(torch.tensor(output[\"logits\"]), dim=-1).cpu().tolist()\n",
    "        result.append(output)\n",
    "    return result\n",
    "prediction = predict_label(unlabel_raw_data, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudo label ratio of unlabel set: \n",
      " {'1': 0.69, '-1': 0.28, '0': 0.03}\n"
     ]
    }
   ],
   "source": [
    "pseudo_label_id = [pred['prediction'] for pred in prediction]\n",
    "pseudo_label_ratio = get_label_ratio(pseudo_label_id)\n",
    "print('pseudo label ratio of unlabel set: \\n',pseudo_label_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of pseudo label (left column label, right column count): \n",
      " [['-1' '18']\n",
      " ['0' '2']\n",
      " ['1' '44']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "(unique, counts) = np.unique(np.array(pseudo_label_id), return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print('Frequency of pseudo label (left column label, right column count): \\n', frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def collect_probability(prediction):\n",
    "    # collect probability of prediction\n",
    "    prob_ls = []\n",
    "    for batch_pred in prediction:\n",
    "            prob_ls.append(batch_pred['probabilities'])\n",
    "    prob_np = np.array(prob_ls)\n",
    "    return prob_np\n",
    "\n",
    "def get_sampled_idx(prob_np, label_ratio, certainty, sample_size, label_to_id):\n",
    "    # sample size for labels\n",
    "    ss_idx = []\n",
    "    label_collection = {}\n",
    "    remain_size = sample_size\n",
    "    summary = {}\n",
    "    print('Important: Sampling Statistics')\n",
    "\n",
    "    for i, key in enumerate(label_ratio.keys()):\n",
    "        key_id = label_to_id[key]\n",
    "\n",
    "        # sample size computation\n",
    "        if i != len(label_ratio.keys()) - 1:\n",
    "            # sample size follows label ratio\n",
    "            key_size = int(sample_size * label_ratio[key])\n",
    "            remain_size = remain_size - key_size\n",
    "        else:\n",
    "            key_size = remain_size\n",
    "\n",
    "        # basic information of label data\n",
    "        summary[key] = []\n",
    "        label_idx = np.argwhere((prob_np.argmax(axis=1)==key_id)).flatten()\n",
    "        summary[key].append(label_idx.shape[0])\n",
    "\n",
    "        # certainty index\n",
    "        key_certain_idx = np.argwhere((prob_np.argmax(axis=1)==key_id) & (prob_np.max(axis=1)>=certainty)).flatten()\n",
    "        summary[key].append(key_certain_idx.shape[0])\n",
    "\n",
    "        summary[key].append(key_size)\n",
    "\n",
    "        # warning if not able to sample enough data (filtered size is smaller than required size)\n",
    "        if key_size > key_certain_idx.shape[0]:\n",
    "            print('\\t(Warning: only sample ',key_certain_idx.shape[0], ' example(s) for label ',key,' because required size > filtered size)')\n",
    "            if key_size <= label_idx.shape[0]:\n",
    "                print('label ',key,':\\t(Suggested Certainty for label ', key,': ', np.sort(prob_np.max(axis=1)[(prob_np.argmax(axis=1)==key_id)])[-key_size], ')')\n",
    "            else:\n",
    "                print('label ',key,':\\t(Suggested Ratio for label ', key,': ', label_idx.shape[0]/sample_size,')')\n",
    "            key_size = key_certain_idx.shape[0]\n",
    "\n",
    "        # append sampled index to list\n",
    "        ss_idx = ss_idx + (random.sample(key_certain_idx.tolist(), key_size))\n",
    "        label_collection[key] = key_size\n",
    "\n",
    "    summary['total'] = ['', len(ss_idx), sample_size]\n",
    "    print (\"\\nSummary Table:\\n{:<25} {:<25} {:<25} {:<25}\".format('label\\size','all','filtered (certainty>'+str(certainty)+')','required'))\n",
    "    for k, v in summary.items():\n",
    "        total, filtered, required = v\n",
    "        print (\"{:<25} {:<25} {:<25} {:<25}\".format(k, total, filtered, required))\n",
    "    return ss_idx\n",
    "\n",
    "def extract_data(data, idx):\n",
    "    # indexing unlabel data\n",
    "    unlabel_data = np.array(data)\n",
    "    return unlabel_data[idx].tolist()\n",
    "\n",
    "def extract_logits(prop_np, idx):\n",
    "    return prop_np[idx].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sampling Statisitcs\n",
    "\n",
    "Important summary of sampling results, required data size is calculated by sample size times label ratio. Generally, total filtered data size (> certainty) should be the same with required size. Else, warning will be popped up.\n",
    "\n",
    "- required size > label size : suggest to edit the label ratio\n",
    "- required size <= label size & required size >= filtered size (> certainty) : suggest to edit certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important: Sampling Statistics\n",
      "\n",
      "Summary Table:\n",
      "label\\size                all                       filtered (certainty>0)    required                 \n",
      "-1                        18                        18                        4                        \n",
      "0                         2                         2                         2                        \n",
      "1                         44                        44                        4                        \n",
      "total                                               10                        10                       \n"
     ]
    }
   ],
   "source": [
    "def sampling(unlabel_dataset, prediction, label_ratio, certainty, sample_size, label_to_id):\n",
    "    '''\n",
    "        input:\n",
    "        - unlabel_dataset: list\n",
    "        - pseudo_label: list\n",
    "        - label_ratio: dict\n",
    "        - certainty: float\n",
    "        - label_to_id: dict\n",
    "\n",
    "        output:\n",
    "        - list\n",
    "    '''\n",
    "    # collect probability of prediction\n",
    "    prob_np = collect_probability(prediction)\n",
    "\n",
    "    # get sampled index\n",
    "    idx = get_sampled_idx(prob_np, label_ratio, certainty, sample_size, label_to_id)\n",
    "\n",
    "    # indexing unlabel data\n",
    "    sampled_data = extract_data(unlabel_dataset, idx)\n",
    "\n",
    "    # indexing unlabel logits\n",
    "    sampled_logits = extract_logits(prob_np, idx)\n",
    "\n",
    "    return sampled_data, sampled_logits\n",
    "\n",
    "sampled_data, sampled_logits = sampling(\n",
    "    unlabel_dataset = unlabel_raw_data, \n",
    "    prediction = prediction, \n",
    "    label_ratio = label_ratio, \n",
    "    certainty = certainty,\n",
    "    sample_size = sample_size,\n",
    "    label_to_id = pipeline.args.label_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of sampled data:  10\n",
      "Overview of first sampled data {'content': '【#紅十字會總會赴武漢工作組#：堅決徹底整改】中國紅十字會黨組書記、常務副會長梁惠玲率領總會工作組于２月１日晚奔赴武漢，調查處置輿情反映有關問題，依法規範捐贈款物接受使用和信息公開工作。對疫情防控工作進行再調度、再部署、再動員，要求深刻汲取捐贈款物管理失職失責的慘痛教訓，迅速開展自查自糾，採取切實管用措施，堅決徹底整改到位。（@人民日報 ）\\n'} \n",
      "\n",
      "Total size of sampled logits:  10\n",
      "Overview of first sampled logits [0.3454711437225342, 0.30857840180397034, 0.3459504544734955]\n"
     ]
    }
   ],
   "source": [
    "print('Total size of sampled data: ', len(sampled_data))\n",
    "print('Overview of first sampled data', sampled_data[0],'\\n')\n",
    "print('Total size of sampled logits: ', len(sampled_logits))\n",
    "print('Overview of first sampled logits', sampled_logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save dataset and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(sample_data: list, save_path: str):\n",
    "    with open(save_path, 'w') as outfile:\n",
    "        json.dump(sample_data, outfile)\n",
    "\n",
    "def save_logit(sample_logits: list, save_path: str):\n",
    "    import pickle\n",
    "    with open(save_path, 'wb') as outfile:\n",
    "        pickle.dump(sample_logits, outfile)\n",
    "\n",
    "save_data_path = save_dir + save_data_file\n",
    "save_logit_path = save_dir + save_logit_file\n",
    "save_data(sampled_data, save_data_path)\n",
    "save_logit(sampled_logits, save_logit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of samples:  10\n",
      "First sample of result:  {'content': '【#紅十字會總會赴武漢工作組#：堅決徹底整改】中國紅十字會黨組書記、常務副會長梁惠玲率領總會工作組于２月１日晚奔赴武漢，調查處置輿情反映有關問題，依法規範捐贈款物接受使用和信息公開工作。對疫情防控工作進行再調度、再部署、再動員，要求深刻汲取捐贈款物管理失職失責的慘痛教訓，迅速開展自查自糾，採取切實管用措施，堅決徹底整改到位。（@人民日報 ）\\n'}\n"
     ]
    }
   ],
   "source": [
    "with open(save_data_path, 'rb') as outfile:\n",
    "    result = json.load(outfile)\n",
    "print('Total num of samples: ',len(result))\n",
    "print('First sample of result: ', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export variables for (unittest)\n",
    "- test_length\n",
    "- test_pseudo_label_ratio\n",
    "- test_certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_certainty(prob):\n",
    "    min_prob = 1.0\n",
    "    for p in prob:\n",
    "        if max(p) < min_prob:\n",
    "            min_prob = max(p)\n",
    "    return min_prob\n",
    "\n",
    "prediction = predict_label(result, pipeline)\n",
    "result_probability = [pred['probabilities'] for pred in prediction]\n",
    "min_certainty = get_min_certainty(result_probability)\n",
    "result_label_id = [pred['prediction'] for pred in prediction]\n",
    "result_label_ratio = get_label_ratio(result_label_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 10,
       "encoder": "json",
       "name": "length",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "length"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "0": 0.2,
        "1": 0.4,
        "-1": 0.4
       },
       "encoder": "json",
       "name": "label_ratio",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "label_ratio"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": 0.334689199924469,
       "encoder": "json",
       "name": "min_certainty",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "min_certainty"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scrapbook as sb\n",
    "sb.glue(\"length\", len(result))\n",
    "sb.glue(\"label_ratio\", result_label_ratio)\n",
    "sb.glue(\"min_certainty\", min_certainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove file\n",
    "\n",
    "This part removes saved files and cleans direcotry, skip below if saving data and model\n",
    "- code 0: sucessful removal\n",
    "- code 256: failed removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove saved result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(f\"rm {save_data_path}\"))\n",
    "print(os.system(f\"rm {save_logit_path}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove trained model (if demo model is existed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(os.system(f\"rm -rf {model_dir}/result\"))\n",
    "print(os.system(f\"rm -rf {model_dir}/model\"))\n",
    "print(os.system(f\"rm -rf {model_dir}/logs\"))\n",
    "print(os.system(f\"rm {model_dir}/log\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
