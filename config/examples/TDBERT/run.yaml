device: 2
data:
  model_dir: "../config/examples/TDBERT/"
  data_dir: "../config/examples/TDBERT/"
  train: sample.json 
  dev: sample.json 
  test: sample.json 
  labels: 3_ways # 2_ways
text_prepro:
  steps:
    - simplified_chinese
    - lower_case
    - convert_java_index
    # - extract_post_context_1
    # - extract_post_context_2
eval:
  batch_size: 64
  state_file: "*.pt"
train:
  model_class: "TDBERT"
  seed: 42
  batch_size: 16
model_params:
  xxxxx: xxxxx
  max_length: 180
  num_train_epochs: 10
  pretrained_emb_path: "../data/word_embeddings/sgns.target.word-character.char1-2.dynwin5.thr10.neg5.dim300.iter5"
  embedding_trainable: False
  # tokenizer_name: "bert-base-chinese"  # source:::tokenizer_type "huggingface:::toastynews/electra-hongkongese-large-discriminator"   
  # pretrained_lm: "bert-base-chinese" # huggingface format "toastynews/electra-hongkongese-large-discriminator" 
