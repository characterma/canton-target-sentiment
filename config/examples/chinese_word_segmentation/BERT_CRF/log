***** Args *****
   device: 0
   data: {'output_dir': '../config/examples/chinese_word_segmentation/BERT_CRF', 'data_dir': '../data/datasets/canton_ws', 'train': 'data_combined.json', 'dev': 'data_combined.json', 'test': 'data_combined.json'}
   text_prepro: {'steps': ['full_to_half']}
   eval: {'batch_size': 64, 'model_file': 'model.pt'}
   train: {'task': 'chinese_word_segmentation', 'model_class': 'BERT_CRF', 'seed': 42, 'batch_size': 16, 'final_model': 'best'}
   model_params: {'num_train_epochs': 20, 'embedding_trainable': True}
***** Loading tokenizer *****
  Tokenizer source = 'transformers'
  Tokenizer name = 'clue/albert_chinese_tiny'
***** Initializing model *****
  Task = chinese_word_segmentation
  Model class = BERT_CRF
***** Loading pretrained language model *****
  Pretrained BERT = 'clue/albert_chinese_tiny'
***** Loading data *****
  Data path = ../data/datasets/canton_ws/data_combined.json
  Number of raw samples = 2445
  Number of loaded samples = 2445
***** Loading data *****
  Data path = ../data/datasets/canton_ws/data_combined.json
  Number of raw samples = 2445
  Number of loaded samples = 2445
***** Running training *****
  Num examples = 2445
  Num Epochs = 20
  Sampler = random
  Batch size = 16
  Gradient Accumulation steps = 1
***** Epoch end: 0 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.16058044716100964
  micro_f1 = 0.25277237812981784
  ADJ-precision = 0.0
  ADJ-recall = 0.0
  ADJ-f1-score = 0.0
  ADJ-support = 149
  ADP-precision = 0.6582278481012658
  ADP-recall = 0.37681159420289856
  ADP-f1-score = 0.47926267281105994
  ADP-support = 414
  ADV-precision = 0.23728813559322035
  ADV-recall = 0.10727969348659004
  ADV-f1-score = 0.14775725593667546
  ADV-support = 522
  AUX-precision = 0.0
  AUX-recall = 0.0
  AUX-f1-score = 0.0
  AUX-support = 75
  CCONJ-precision = 0.0
  CCONJ-recall = 0.0
  CCONJ-f1-score = 0.0
  CCONJ-support = 101
  DET-precision = 0.6388888888888888
  DET-recall = 0.5041095890410959
  DET-f1-score = 0.563552833078101
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.2223019861210816
  NOUN-recall = 0.6546863988724454
  NOUN-f1-score = 0.3319042515183994
  NOUN-support = 1419
  NUM-precision = 0.7448275862068966
  NUM-recall = 0.2864721485411141
  NUM-f1-score = 0.4137931034482759
  NUM-support = 377
  PART-precision = 0.0
  PART-recall = 0.0
  PART-f1-score = 0.0
  PART-support = 101
  PRON-precision = 0.8043478260869565
  PRON-recall = 0.12171052631578948
  PRON-f1-score = 0.21142857142857144
  PRON-support = 304
  PROPN-precision = 0.12099644128113879
  PROPN-recall = 0.11604095563139932
  PROPN-f1-score = 0.11846689895470384
  PROPN-support = 586
  PUNCT-precision = 0.0
  PUNCT-recall = 0.0
  PUNCT-f1-score = 0.0
  PUNCT-support = 200
  SCONJ-precision = 0.29411764705882354
  SCONJ-recall = 0.08733624454148471
  SCONJ-f1-score = 0.13468013468013468
  SCONJ-support = 229
  VERB-precision = 0.18669527896995708
  VERB-recall = 0.15343915343915343
  VERB-f1-score = 0.16844143272023232
  VERB-support = 567
  _-precision = 0.0
  _-recall = 0.0
  _-f1-score = 0.0
  _-support = 0
  loss = 7.6618469433906755
  dataset = dev
***** Epoch end: 1 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.35348164544987276
  micro_f1 = 0.4562347288171405
  ADJ-precision = 0.0
  ADJ-recall = 0.0
  ADJ-f1-score = 0.0
  ADJ-support = 149
  ADP-precision = 0.6979591836734694
  ADP-recall = 0.41304347826086957
  ADP-f1-score = 0.5189681335356602
  ADP-support = 414
  ADV-precision = 0.25566750629722923
  ADV-recall = 0.3888888888888889
  ADV-f1-score = 0.3085106382978723
  ADV-support = 522
  AUX-precision = 0.0
  AUX-recall = 0.0
  AUX-f1-score = 0.0
  AUX-support = 75
  CCONJ-precision = 0.125
  CCONJ-recall = 0.009900990099009901
  CCONJ-f1-score = 0.018348623853211007
  CCONJ-support = 101
  DET-precision = 0.717687074829932
  DET-recall = 0.5780821917808219
  DET-f1-score = 0.6403641881638846
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.40190146931719967
  NOUN-recall = 0.6553911205073996
  NOUN-f1-score = 0.4982587731047415
  NOUN-support = 1419
  NUM-precision = 0.8135593220338984
  NUM-recall = 0.7639257294429708
  NUM-f1-score = 0.7879616963064295
  NUM-support = 377
  PART-precision = 1.0
  PART-recall = 0.0594059405940594
  PART-f1-score = 0.11214953271028036
  PART-support = 101
  PRON-precision = 0.7079207920792079
  PRON-recall = 0.47039473684210525
  PRON-f1-score = 0.5652173913043478
  PRON-support = 304
  PROPN-precision = 0.38596491228070173
  PROPN-recall = 0.45051194539249145
  PROPN-f1-score = 0.415748031496063
  PROPN-support = 586
  PUNCT-precision = 0.8461538461538461
  PUNCT-recall = 0.385
  PUNCT-f1-score = 0.5292096219931272
  PUNCT-support = 200
  SCONJ-precision = 0.5298507462686567
  SCONJ-recall = 0.6200873362445415
  SCONJ-f1-score = 0.5714285714285714
  SCONJ-support = 229
  VERB-precision = 0.29048843187660667
  VERB-recall = 0.3985890652557319
  VERB-f1-score = 0.3360594795539033
  VERB-support = 567
  loss = 5.598417196518335
  dataset = dev
***** Epoch end: 2 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.4580457759493618
  micro_f1 = 0.547943679882452
  ADJ-precision = 0.0
  ADJ-recall = 0.0
  ADJ-f1-score = 0.0
  ADJ-support = 149
  ADP-precision = 0.8373205741626795
  ADP-recall = 0.4227053140096618
  ADP-f1-score = 0.5617977528089888
  ADP-support = 414
  ADV-precision = 0.3346456692913386
  ADV-recall = 0.4885057471264368
  ADV-f1-score = 0.397196261682243
  ADV-support = 522
  AUX-precision = 0.0
  AUX-recall = 0.0
  AUX-f1-score = 0.0
  AUX-support = 75
  CCONJ-precision = 0.4418604651162791
  CCONJ-recall = 0.18811881188118812
  CCONJ-f1-score = 0.2638888888888889
  CCONJ-support = 101
  DET-precision = 0.7749077490774908
  DET-recall = 0.5753424657534246
  DET-f1-score = 0.660377358490566
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.5115405260332797
  NOUN-recall = 0.671599718111346
  NOUN-f1-score = 0.5807434491163924
  NOUN-support = 1419
  NUM-precision = 0.8253164556962025
  NUM-recall = 0.8647214854111406
  NUM-f1-score = 0.844559585492228
  NUM-support = 377
  PART-precision = 0.8048780487804879
  PART-recall = 0.32673267326732675
  PART-f1-score = 0.4647887323943662
  PART-support = 101
  PRON-precision = 0.7904761904761904
  PRON-recall = 0.5460526315789473
  PRON-f1-score = 0.6459143968871596
  PRON-support = 304
  PROPN-precision = 0.4364060676779463
  PROPN-recall = 0.6382252559726962
  PROPN-f1-score = 0.5183645183645185
  PROPN-support = 586
  PUNCT-precision = 0.7586206896551724
  PUNCT-recall = 0.77
  PUNCT-f1-score = 0.7642679900744417
  PUNCT-support = 200
  SCONJ-precision = 0.6779026217228464
  SCONJ-recall = 0.7903930131004366
  SCONJ-f1-score = 0.7298387096774194
  SCONJ-support = 229
  VERB-precision = 0.390646492434663
  VERB-recall = 0.5008818342151675
  VERB-f1-score = 0.4389489953632148
  VERB-support = 567
  loss = 4.603476707751934
  dataset = dev
***** Epoch end: 3 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.5345544339910062
  micro_f1 = 0.6179940134695985
  ADJ-precision = 0.0
  ADJ-recall = 0.0
  ADJ-f1-score = 0.0
  ADJ-support = 149
  ADP-precision = 0.8133802816901409
  ADP-recall = 0.5579710144927537
  ADP-f1-score = 0.6618911174785101
  ADP-support = 414
  ADV-precision = 0.403068340306834
  ADV-recall = 0.553639846743295
  ADV-f1-score = 0.46650524616626315
  ADV-support = 522
  AUX-precision = 0.0
  AUX-recall = 0.0
  AUX-f1-score = 0.0
  AUX-support = 75
  CCONJ-precision = 0.7014925373134329
  CCONJ-recall = 0.46534653465346537
  CCONJ-f1-score = 0.5595238095238095
  CCONJ-support = 101
  DET-precision = 0.7719298245614035
  DET-recall = 0.6027397260273972
  DET-f1-score = 0.676923076923077
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.563169164882227
  NOUN-recall = 0.7413671599718111
  NOUN-f1-score = 0.6400973532096137
  NOUN-support = 1419
  NUM-precision = 0.8201438848920863
  NUM-recall = 0.9071618037135278
  NUM-f1-score = 0.8614609571788413
  NUM-support = 377
  PART-precision = 0.7228915662650602
  PART-recall = 0.594059405940594
  PART-f1-score = 0.6521739130434783
  PART-support = 101
  PRON-precision = 0.8508771929824561
  PRON-recall = 0.6381578947368421
  PRON-f1-score = 0.7293233082706767
  PRON-support = 304
  PROPN-precision = 0.6298245614035087
  PROPN-recall = 0.6126279863481229
  PROPN-f1-score = 0.6211072664359861
  PROPN-support = 586
  PUNCT-precision = 0.8486238532110092
  PUNCT-recall = 0.925
  PUNCT-f1-score = 0.8851674641148326
  PUNCT-support = 200
  SCONJ-precision = 0.6977611940298507
  SCONJ-recall = 0.8165938864628821
  SCONJ-f1-score = 0.7525150905432596
  SCONJ-support = 229
  VERB-precision = 0.426056338028169
  VERB-recall = 0.6402116402116402
  VERB-f1-score = 0.5116279069767442
  VERB-support = 567
  loss = 3.947078918799376
  dataset = dev
***** Epoch end: 4 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.5615059781802751
  micro_f1 = 0.6504515049311966
  ADJ-precision = 0.1
  ADJ-recall = 0.013422818791946308
  ADJ-f1-score = 0.02366863905325444
  ADJ-support = 149
  ADP-precision = 0.7797619047619048
  ADP-recall = 0.6328502415458938
  ADP-f1-score = 0.6986666666666667
  ADP-support = 414
  ADV-precision = 0.4613050075872534
  ADV-recall = 0.5823754789272031
  ADV-f1-score = 0.514817950889077
  ADV-support = 522
  AUX-precision = 0.0
  AUX-recall = 0.0
  AUX-f1-score = 0.0
  AUX-support = 75
  CCONJ-precision = 0.6986301369863014
  CCONJ-recall = 0.504950495049505
  CCONJ-f1-score = 0.5862068965517241
  CCONJ-support = 101
  DET-precision = 0.7643097643097643
  DET-recall = 0.6219178082191781
  DET-f1-score = 0.6858006042296073
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.6046511627906976
  NOUN-recall = 0.7695560253699789
  NOUN-f1-score = 0.6772093023255814
  NOUN-support = 1419
  NUM-precision = 0.8484107579462102
  NUM-recall = 0.9204244031830239
  NUM-f1-score = 0.8829516539440203
  NUM-support = 377
  PART-precision = 0.7127659574468085
  PART-recall = 0.6633663366336634
  PART-f1-score = 0.6871794871794872
  PART-support = 101
  PRON-precision = 0.9
  PRON-recall = 0.680921052631579
  PRON-f1-score = 0.7752808988764045
  PRON-support = 304
  PROPN-precision = 0.6347402597402597
  PROPN-recall = 0.6672354948805461
  PROPN-f1-score = 0.6505823627287853
  PROPN-support = 586
  PUNCT-precision = 0.8687782805429864
  PUNCT-recall = 0.96
  PUNCT-f1-score = 0.9121140142517815
  PUNCT-support = 200
  SCONJ-precision = 0.7303370786516854
  SCONJ-recall = 0.851528384279476
  SCONJ-f1-score = 0.7862903225806451
  SCONJ-support = 229
  VERB-precision = 0.46683673469387754
  VERB-recall = 0.6455026455026455
  VERB-f1-score = 0.541820873427091
  VERB-support = 567
  loss = 3.4896753139984913
  dataset = dev
***** Epoch end: 5 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.5850052034941909
  micro_f1 = 0.6797584569811966
  ADJ-precision = 0.36363636363636365
  ADJ-recall = 0.053691275167785234
  ADJ-f1-score = 0.0935672514619883
  ADJ-support = 149
  ADP-precision = 0.8179012345679012
  ADP-recall = 0.6400966183574879
  ADP-f1-score = 0.7181571815718156
  ADP-support = 414
  ADV-precision = 0.4888888888888889
  ADV-recall = 0.632183908045977
  ADV-f1-score = 0.5513784461152882
  ADV-support = 522
  AUX-precision = 0.0
  AUX-recall = 0.0
  AUX-f1-score = 0.0
  AUX-support = 75
  CCONJ-precision = 0.7123287671232876
  CCONJ-recall = 0.5148514851485149
  CCONJ-f1-score = 0.5977011494252874
  CCONJ-support = 101
  DET-precision = 0.8013937282229965
  DET-recall = 0.6301369863013698
  DET-f1-score = 0.705521472392638
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.6413911060433295
  NOUN-recall = 0.7928118393234672
  NOUN-f1-score = 0.7091080995902931
  NOUN-support = 1419
  NUM-precision = 0.8574938574938575
  NUM-recall = 0.9257294429708223
  NUM-f1-score = 0.8903061224489797
  NUM-support = 377
  PART-precision = 0.7263157894736842
  PART-recall = 0.6831683168316832
  PART-f1-score = 0.7040816326530612
  PART-support = 101
  PRON-precision = 0.9181034482758621
  PRON-recall = 0.7006578947368421
  PRON-f1-score = 0.7947761194029852
  PRON-support = 304
  PROPN-precision = 0.672386895475819
  PROPN-recall = 0.735494880546075
  PROPN-f1-score = 0.7025264873675632
  PROPN-support = 586
  PUNCT-precision = 0.8935185185185185
  PUNCT-recall = 0.965
  PUNCT-f1-score = 0.9278846153846153
  PUNCT-support = 200
  SCONJ-precision = 0.7547892720306514
  SCONJ-recall = 0.8602620087336245
  SCONJ-f1-score = 0.8040816326530613
  SCONJ-support = 229
  VERB-precision = 0.5060080106809078
  VERB-recall = 0.6684303350970018
  VERB-f1-score = 0.5759878419452887
  VERB-support = 567
  loss = 3.1546526688795824
  dataset = dev
***** Epoch end: 6 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6050917967677658
  micro_f1 = 0.7040796045503261
  ADJ-precision = 0.4166666666666667
  ADJ-recall = 0.06711409395973154
  ADJ-f1-score = 0.11560693641618497
  ADJ-support = 149
  ADP-precision = 0.8115942028985508
  ADP-recall = 0.6763285024154589
  ADP-f1-score = 0.7378129117259553
  ADP-support = 414
  ADV-precision = 0.4888304862023653
  ADV-recall = 0.7126436781609196
  ADV-f1-score = 0.5798908807482462
  ADV-support = 522
  AUX-precision = 1.0
  AUX-recall = 0.02666666666666667
  AUX-f1-score = 0.05194805194805195
  AUX-support = 75
  CCONJ-precision = 0.6933333333333334
  CCONJ-recall = 0.5148514851485149
  CCONJ-f1-score = 0.5909090909090909
  CCONJ-support = 101
  DET-precision = 0.8047945205479452
  DET-recall = 0.6438356164383562
  DET-f1-score = 0.715372907153729
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.6760070052539404
  NOUN-recall = 0.8160676532769556
  NOUN-f1-score = 0.739463601532567
  NOUN-support = 1419
  NUM-precision = 0.8691358024691358
  NUM-recall = 0.9336870026525199
  NUM-f1-score = 0.9002557544757033
  NUM-support = 377
  PART-precision = 0.7931034482758621
  PART-recall = 0.6831683168316832
  PART-f1-score = 0.7340425531914894
  PART-support = 101
  PRON-precision = 0.9037656903765691
  PRON-recall = 0.7105263157894737
  PRON-f1-score = 0.7955801104972376
  PRON-support = 304
  PROPN-precision = 0.7054140127388535
  PROPN-recall = 0.7559726962457338
  PROPN-f1-score = 0.729818780889621
  PROPN-support = 586
  PUNCT-precision = 0.9154929577464789
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.9443099273607748
  PUNCT-support = 200
  SCONJ-precision = 0.77734375
  SCONJ-recall = 0.868995633187773
  SCONJ-f1-score = 0.820618556701031
  SCONJ-support = 229
  VERB-precision = 0.5862068965517241
  VERB-recall = 0.6596119929453262
  VERB-f1-score = 0.620746887966805
  VERB-support = 567
  loss = 2.886821911885188
  dataset = dev
***** Epoch end: 7 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6227757461529442
  micro_f1 = 0.7196716143600705
  ADJ-precision = 0.46153846153846156
  ADJ-recall = 0.08053691275167785
  ADJ-f1-score = 0.13714285714285712
  ADJ-support = 149
  ADP-precision = 0.8558558558558559
  ADP-recall = 0.6884057971014492
  ADP-f1-score = 0.7630522088353413
  ADP-support = 414
  ADV-precision = 0.5311203319502075
  ADV-recall = 0.735632183908046
  ADV-f1-score = 0.6168674698795181
  ADV-support = 522
  AUX-precision = 0.7777777777777778
  AUX-recall = 0.09333333333333334
  AUX-f1-score = 0.16666666666666666
  AUX-support = 75
  CCONJ-precision = 0.6666666666666666
  CCONJ-recall = 0.5148514851485149
  CCONJ-f1-score = 0.5810055865921788
  CCONJ-support = 101
  DET-precision = 0.7777777777777778
  DET-recall = 0.6520547945205479
  DET-f1-score = 0.7093889716840537
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.6818960593946316
  NOUN-recall = 0.8414376321353065
  NOUN-f1-score = 0.7533123028391165
  NOUN-support = 1419
  NUM-precision = 0.8700980392156863
  NUM-recall = 0.9416445623342176
  NUM-f1-score = 0.9044585987261148
  NUM-support = 377
  PART-precision = 0.8214285714285714
  PART-recall = 0.6831683168316832
  PART-f1-score = 0.745945945945946
  PART-support = 101
  PRON-precision = 0.9156118143459916
  PRON-recall = 0.7138157894736842
  PRON-f1-score = 0.8022181146025879
  PRON-support = 304
  PROPN-precision = 0.7181528662420382
  PROPN-recall = 0.7696245733788396
  PROPN-f1-score = 0.742998352553542
  PROPN-support = 586
  PUNCT-precision = 0.9241706161137441
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.948905109489051
  PUNCT-support = 200
  SCONJ-precision = 0.7905138339920948
  SCONJ-recall = 0.8733624454148472
  SCONJ-f1-score = 0.8298755186721991
  SCONJ-support = 229
  VERB-precision = 0.6105769230769231
  VERB-recall = 0.671957671957672
  VERB-f1-score = 0.6397984886649876
  VERB-support = 567
  loss = 2.674648553897173
  dataset = dev
***** Epoch end: 8 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6389737513397777
  micro_f1 = 0.7381521844653182
  ADJ-precision = 0.4827586206896552
  ADJ-recall = 0.09395973154362416
  ADJ-f1-score = 0.15730337078651685
  ADJ-support = 149
  ADP-precision = 0.8156424581005587
  ADP-recall = 0.7053140096618358
  ADP-f1-score = 0.7564766839378237
  ADP-support = 414
  ADV-precision = 0.5578034682080925
  ADV-recall = 0.7394636015325671
  ADV-f1-score = 0.6359143327841844
  ADV-support = 522
  AUX-precision = 0.8333333333333334
  AUX-recall = 0.13333333333333333
  AUX-f1-score = 0.2298850574712644
  AUX-support = 75
  CCONJ-precision = 0.7272727272727273
  CCONJ-recall = 0.5544554455445545
  CCONJ-f1-score = 0.6292134831460674
  CCONJ-support = 101
  DET-precision = 0.76
  DET-recall = 0.6767123287671233
  DET-f1-score = 0.7159420289855072
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.7355973317161917
  NOUN-recall = 0.8548273431994362
  NOUN-f1-score = 0.7907431551499349
  NOUN-support = 1419
  NUM-precision = 0.8793103448275862
  NUM-recall = 0.946949602122016
  NUM-f1-score = 0.9118773946360152
  NUM-support = 377
  PART-precision = 0.8045977011494253
  PART-recall = 0.693069306930693
  PART-f1-score = 0.7446808510638299
  PART-support = 101
  PRON-precision = 0.919831223628692
  PRON-recall = 0.7171052631578947
  PRON-f1-score = 0.8059149722735675
  PRON-support = 304
  PROPN-precision = 0.7476635514018691
  PROPN-recall = 0.8191126279863481
  PROPN-f1-score = 0.7817589576547231
  PROPN-support = 586
  PUNCT-precision = 0.9241706161137441
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.948905109489051
  PUNCT-support = 200
  SCONJ-precision = 0.8087649402390438
  SCONJ-recall = 0.8864628820960698
  SCONJ-f1-score = 0.8458333333333333
  SCONJ-support = 229
  VERB-precision = 0.5483028720626631
  VERB-recall = 0.7407407407407407
  VERB-f1-score = 0.6301575393848462
  VERB-support = 567
  loss = 2.4821228553087282
  dataset = dev
***** Epoch end: 9 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6500501049004362
  micro_f1 = 0.7508821027884206
  ADJ-precision = 0.5
  ADJ-recall = 0.10738255033557047
  ADJ-f1-score = 0.17679558011049726
  ADJ-support = 149
  ADP-precision = 0.8361111111111111
  ADP-recall = 0.7270531400966184
  ADP-f1-score = 0.7777777777777778
  ADP-support = 414
  ADV-precision = 0.562942008486563
  ADV-recall = 0.7624521072796935
  ADV-f1-score = 0.6476810414971522
  ADV-support = 522
  AUX-precision = 0.8333333333333334
  AUX-recall = 0.13333333333333333
  AUX-f1-score = 0.2298850574712644
  AUX-support = 75
  CCONJ-precision = 0.7125
  CCONJ-recall = 0.5643564356435643
  CCONJ-f1-score = 0.6298342541436464
  CCONJ-support = 101
  DET-precision = 0.7701863354037267
  DET-recall = 0.6794520547945205
  DET-f1-score = 0.7219796215429403
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.7305669199298656
  NOUN-recall = 0.8809020436927414
  NOUN-f1-score = 0.7987220447284344
  NOUN-support = 1419
  NUM-precision = 0.8938271604938272
  NUM-recall = 0.9602122015915119
  NUM-f1-score = 0.9258312020460358
  NUM-support = 377
  PART-precision = 0.8352941176470589
  PART-recall = 0.7029702970297029
  PART-f1-score = 0.7634408602150539
  PART-support = 101
  PRON-precision = 0.8983739837398373
  PRON-recall = 0.7269736842105263
  PRON-f1-score = 0.8036363636363637
  PRON-support = 304
  PROPN-precision = 0.7837398373983739
  PROPN-recall = 0.8225255972696246
  PROPN-f1-score = 0.8026644462947543
  PROPN-support = 586
  PUNCT-precision = 0.9420289855072463
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.9582309582309583
  PUNCT-support = 200
  SCONJ-precision = 0.824
  SCONJ-recall = 0.8995633187772926
  SCONJ-f1-score = 0.860125260960334
  SCONJ-support = 229
  VERB-precision = 0.5879043600562588
  VERB-recall = 0.7372134038800705
  VERB-f1-score = 0.6541471048513301
  VERB-support = 567
  loss = 2.331836694326156
  dataset = dev
***** Epoch end: 10 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6671116521072745
  micro_f1 = 0.7655948523222014
  ADJ-precision = 0.5116279069767442
  ADJ-recall = 0.1476510067114094
  ADJ-f1-score = 0.22916666666666669
  ADJ-support = 149
  ADP-precision = 0.7864321608040201
  ADP-recall = 0.7560386473429952
  ADP-f1-score = 0.7709359605911331
  ADP-support = 414
  ADV-precision = 0.5695652173913044
  ADV-recall = 0.7528735632183908
  ADV-f1-score = 0.6485148514851485
  ADV-support = 522
  AUX-precision = 0.9166666666666666
  AUX-recall = 0.14666666666666667
  AUX-f1-score = 0.25287356321839083
  AUX-support = 75
  CCONJ-precision = 0.7619047619047619
  CCONJ-recall = 0.6336633663366337
  CCONJ-f1-score = 0.6918918918918918
  CCONJ-support = 101
  DET-precision = 0.7678571428571429
  DET-recall = 0.7068493150684931
  DET-f1-score = 0.7360912981455066
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.7593712212817413
  NOUN-recall = 0.8851303735024665
  NOUN-f1-score = 0.8174422388545396
  NOUN-support = 1419
  NUM-precision = 0.9029850746268657
  NUM-recall = 0.9628647214854111
  NUM-f1-score = 0.9319640564826701
  NUM-support = 377
  PART-precision = 0.8488372093023255
  PART-recall = 0.7227722772277227
  PART-f1-score = 0.7807486631016043
  PART-support = 101
  PRON-precision = 0.902834008097166
  PRON-recall = 0.7335526315789473
  PRON-f1-score = 0.809437386569873
  PRON-support = 304
  PROPN-precision = 0.7987117552334944
  PROPN-recall = 0.8464163822525598
  PROPN-f1-score = 0.8218724109362054
  PROPN-support = 586
  PUNCT-precision = 0.9466019417475728
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.9605911330049262
  PUNCT-support = 200
  SCONJ-precision = 0.8583333333333333
  SCONJ-recall = 0.8995633187772926
  SCONJ-f1-score = 0.8784648187633262
  SCONJ-support = 229
  VERB-precision = 0.6131805157593123
  VERB-recall = 0.7548500881834215
  VERB-f1-score = 0.6766798418972332
  VERB-support = 567
  loss = 2.1952891563757873
  dataset = dev
***** Epoch end: 11 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6778515582236324
  micro_f1 = 0.7784509045800952
  ADJ-precision = 0.45652173913043476
  ADJ-recall = 0.14093959731543623
  ADJ-f1-score = 0.2153846153846154
  ADJ-support = 149
  ADP-precision = 0.8373983739837398
  ADP-recall = 0.7463768115942029
  ADP-f1-score = 0.789272030651341
  ADP-support = 414
  ADV-precision = 0.5845942228335625
  ADV-recall = 0.814176245210728
  ADV-f1-score = 0.6805444355484388
  ADV-support = 522
  AUX-precision = 0.8
  AUX-recall = 0.16
  AUX-f1-score = 0.26666666666666666
  AUX-support = 75
  CCONJ-precision = 0.7790697674418605
  CCONJ-recall = 0.6633663366336634
  CCONJ-f1-score = 0.7165775401069518
  CCONJ-support = 101
  DET-precision = 0.7636887608069164
  DET-recall = 0.726027397260274
  DET-f1-score = 0.74438202247191
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.7768187422934648
  NOUN-recall = 0.8879492600422833
  NOUN-f1-score = 0.8286747780335416
  NOUN-support = 1419
  NUM-precision = 0.9057071960297767
  NUM-recall = 0.9681697612732095
  NUM-f1-score = 0.9358974358974359
  NUM-support = 377
  PART-precision = 0.8809523809523809
  PART-recall = 0.7326732673267327
  PART-f1-score = 0.8
  PART-support = 101
  PRON-precision = 0.8987854251012146
  PRON-recall = 0.7302631578947368
  PRON-f1-score = 0.8058076225045372
  PRON-support = 304
  PROPN-precision = 0.8045602605863192
  PROPN-recall = 0.8430034129692833
  PROPN-f1-score = 0.8233333333333334
  PROPN-support = 586
  PUNCT-precision = 0.9468599033816425
  PUNCT-recall = 0.98
  PUNCT-f1-score = 0.9631449631449631
  PUNCT-support = 200
  SCONJ-precision = 0.8765957446808511
  SCONJ-recall = 0.8995633187772926
  SCONJ-f1-score = 0.8879310344827586
  SCONJ-support = 229
  VERB-precision = 0.6677018633540373
  VERB-recall = 0.7583774250440917
  VERB-f1-score = 0.7101568951279933
  VERB-support = 567
  loss = 2.091905667231633
  dataset = dev
***** Epoch end: 12 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6838048148922389
  micro_f1 = 0.7852434034731779
  ADJ-precision = 0.41509433962264153
  ADJ-recall = 0.1476510067114094
  ADJ-f1-score = 0.21782178217821785
  ADJ-support = 149
  ADP-precision = 0.8337801608579088
  ADP-recall = 0.751207729468599
  ADP-f1-score = 0.7903430749682337
  ADP-support = 414
  ADV-precision = 0.5968660968660968
  ADV-recall = 0.8026819923371648
  ADV-f1-score = 0.684640522875817
  ADV-support = 522
  AUX-precision = 0.8235294117647058
  AUX-recall = 0.18666666666666668
  AUX-f1-score = 0.3043478260869565
  AUX-support = 75
  CCONJ-precision = 0.788235294117647
  CCONJ-recall = 0.6633663366336634
  CCONJ-f1-score = 0.7204301075268816
  CCONJ-support = 101
  DET-precision = 0.7571428571428571
  DET-recall = 0.726027397260274
  DET-f1-score = 0.7412587412587412
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.7838983050847458
  NOUN-recall = 0.9126145172656801
  NOUN-f1-score = 0.8433734939759037
  NOUN-support = 1419
  NUM-precision = 0.9097744360902256
  NUM-recall = 0.9628647214854111
  NUM-f1-score = 0.9355670103092784
  NUM-support = 377
  PART-precision = 0.9125
  PART-recall = 0.7227722772277227
  PART-f1-score = 0.8066298342541437
  PART-support = 101
  PRON-precision = 0.9068825910931174
  PRON-recall = 0.7368421052631579
  PRON-f1-score = 0.8130671506352086
  PRON-support = 304
  PROPN-precision = 0.8283828382838284
  PROPN-recall = 0.856655290102389
  PROPN-f1-score = 0.8422818791946309
  PROPN-support = 586
  PUNCT-precision = 0.9512195121951219
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.9629629629629629
  PUNCT-support = 200
  SCONJ-precision = 0.8771186440677966
  SCONJ-recall = 0.9039301310043668
  SCONJ-f1-score = 0.8903225806451612
  SCONJ-support = 229
  VERB-precision = 0.6371428571428571
  VERB-recall = 0.7865961199294532
  VERB-f1-score = 0.7040252565114443
  VERB-support = 567
  loss = 1.9925275613100102
  dataset = dev
***** Epoch end: 13 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.6951743429233475
  micro_f1 = 0.7982638580572654
  ADJ-precision = 0.46296296296296297
  ADJ-recall = 0.16778523489932887
  ADJ-f1-score = 0.24630541871921183
  ADJ-support = 149
  ADP-precision = 0.856
  ADP-recall = 0.7753623188405797
  ADP-f1-score = 0.8136882129277566
  ADP-support = 414
  ADV-precision = 0.6045197740112994
  ADV-recall = 0.8199233716475096
  ADV-f1-score = 0.6959349593495934
  ADV-support = 522
  AUX-precision = 0.8823529411764706
  AUX-recall = 0.2
  AUX-f1-score = 0.3260869565217392
  AUX-support = 75
  CCONJ-precision = 0.7906976744186046
  CCONJ-recall = 0.6732673267326733
  CCONJ-f1-score = 0.7272727272727273
  CCONJ-support = 101
  DET-precision = 0.7506849315068493
  DET-recall = 0.7506849315068493
  DET-f1-score = 0.7506849315068492
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8123815540113708
  NOUN-recall = 0.9062720225510923
  NOUN-f1-score = 0.8567621585609593
  NOUN-support = 1419
  NUM-precision = 0.9032258064516129
  NUM-recall = 0.9655172413793104
  NUM-f1-score = 0.9333333333333333
  NUM-support = 377
  PART-precision = 0.8928571428571429
  PART-recall = 0.7425742574257426
  PART-f1-score = 0.8108108108108107
  PART-support = 101
  PRON-precision = 0.907258064516129
  PRON-recall = 0.7401315789473685
  PRON-f1-score = 0.8152173913043478
  PRON-support = 304
  PROPN-precision = 0.815625
  PROPN-recall = 0.8907849829351536
  PROPN-f1-score = 0.8515497553017946
  PROPN-support = 586
  PUNCT-precision = 0.9653465346534653
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.9701492537313433
  PUNCT-support = 200
  SCONJ-precision = 0.8846153846153846
  SCONJ-recall = 0.9039301310043668
  SCONJ-f1-score = 0.8941684665226781
  SCONJ-support = 229
  VERB-precision = 0.6791044776119403
  VERB-recall = 0.8024691358024691
  VERB-f1-score = 0.7356507679870654
  VERB-support = 567
  loss = 1.9101711389346
  dataset = dev
***** Epoch end: 14 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7007207398945681
  micro_f1 = 0.8043681046477102
  ADJ-precision = 0.5
  ADJ-recall = 0.18120805369127516
  ADJ-f1-score = 0.2660098522167488
  ADJ-support = 149
  ADP-precision = 0.8496042216358839
  ADP-recall = 0.7777777777777778
  ADP-f1-score = 0.8121059268600253
  ADP-support = 414
  ADV-precision = 0.6153846153846154
  ADV-recall = 0.842911877394636
  ADV-f1-score = 0.7113985448666127
  ADV-support = 522
  AUX-precision = 0.8823529411764706
  AUX-recall = 0.2
  AUX-f1-score = 0.3260869565217392
  AUX-support = 75
  CCONJ-precision = 0.7931034482758621
  CCONJ-recall = 0.6831683168316832
  CCONJ-f1-score = 0.7340425531914894
  CCONJ-support = 101
  DET-precision = 0.7670454545454546
  DET-recall = 0.7397260273972602
  DET-f1-score = 0.7531380753138076
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8030487804878049
  NOUN-recall = 0.9281183932346723
  NOUN-f1-score = 0.86106570774763
  NOUN-support = 1419
  NUM-precision = 0.914572864321608
  NUM-recall = 0.9655172413793104
  NUM-f1-score = 0.9393548387096775
  NUM-support = 377
  PART-precision = 0.9146341463414634
  PART-recall = 0.7425742574257426
  PART-f1-score = 0.819672131147541
  PART-support = 101
  PRON-precision = 0.9032258064516129
  PRON-recall = 0.7368421052631579
  PRON-f1-score = 0.8115942028985507
  PRON-support = 304
  PROPN-precision = 0.8615384615384616
  PROPN-recall = 0.8600682593856656
  PROPN-f1-score = 0.8608027327070881
  PROPN-support = 586
  PUNCT-precision = 0.9653465346534653
  PUNCT-recall = 0.975
  PUNCT-f1-score = 0.9701492537313433
  PUNCT-support = 200
  SCONJ-precision = 0.8922413793103449
  SCONJ-recall = 0.9039301310043668
  SCONJ-f1-score = 0.8980477223427332
  SCONJ-support = 229
  VERB-precision = 0.6966463414634146
  VERB-recall = 0.8059964726631393
  VERB-f1-score = 0.7473426001635323
  VERB-support = 567
  loss = 1.8462357215392284
  dataset = dev
***** Epoch end: 15 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7093879125590818
  micro_f1 = 0.8111224370157987
  ADJ-precision = 0.5166666666666667
  ADJ-recall = 0.2080536912751678
  ADJ-f1-score = 0.2966507177033493
  ADJ-support = 149
  ADP-precision = 0.8534031413612565
  ADP-recall = 0.7874396135265701
  ADP-f1-score = 0.8190954773869348
  ADP-support = 414
  ADV-precision = 0.6178521617852162
  ADV-recall = 0.8486590038314177
  ADV-f1-score = 0.7150928167877321
  ADV-support = 522
  AUX-precision = 0.85
  AUX-recall = 0.22666666666666666
  AUX-f1-score = 0.35789473684210527
  AUX-support = 75
  CCONJ-precision = 0.797752808988764
  CCONJ-recall = 0.7029702970297029
  CCONJ-f1-score = 0.7473684210526316
  CCONJ-support = 101
  DET-precision = 0.7554347826086957
  DET-recall = 0.7616438356164383
  DET-f1-score = 0.7585266030013643
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8218572331017057
  NOUN-recall = 0.9168428470754052
  NOUN-f1-score = 0.8667554963357762
  NOUN-support = 1419
  NUM-precision = 0.9122807017543859
  NUM-recall = 0.9655172413793104
  NUM-f1-score = 0.9381443298969072
  NUM-support = 377
  PART-precision = 0.9259259259259259
  PART-recall = 0.7425742574257426
  PART-f1-score = 0.8241758241758241
  PART-support = 101
  PRON-precision = 0.8932806324110671
  PRON-recall = 0.743421052631579
  PRON-f1-score = 0.8114901256732496
  PRON-support = 304
  PROPN-precision = 0.8624161073825504
  PROPN-recall = 0.8771331058020477
  PROPN-f1-score = 0.8697123519458544
  PROPN-support = 586
  PUNCT-precision = 0.9656862745098039
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9752475247524752
  PUNCT-support = 200
  SCONJ-precision = 0.896551724137931
  SCONJ-recall = 0.9082969432314411
  SCONJ-f1-score = 0.9023861171366595
  SCONJ-support = 229
  VERB-precision = 0.7145085803432137
  VERB-recall = 0.8077601410934744
  VERB-f1-score = 0.7582781456953642
  VERB-support = 567
  loss = 1.8019830385843914
  dataset = dev
***** Epoch end: 16 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7125835368451108
  micro_f1 = 0.8148072958915544
  ADJ-precision = 0.45454545454545453
  ADJ-recall = 0.20134228187919462
  ADJ-f1-score = 0.27906976744186046
  ADJ-support = 149
  ADP-precision = 0.8385416666666666
  ADP-recall = 0.7777777777777778
  ADP-f1-score = 0.8070175438596491
  ADP-support = 414
  ADV-precision = 0.6342525399129173
  ADV-recall = 0.8371647509578544
  ADV-f1-score = 0.7217175887696119
  ADV-support = 522
  AUX-precision = 0.8571428571428571
  AUX-recall = 0.24
  AUX-f1-score = 0.375
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.7666666666666667
  DET-recall = 0.7561643835616438
  DET-f1-score = 0.7613793103448276
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8229813664596274
  NOUN-recall = 0.9337561663143058
  NOUN-f1-score = 0.8748761967646088
  NOUN-support = 1419
  NUM-precision = 0.9265822784810127
  NUM-recall = 0.9708222811671088
  NUM-f1-score = 0.9481865284974094
  NUM-support = 377
  PART-precision = 0.9375
  PART-recall = 0.7425742574257426
  PART-f1-score = 0.8287292817679558
  PART-support = 101
  PRON-precision = 0.9043824701195219
  PRON-recall = 0.7467105263157895
  PRON-f1-score = 0.818018018018018
  PRON-support = 304
  PROPN-precision = 0.8571428571428571
  PROPN-recall = 0.8907849829351536
  PROPN-f1-score = 0.8736401673640167
  PROPN-support = 586
  PUNCT-precision = 0.9800995024875622
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9825436408977556
  PUNCT-support = 200
  SCONJ-precision = 0.8969957081545065
  SCONJ-recall = 0.9126637554585153
  SCONJ-f1-score = 0.9047619047619049
  SCONJ-support = 229
  VERB-precision = 0.7036474164133738
  VERB-recall = 0.8165784832451499
  VERB-f1-score = 0.7559183673469388
  VERB-support = 567
  loss = 1.746680702918615
  dataset = dev
***** Epoch end: 17 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7188995389951429
  micro_f1 = 0.8199824105078949
  ADJ-precision = 0.5074626865671642
  ADJ-recall = 0.22818791946308725
  ADJ-f1-score = 0.3148148148148148
  ADJ-support = 149
  ADP-precision = 0.8397932816537468
  ADP-recall = 0.785024154589372
  ADP-f1-score = 0.8114856429463172
  ADP-support = 414
  ADV-precision = 0.6324786324786325
  ADV-recall = 0.8505747126436781
  ADV-f1-score = 0.7254901960784313
  ADV-support = 522
  AUX-precision = 0.8695652173913043
  AUX-recall = 0.26666666666666666
  AUX-f1-score = 0.40816326530612246
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.7683923705722071
  DET-recall = 0.7726027397260274
  DET-f1-score = 0.7704918032786885
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.83575489576753
  NOUN-recall = 0.9323467230443975
  NOUN-f1-score = 0.8814123917388408
  NOUN-support = 1419
  NUM-precision = 0.9221105527638191
  NUM-recall = 0.9734748010610079
  NUM-f1-score = 0.9470967741935484
  NUM-support = 377
  PART-precision = 0.9259259259259259
  PART-recall = 0.7425742574257426
  PART-f1-score = 0.8241758241758241
  PART-support = 101
  PRON-precision = 0.9043824701195219
  PRON-recall = 0.7467105263157895
  PRON-f1-score = 0.818018018018018
  PRON-support = 304
  PROPN-precision = 0.867330016583748
  PROPN-recall = 0.8924914675767918
  PROPN-f1-score = 0.87973086627418
  PROPN-support = 586
  PUNCT-precision = 0.9752475247524752
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9800995024875623
  PUNCT-support = 200
  SCONJ-precision = 0.9008620689655172
  SCONJ-recall = 0.9126637554585153
  SCONJ-f1-score = 0.9067245119305858
  SCONJ-support = 229
  VERB-precision = 0.7005988023952096
  VERB-recall = 0.8253968253968254
  VERB-f1-score = 0.7578947368421053
  VERB-support = 567
  loss = 1.7145863710305629
  dataset = dev
***** Epoch end: 18 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7215362587487012
  micro_f1 = 0.8225512715886986
  ADJ-precision = 0.4782608695652174
  ADJ-recall = 0.2214765100671141
  ADJ-f1-score = 0.30275229357798167
  ADJ-support = 149
  ADP-precision = 0.8537859007832899
  ADP-recall = 0.7898550724637681
  ADP-f1-score = 0.8205771643663737
  ADP-support = 414
  ADV-precision = 0.6362339514978602
  ADV-recall = 0.8544061302681992
  ADV-f1-score = 0.7293540474243663
  ADV-support = 522
  AUX-precision = 0.8695652173913043
  AUX-recall = 0.26666666666666666
  AUX-f1-score = 0.40816326530612246
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.7704918032786885
  DET-recall = 0.7726027397260274
  DET-f1-score = 0.771545827633379
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8326018808777429
  NOUN-recall = 0.9358703312191684
  NOUN-f1-score = 0.8812209688122098
  NOUN-support = 1419
  NUM-precision = 0.9221105527638191
  NUM-recall = 0.9734748010610079
  NUM-f1-score = 0.9470967741935484
  NUM-support = 377
  PART-precision = 0.9397590361445783
  PART-recall = 0.7722772277227723
  PART-f1-score = 0.8478260869565218
  PART-support = 101
  PRON-precision = 0.9011857707509882
  PRON-recall = 0.75
  PRON-f1-score = 0.8186714542190304
  PRON-support = 304
  PROPN-precision = 0.8616144975288303
  PROPN-recall = 0.8924914675767918
  PROPN-f1-score = 0.8767812238055323
  PROPN-support = 586
  PUNCT-precision = 0.9800995024875622
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9825436408977556
  PUNCT-support = 200
  SCONJ-precision = 0.8936170212765957
  SCONJ-recall = 0.9170305676855895
  SCONJ-f1-score = 0.9051724137931034
  SCONJ-support = 229
  VERB-precision = 0.7304075235109718
  VERB-recall = 0.8218694885361552
  VERB-f1-score = 0.7734439834024895
  VERB-support = 567
  loss = 1.6976032715577345
  dataset = dev
***** Epoch end: 19 *****
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.721172541338261
  micro_f1 = 0.8221635998615354
  ADJ-precision = 0.4852941176470588
  ADJ-recall = 0.2214765100671141
  ADJ-f1-score = 0.30414746543778803
  ADJ-support = 149
  ADP-precision = 0.8388746803069054
  ADP-recall = 0.7922705314009661
  ADP-f1-score = 0.8149068322981367
  ADP-support = 414
  ADV-precision = 0.638328530259366
  ADV-recall = 0.8486590038314177
  ADV-f1-score = 0.7286184210526315
  ADV-support = 522
  AUX-precision = 0.875
  AUX-recall = 0.28
  AUX-f1-score = 0.42424242424242425
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.773841961852861
  DET-recall = 0.7780821917808219
  DET-f1-score = 0.7759562841530054
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8337515683814304
  NOUN-recall = 0.9365750528541226
  NOUN-f1-score = 0.8821772319946896
  NOUN-support = 1419
  NUM-precision = 0.9221105527638191
  NUM-recall = 0.9734748010610079
  NUM-f1-score = 0.9470967741935484
  NUM-support = 377
  PART-precision = 0.9375
  PART-recall = 0.7425742574257426
  PART-f1-score = 0.8287292817679558
  PART-support = 101
  PRON-precision = 0.9047619047619048
  PRON-recall = 0.75
  PRON-f1-score = 0.8201438848920864
  PRON-support = 304
  PROPN-precision = 0.863036303630363
  PROPN-recall = 0.8924914675767918
  PROPN-f1-score = 0.8775167785234899
  PROPN-support = 586
  PUNCT-precision = 0.9800995024875622
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9825436408977556
  PUNCT-support = 200
  SCONJ-precision = 0.8969957081545065
  SCONJ-recall = 0.9126637554585153
  SCONJ-f1-score = 0.9047619047619049
  SCONJ-support = 229
  VERB-precision = 0.7182235834609495
  VERB-recall = 0.8271604938271605
  VERB-f1-score = 0.7688524590163935
  VERB-support = 567
  loss = 1.6908806409591284
  dataset = dev
***** Training end *****
  Model path = ../config/examples/chinese_word_segmentation/BERT_CRF/model/model.pt
***** Loading data *****
  Data path = ../data/datasets/canton_ws/data_combined.json
  Number of raw samples = 2445
  Number of loaded samples = 2445
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7215362587487012
  micro_f1 = 0.8225512715886986
  ADJ-precision = 0.4782608695652174
  ADJ-recall = 0.2214765100671141
  ADJ-f1-score = 0.30275229357798167
  ADJ-support = 149
  ADP-precision = 0.8537859007832899
  ADP-recall = 0.7898550724637681
  ADP-f1-score = 0.8205771643663737
  ADP-support = 414
  ADV-precision = 0.6362339514978602
  ADV-recall = 0.8544061302681992
  ADV-f1-score = 0.7293540474243663
  ADV-support = 522
  AUX-precision = 0.8695652173913043
  AUX-recall = 0.26666666666666666
  AUX-f1-score = 0.40816326530612246
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.7704918032786885
  DET-recall = 0.7726027397260274
  DET-f1-score = 0.771545827633379
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8326018808777429
  NOUN-recall = 0.9358703312191684
  NOUN-f1-score = 0.8812209688122098
  NOUN-support = 1419
  NUM-precision = 0.9221105527638191
  NUM-recall = 0.9734748010610079
  NUM-f1-score = 0.9470967741935484
  NUM-support = 377
  PART-precision = 0.9397590361445783
  PART-recall = 0.7722772277227723
  PART-f1-score = 0.8478260869565218
  PART-support = 101
  PRON-precision = 0.9011857707509882
  PRON-recall = 0.75
  PRON-f1-score = 0.8186714542190304
  PRON-support = 304
  PROPN-precision = 0.8616144975288303
  PROPN-recall = 0.8924914675767918
  PROPN-f1-score = 0.8767812238055323
  PROPN-support = 586
  PUNCT-precision = 0.9800995024875622
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9825436408977556
  PUNCT-support = 200
  SCONJ-precision = 0.8936170212765957
  SCONJ-recall = 0.9170305676855895
  SCONJ-f1-score = 0.9051724137931034
  SCONJ-support = 229
  VERB-precision = 0.7304075235109718
  VERB-recall = 0.8218694885361552
  VERB-f1-score = 0.7734439834024895
  VERB-support = 567
  loss = 1.6976032715577345
  dataset = train
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7215362587487012
  micro_f1 = 0.8225512715886986
  ADJ-precision = 0.4782608695652174
  ADJ-recall = 0.2214765100671141
  ADJ-f1-score = 0.30275229357798167
  ADJ-support = 149
  ADP-precision = 0.8537859007832899
  ADP-recall = 0.7898550724637681
  ADP-f1-score = 0.8205771643663737
  ADP-support = 414
  ADV-precision = 0.6362339514978602
  ADV-recall = 0.8544061302681992
  ADV-f1-score = 0.7293540474243663
  ADV-support = 522
  AUX-precision = 0.8695652173913043
  AUX-recall = 0.26666666666666666
  AUX-f1-score = 0.40816326530612246
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.7704918032786885
  DET-recall = 0.7726027397260274
  DET-f1-score = 0.771545827633379
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8326018808777429
  NOUN-recall = 0.9358703312191684
  NOUN-f1-score = 0.8812209688122098
  NOUN-support = 1419
  NUM-precision = 0.9221105527638191
  NUM-recall = 0.9734748010610079
  NUM-f1-score = 0.9470967741935484
  NUM-support = 377
  PART-precision = 0.9397590361445783
  PART-recall = 0.7722772277227723
  PART-f1-score = 0.8478260869565218
  PART-support = 101
  PRON-precision = 0.9011857707509882
  PRON-recall = 0.75
  PRON-f1-score = 0.8186714542190304
  PRON-support = 304
  PROPN-precision = 0.8616144975288303
  PROPN-recall = 0.8924914675767918
  PROPN-f1-score = 0.8767812238055323
  PROPN-support = 586
  PUNCT-precision = 0.9800995024875622
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9825436408977556
  PUNCT-support = 200
  SCONJ-precision = 0.8936170212765957
  SCONJ-recall = 0.9170305676855895
  SCONJ-f1-score = 0.9051724137931034
  SCONJ-support = 229
  VERB-precision = 0.7304075235109718
  VERB-recall = 0.8218694885361552
  VERB-f1-score = 0.7734439834024895
  VERB-support = 567
  loss = 1.6976032715577345
  dataset = dev
***** Running evaluation *****
  Num examples = 2445
  Batch size = 64
  macro_f1 = 0.7215362587487012
  micro_f1 = 0.8225512715886986
  ADJ-precision = 0.4782608695652174
  ADJ-recall = 0.2214765100671141
  ADJ-f1-score = 0.30275229357798167
  ADJ-support = 149
  ADP-precision = 0.8537859007832899
  ADP-recall = 0.7898550724637681
  ADP-f1-score = 0.8205771643663737
  ADP-support = 414
  ADV-precision = 0.6362339514978602
  ADV-recall = 0.8544061302681992
  ADV-f1-score = 0.7293540474243663
  ADV-support = 522
  AUX-precision = 0.8695652173913043
  AUX-recall = 0.26666666666666666
  AUX-f1-score = 0.40816326530612246
  AUX-support = 75
  CCONJ-precision = 0.8089887640449438
  CCONJ-recall = 0.7128712871287128
  CCONJ-f1-score = 0.7578947368421052
  CCONJ-support = 101
  DET-precision = 0.7704918032786885
  DET-recall = 0.7726027397260274
  DET-f1-score = 0.771545827633379
  DET-support = 365
  INTJ-precision = 0.0
  INTJ-recall = 0.0
  INTJ-f1-score = 0.0
  INTJ-support = 4
  NOUN-precision = 0.8326018808777429
  NOUN-recall = 0.9358703312191684
  NOUN-f1-score = 0.8812209688122098
  NOUN-support = 1419
  NUM-precision = 0.9221105527638191
  NUM-recall = 0.9734748010610079
  NUM-f1-score = 0.9470967741935484
  NUM-support = 377
  PART-precision = 0.9397590361445783
  PART-recall = 0.7722772277227723
  PART-f1-score = 0.8478260869565218
  PART-support = 101
  PRON-precision = 0.9011857707509882
  PRON-recall = 0.75
  PRON-f1-score = 0.8186714542190304
  PRON-support = 304
  PROPN-precision = 0.8616144975288303
  PROPN-recall = 0.8924914675767918
  PROPN-f1-score = 0.8767812238055323
  PROPN-support = 586
  PUNCT-precision = 0.9800995024875622
  PUNCT-recall = 0.985
  PUNCT-f1-score = 0.9825436408977556
  PUNCT-support = 200
  SCONJ-precision = 0.8936170212765957
  SCONJ-recall = 0.9170305676855895
  SCONJ-f1-score = 0.9051724137931034
  SCONJ-support = 229
  VERB-precision = 0.7304075235109718
  VERB-recall = 0.8218694885361552
  VERB-f1-score = 0.7734439834024895
  VERB-support = 567
  loss = 1.6976032715577345
  dataset = test
